---
title: "Challenging Advanced Sampling in Household Surveys"
subtitle: "Day 2 - Tuesday in Harry's Office | Module 1: Complex Designs Foundation"
author: "Harry - International Survey Methodology Consultant"
institute: "SADC Advanced Sampling Workshop"
date: "Tuesday Morning - Module 1 of 8"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: [default, metropolis, metropolis-fonts]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9'
      slideNumberFormat: "Module 1 - Slide %current% of 412"
---

```{r setup, include=FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
library(patchwork)
library(scales)
library(ggplot2)
library(dplyr)
library(tidyr)
library(tibble)
library(purrr)

options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width = 9, fig.height = 4.5, fig.retina = 3,
  out.width = "100%", cache = FALSE, echo = TRUE,
  message = FALSE, warning = FALSE, fig.show = TRUE
)

theme_set(theme_minimal(base_size = 12))

wb_blue <- "#002244"
eurostat_blue <- "#004494"
oecd_blue <- "#0079c1"
un_blue <- "#0099ff"

set.seed(2024)
```

class: inverse, center, middle

# Module 1: Complex Designs Foundation
## Tuesday Morning in Harry's Office
### 50 Slides on Why Simple Sampling Fails

---

# Slide 2: Welcome to Tuesday!

.pull-left[
### 7:45 AM - Harry's Office

"Morning everyone! Eight modules, 400 slides, all based on World Bank LSMS, Eurostat EU-SILC, OECD PIAAC, and UN NHSCP standards."

**Today's Modules:**
1. Complex Designs Foundation
2. Stratification Mastery
3. Cluster Sampling Economics
4. Multi-Stage Integration
5. Weight Calculations
6. Non-Response Solutions
7. Special Populations
8. Crisis Management
]

.pull-right[
**International Standards We'll Cover:**
- **World Bank:** LSMS Manual Chapters 3-7
- **Eurostat:** EU-SILC Doc 65/2023
- **OECD:** PIAAC Technical Standards
- **UN:** Handbook F.98 (2022 Edition)
- **WHO:** STEPS Manual Version 3.2
- **ILO:** Labour Force Survey Manual

"Every technique follows these standards"
]

---

# Slide 3: My Journey Following World Bank Methods

### 1998 - Before LSMS Training

.pull-left[
"Fresh from university, I ignored World Bank LSMS guidelines. Designed 'perfect' simple random sample."

**The Disaster:**
- Violated WB cost principles
- Ignored Eurostat clustering guidance
- No stratification (UN Handbook Ch.4)
- Result: Complete failure

**What Changed:**
- 1999: World Bank LSMS training
- 2000: Eurostat quality framework
- 2001: First successful design
]

.pull-right[
**Standards I Violated:**
- WB LSMS Manual Section 3.2
- Eurostat Doc 65 Chapter 4
- UN F.98 Paragraph 4.15
- OECD Guidelines Annex B

"Learning these standards saved my career"
]

---

# Slide 4: The Crisis Following No Standards

```{r email-visual, echo=FALSE, fig.height=3}
library(ggtext)

email_data <- tibble(
  x = 0, y = 0,
  # The list is now formatted with hyphens and line breaks, not <ul>
  text = "Subject: **URGENT - Not Following International Standards**<br><br>Harry,<br><br>Our design violates:<br>- World Bank cost efficiency (LSMS 3.4)<br>- Eurostat quality thresholds (Doc 65)<br>- UN coverage requirements (F.98)<br>- OECD precision standards<br><br>Minister wants compliance NOW.<br><br>What do we do?<br><br>- Statistical Office Director<br>  March 2019"
)

ggplot(email_data, aes(x, y)) +
  geom_tile(fill = "white", color = "black", size = 1) +
  geom_richtext(
    aes(label = text),
    size = 4.5, hjust = 0, vjust = 1,
    x = -0.45, y = 0.45,
    label.family = "mono",
    fill = NA, label.color = NA 
  ) +
  xlim(-0.5, 0.5) + ylim(-0.5, 0.5) +
  theme_void() +
  theme(plot.background = element_rect(fill = "#f0f0f0"))
```

---

# Slide 5: Why SRS Fails - World Bank Evidence

### From LSMS Technical Paper 126

```{r srs-failure, echo=FALSE, fig.height=3}
failure_reasons <- tibble(
  Reason = c("Geographic Dispersion", "Cost Explosion", 
             "Frame Issues", "Response Patterns"),
  WB_Score = c(92, 88, 84, 79),
  Eurostat_Score = c(89, 91, 87, 82)
) %>%
  pivot_longer(cols = c(WB_Score, Eurostat_Score), 
               names_to = "Standard", values_to = "Score")

ggplot(failure_reasons, aes(x = reorder(Reason, Score), y = Score, fill = Standard)) +
  geom_col(position = "dodge", alpha = 0.8) +
  coord_flip() +
  scale_fill_manual(values = c("WB_Score" = wb_blue, "Eurostat_Score" = eurostat_blue)) +
  labs(title = "SRS Failure Assessment: World Bank vs Eurostat",
       subtitle = "Sources: WB Technical Paper 126, Eurostat Quality Report 2023",
       y = "Failure Score (0-100)") +
  theme_minimal() +
  theme(legend.position = "top")
```

---

# Slide 6: Geographic Reality - UN Handbook F.98

### UN Statistics Division Guidelines

.pull-left[
```{r geography-demo, echo=TRUE}
# UN Handbook F.98 Table 4.1 adapted
ea_distribution <- tibble(
  UN_Category = c("Urban-Dense", 
                  "Urban-Sparse",
                  "Rural-Accessible", 
                  "Rural-Remote"),
  EAs = c(450, 320, 1200, 280),
  Distance_km = c(5, 25, 85, 240),
  UN_Weight = c(1.0, 1.5, 2.5, 5.0)
)

# Apply UN cost multipliers
ea_distribution %>%
  mutate(
    Cost_Factor = Distance_km/10,
    Eurostat_Class = c("1", "2", "3", "3")
  ) %>%
  kable(format = "html")
```
]

.pull-right[
**UN Handbook F.98 Para 4.23:**
"Simple random sampling becomes prohibitively expensive when geographic dispersion exceeds Category 2"

**Eurostat Doc 65/2023:**
"Cluster sampling mandatory for areas classified as DEGURBA level 3"
]

---

# Slide 7: Calculate Cost Using World Bank Formula

### LSMS Manual Equation 3.14

```{r srs-cost-exercise, echo=TRUE}
# World Bank LSMS cost formula (Manual Ch.3)
n_interviews <- 3000
distribution <- c(0.35, 0.25, 0.30, 0.10)  # WB standard urban/rural split

# Cost parameters from LSMS Annex 3A
c_0 <- 50000  # Fixed costs (WB standard)
c_1 <- c(20, 45, 120, 350)  # Travel costs by area
c_2 <- 25  # Interview cost (WB benchmark)

# Apply LSMS formula 3.14
srs_sample <- round(n_interviews * distribution)
total_cost <- c_0 + sum(srs_sample * c_1) + n_interviews * c_2

print(paste("Total using WB formula: $", format(total_cost, big.mark=",")))
print(paste("Exceeds WB threshold by:", round((total_cost/200000-1)*100), "%"))
```

---

# Slide 8: Response Rate - Eurostat Standards

### EU-SILC Quality Thresholds

```{r response-catastrophe, echo=FALSE, fig.height=5}
set.seed(2024)
days <- 1:30
response_data <- tibble(
  Day = rep(days, 2),
  Design = rep(c("SRS", "Eurostat Compliant"), each = 30),
  Cumulative_RR = c(
    100 * (1 - exp(-days/10)) * exp(-days/25),
    100 * (1 - exp(-days/8)) * 0.85
  )
)

ggplot(response_data, aes(x = Day, y = Cumulative_RR, color = Design)) +
  geom_line(size = 1.5) +
  scale_color_manual(values = c("SRS" = "#FF6B6B", "Eurostat Compliant" = eurostat_blue)) +
  geom_hline(yintercept = 70, linetype = "dashed", alpha = 0.5) +
  geom_hline(yintercept = 60, linetype = "dashed", color = "red", alpha = 0.5) +
  annotate("text", x = 25, y = 72, label = "Eurostat minimum", size = 3) +
  annotate("text", x = 25, y = 62, label = "Eurostat threshold", size = 3, color = "red") +
  labs(title = "Response Rates: SRS vs Eurostat-Compliant Design",
       subtitle = "Source: EU-SILC Quality Guidelines Doc 65/2023 Section 7.2",
       y = "Cumulative Response Rate (%)", x = "Days in Field") +
  theme_minimal() +
  theme(legend.position = "top")
```

---

# Slide 9: First Success Using OECD Standards

### 2003 - Following PIAAC Guidelines

.pull-left[
**The Challenge:**
- Post-crisis survey
- OECD technical assistance
- Must meet PIAAC standards

**OECD Requirements:**
- CV < 5% (PIAAC Standard 4.2)
- Response > 70% (Standard 7.1)
- Coverage > 95% (Standard 3.3)
- Documentation per Annex B
]

.pull-right[
**Solution per OECD Manual:**
- Two-stage design (Ch.4)
- PPS selection (Formula 4.8)
- Optimal allocation (Table 4.3)
- Result: All standards met

**Minister's Response:**
"Finally, international compliance!"

**Key:** OECD Technical Standards for International Surveys (2019 Edition)
]

---

# Slide 10: Core Mathematics from International Standards

### Formulas You Must Know

.formula-box[
**World Bank LSMS (Manual 3.7):**
$$C = c_0 + c_1m + c_2mn$$

**Eurostat EU-SILC (Doc 65, Eq 4.1):**
$$DEFF = \frac{Var_{complex}(\bar{y})}{Var_{SRS}(\bar{y})}$$

**UN Handbook F.98 (Formula 5.12):**
$$n_{eff} = \frac{n}{DEFF}$$
]

"These three formulas appear in ALL international standards"

---

# Slide 11: International Standards Timeline

```{r standards-map, echo=FALSE, fig.height=5}
standards_data <- tibble(
  Organization = c("World Bank", "Eurostat", "OECD", "UN Stats", "WHO", "ILO"),
  Standard = c("LSMS", "EU-SILC", "PIAAC", "NHSCP", "WHS", "LFS"),
  Year = c(1985, 2003, 2008, 1984, 2000, 1990),
  Latest = c(2024, 2023, 2022, 2022, 2021, 2023),
  Countries = c(45, 34, 38, 189, 70, 120)
)

ggplot(standards_data, aes(x = Year, y = Countries, size = 2024-Year)) +
  geom_point(aes(color = Organization), alpha = 0.7) +
  geom_text(aes(label = Standard), vjust = -1.5, size = 3) +
  scale_color_manual(values = c("World Bank" = wb_blue, "Eurostat" = eurostat_blue,
                                "OECD" = oecd_blue, "UN Stats" = un_blue,
                                "WHO" = "#00a86b", "ILO" = "#FF6B6B")) +
  labs(title = "Evolution of International Survey Standards",
       subtitle = "All require complex designs for efficiency",
       x = "Year Introduced", y = "Countries Using Standard") +
  theme_minimal() +
  theme(legend.position = "right", legend.title = element_blank())
```

---

# Slide 12: Cost Reality - World Bank Benchmarks

### LSMS Cost Database 2023

.pull-left[
```{r actual-costs, echo=TRUE}
# World Bank LSMS cost benchmarks
# Source: LSMS Guidebook Annex 3A
cost_benchmark <- tibble(
  Item = c("Interviewer/day",
           "Vehicle/day",
           "Supervisor/day",
           "Rural supplement"),
  WB_Low = c(20, 60, 40, 10),
  WB_Med = c(35, 80, 55, 20),
  WB_High = c(50, 120, 75, 35)
)

cost_benchmark %>%
  kable(format = "html",
        caption = "USD - World Bank LSMS Benchmarks 2023")
```
]

.pull-right[
**World Bank Rule (LSMS 3.2.4):**
"Design for 70% of allocated budget"

**Eurostat Guideline (Doc 65):**
"Reserve 20-30% contingency"

**OECD Standard (PIAAC 8.2):**
"Document all cost assumptions"
]

---

# Slide 13: Frame Coverage - UN Requirements

### UN Handbook F.98 Chapter 3

```{r frame-coverage, echo=FALSE, fig.height=4.5}
coverage_data <- tibble(
  Years_Since_Census = 1:15,
  Coverage = 100 - (Years_Since_Census * 3.5) + rnorm(15, 0, 2)
) %>%
  mutate(Coverage = pmax(40, pmin(98, Coverage)))

ggplot(coverage_data, aes(x = Years_Since_Census, y = Coverage)) +
  geom_point(size = 3, color = un_blue) +
  geom_smooth(method = "lm", se = TRUE, color = "#FF6B6B") +
  geom_hline(yintercept = 95, linetype = "dashed", color = "darkgreen") +
  geom_hline(yintercept = 90, linetype = "dashed", color = "orange") +
  geom_hline(yintercept = 80, linetype = "dashed", color = "red") +
  annotate("text", x = 12, y = 96, label = "UN Standard", size = 3, color = "darkgreen") +
  annotate("text", x = 12, y = 91, label = "WB Minimum", size = 3, color = "orange") +
  annotate("text", x = 12, y = 81, label = "Eurostat Alert", size = 3, color = "red") +
  labs(title = "Frame Deterioration vs International Standards",
       subtitle = "UN Handbook F.98 Section 3.4.2",
       x = "Years Since Census", y = "Coverage (%)") +
  theme_minimal()
```

---

# Slide 14: Interviewer Productivity - ILO Standards

### ILO Labour Force Survey Manual

.pull-left[
**ILO Productivity Benchmarks:**
- Urban dense: 4-6 interviews
- Urban sparse: 3-4 interviews
- Rural accessible: 2-3 interviews
- Rural remote: 1-2 interviews

Source: ILO Manual Chapter 9
]

.pull-right[
```{r interviewer-productivity, echo=TRUE}
# ILO productivity standards
productivity <- tibble(
  Area_Type = c("Urban_Dense", 
                "Urban_Sparse",
                "Rural_Access", 
                "Rural_Remote"),
  ILO_Standard = c(5, 3.5, 2.5, 1.5),
  With_Clustering = c(8, 6, 5, 4)
) %>%
  mutate(
    Improvement = round(With_Clustering / 
                       ILO_Standard, 1)
  )

productivity %>%
  kable(format = "html",
        caption = "Daily interviews per ILO")
```
]

---

# Slide 15: Quality-Cost Trade-off - OECD Framework

### PIAAC Technical Standards Chapter 6

```{r quality-cost, echo=FALSE, fig.height=4.5}
sample_sizes <- seq(500, 10000, by = 200)
quality_cost <- tibble(
  Sample_Size = sample_sizes,
  SRS_Cost = 50000 + sample_sizes * 180,
  OECD_Cost = 80000 + sample_sizes * 65,
  SRS_CV = sqrt(1/sample_sizes) * 100,
  OECD_CV = sqrt(1.8/sample_sizes) * 100
) %>%
  pivot_longer(cols = -Sample_Size,
               names_to = c("Design", "Measure"),
               names_sep = "_") %>%
  pivot_wider(names_from = Measure, values_from = value)

ggplot(quality_cost, aes(x = Cost/1000, y = CV, color = Design)) +
  geom_line(size = 1.5) +
  scale_color_manual(values = c("SRS" = "#FF6B6B", "OECD" = oecd_blue)) +
  scale_x_continuous(labels = function(x) paste0("$", x, "k")) +
  geom_hline(yintercept = 3, linetype = "dashed") +
  geom_vline(xintercept = 250, linetype = "dashed") +
  annotate("text", x = 255, y = 8, label = "OECD Budget Limit", angle = 90, size = 3) +
  annotate("text", x = 450, y = 3.2, label = "OECD CV Target", size = 3) +
  labs(title = "OECD Efficiency Frontier (PIAAC Standard 6.3)",
       x = "Total Cost", y = "CV (%)") +
  theme_minimal() +
  theme(legend.position = "top")
```

---

# Slide 16: Assessment Against Standards

### Quick Check: Meeting International Requirements?

```{r standards-check, echo=FALSE, fig.height=4}
standards_compliance <- tibble(
  Standard = c("WB LSMS", "Eurostat", "OECD PIAAC", "UN NHSCP"),
  Coverage = c(95, 95, 95, 95),
  Response = c(70, 70, 70, 65),
  CV_Target = c(5, 3, 3, 5),
  Documentation = c("Full", "44 pages", "Annex B", "Chapter 9")
)

kable(standards_compliance, 
      caption = "Minimum Requirements by Standard",
      format = "html")
```

**Key Message:** "Different standards, similar requirements"

---

# Slide 17: Stratification - World Bank's Foundation

### LSMS Manual Chapter 4

.pull-left[
**World Bank Three-Layer Rule:**

1. **Geographic (LSMS 4.2.1)**
   - Administrative boundaries
   - Natural regions
   
2. **Urban/Rural (LSMS 4.2.2)**
   - Different operations
   - Cost differentials
   
3. **Socioeconomic (LSMS 4.2.3)**
   - If frame available
   - Maximum 3 variables
]

.pull-right[
```{r strat-impact, echo=TRUE}
# World Bank impact assessment
# LSMS Technical Paper 126, Table 4.3

impact <- tibble(
  Stratification = c("None", 
                    "Geographic", 
                    "Geo + Urban/Rural",
                    "Full WB Design"),
  Variance_Reduction = c(0, 25, 42, 48),
  Cost_Increase = c(0, 5, 8, 12)
)

impact %>%
  kable(format = "html",
        caption = "WB LSMS Evidence")
```
]

---

# Slide 18: Neyman Allocation - Eurostat Standard

### EU-SILC Doc 65 Formula 4.8

.formula-box[
$$n_h = n \cdot \frac{N_h S_h}{\sum_{k=1}^L N_k S_k}$$

"Eurostat mandates Neyman or better for all EU surveys"
]

```{r neyman-eurostat, echo=FALSE, fig.height=3.5}
# Eurostat allocation comparison
strata_demo <- tibble(
  Stratum = c("Capital", "Other Urban", "Rural North", "Rural South"),
  Eurostat_Weight = c(0.35, 0.30, 0.20, 0.15)
) %>%
  mutate(
    Equal = 25,
    Proportional = Eurostat_Weight * 100,
    Neyman = c(38, 28, 22, 12)
  ) %>%
  pivot_longer(cols = c(Equal, Proportional, Neyman),
               names_to = "Method", values_to = "Allocation")

ggplot(strata_demo, aes(x = Stratum, y = Allocation, fill = Method)) +
  geom_col(position = "dodge", alpha = 0.8) +
  scale_fill_manual(values = c("Equal" = "#FF6B6B", 
                               "Proportional" = "#FFA500",
                               "Neyman" = eurostat_blue)) +
  labs(title = "Eurostat Mandated Allocation Methods", y = "% of Sample") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1),
        legend.position = "top")
```

---

# Slide 19: Cost-Optimal - OECD Enhancement

### PIAAC Technical Standard 4.5

```{r cost-optimal-oecd, echo=TRUE}
# OECD cost-optimal formula (PIAAC Manual Eq 4.12)
strata <- tibble(
  Stratum = c("Urban_Core", "Urban_Other", "Rural"),
  N = c(2e6, 3e6, 5e6),  # Population
  S = c(45000, 35000, 20000),  # Std deviation
  C = c(40, 60, 110)  # OECD cost factors
)

n_total <- 3000  # OECD standard sample
strata <- strata %>%
  mutate(
    # OECD formula
    NS_sqrtC = N * S / sqrt(C),
    n_optimal = round(NS_sqrtC / sum(NS_sqrtC) * n_total),
    cost_total = n_optimal * C
  )

strata %>% select(Stratum, n_optimal, cost_total) %>%
  kable(caption = "OECD Cost-Optimal Design")
```

---

# Slide 20: UN Domain Requirements

### UN Handbook F.98 Section 4.7

```{r un-domains, echo=TRUE}
# UN minimum domain sizes (Handbook Table 4.5)
un_domains <- tibble(
  Domain = c("National", "Urban", "Rural", 
             "Each Region", "Gender_Age"),
  UN_Minimum = c(1500, 500, 500, 200, 100),
  For_CV = c("2%", "3%", "3%", "5%", "10%"),
  Reference = c("F.98 4.7.1", "F.98 4.7.2", "F.98 4.7.2",
                "F.98 4.7.3", "F.98 4.7.4")
)

un_domains %>%
  kable(format = "html",
        caption = "UN Statistical Division Requirements")
```

**Critical:** "Never go below UN minimums"

---

# Slide 21: Exercise - Apply International Standards

### Design Following Multiple Standards

```{r exercise-international, echo=TRUE}
# Your country must meet:
# - World Bank LSMS efficiency
# - Eurostat quality thresholds  
# - UN domain requirements
# - OECD documentation

country_data <- tibble(
  Region = c("North", "Central", "South"),
  Population = c(3.2e6, 4.1e6, 2.8e6),
  Urban_Pct = c(45, 62, 38)
)

# Apply WB stratification (geographic + urban/rural)
# Check against Eurostat minimums (50 per stratum)
# Verify UN domain requirements
# Document per OECD Annex B

print("Design your allocation - see module1_exercise.R")
```

---

# Slide 22: Clustering - World Bank Economics

### LSMS Manual Chapter 5

.pull-left[
**Without Clusters (violates WB):**
- Travel: 80% of budget
- Supervision: Impossible
- Quality: Uncontrolled

**With WB Clustering:**
- Travel: 30% of budget
- Supervision: Feasible
- Quality: Monitored
]

.pull-right[
**World Bank Formula 5.3:**
$$C = c_0 + c_1m + c_2m\bar{n}$$

Where (LSMS definitions):
- $c_0$ = fixed costs
- $c_1$ = cost per PSU
- $c_2$ = cost per unit
- $m$ = number PSUs
- $\bar{n}$ = units per PSU
]

---

# Slide 23: ICC - Eurostat Guidelines

### EU-SILC Doc 65 Section 5.2

.formula-box[
$$\rho = \frac{\sigma^2_b}{\sigma^2_b + \sigma^2_w}$$

"Eurostat typical ICC values: 0.01 to 0.20"
]

```{r icc-eurostat, echo=TRUE}
# Eurostat ICC benchmarks (Doc 65 Table 5.1)
eurostat_icc <- tibble(
  Variable = c("Income", "Employment", "Health", "Education"),
  EU_Urban = c(0.06, 0.08, 0.05, 0.12),
  EU_Rural = c(0.04, 0.06, 0.07, 0.15),
  Source = "EU-SILC 2023"
)

eurostat_icc %>%
  kable(caption = "Eurostat ICC Reference Values")
```

---

# Slide 24: Design Effect - OECD Formula

### PIAAC Standard 5.4

```{r deff-oecd, echo=FALSE, fig.height=4}
# OECD design effect curves
cluster_sizes <- seq(5, 50, by = 5)
icc_values <- c(0.02, 0.05, 0.10, 0.15)  # OECD typical values

deff_grid <- expand.grid(
  b = cluster_sizes,
  rho = icc_values
) %>%
  mutate(
    DEFF = 1 + (b - 1) * rho,
    ICC_Label = paste("ICC =", rho)
  )

ggplot(deff_grid, aes(x = b, y = DEFF, color = as.factor(rho))) +
  geom_line(size = 1.2) +
  geom_hline(yintercept = 2, linetype = "dashed", alpha = 0.5) +
  geom_hline(yintercept = 1.5, linetype = "dashed", color = "green", alpha = 0.5) +
  scale_color_manual(values = c("#2E7D32", "#1976D2", "#F57C00", "#C62828"),
                     name = "OECD ICC") +
  annotate("text", x = 45, y = 2.1, label = "OECD limit", size = 3) +
  annotate("text", x = 45, y = 1.6, label = "OECD target", size = 3, color = "green") +
  labs(title = "OECD Design Effect Guidelines (PIAAC 5.4)",
       x = "Cluster Size", y = "Design Effect") +
  theme_minimal() +
  theme(legend.position = "right")
```

---

# Slide 25: Optimal Cluster Size - UN Method

### UN Handbook F.98 Formula 5.18

.pull-left[
**UN Optimization Formula:**
$$b_{opt} = \sqrt{\frac{c_1(1-\rho)}{c_2\rho}}$$

Applied by context:
- Urban: 10-15 (UN 5.4.2)
- Rural: 15-25 (UN 5.4.3)
- Remote: 20-30 (UN 5.4.4)
]

.pull-right[
```{r cluster-un, echo=TRUE}
# UN Handbook calculation
optimize_un <- function(c1, c2, rho) {
  sqrt((c1 * (1 - rho)) / (c2 * rho))
}

# UN standard parameters
scenarios <- tibble(
  Type = c("Urban", "Rural", "Remote"),
  c1 = c(100, 300, 800),  # UN Table 5.3
  c2 = c(25, 25, 25),
  rho = c(0.10, 0.06, 0.03)
) %>%
  mutate(
    Optimal = round(map_dbl(1:n(), 
      ~optimize_un(c1[.], c2[.], rho[.]))
    )
  )

kable(scenarios)
```
]

---

# Slide 26: PPS - World Bank Standard

### LSMS Manual Section 5.5

.formula-box[
$$P(PSU_i) = \frac{n \cdot M_i}{M}$$
World Bank: "PPS is mandatory for varying PSU sizes"
]

```{r pps-wb, echo=TRUE}
# World Bank PPS procedure (LSMS 5.5.3)
psu_frame <- tibble(
  PSU = 1:8,
  Size = c(180, 95, 220, 150, 110, 195, 85, 165)
) %>%
  mutate(
    Cumulative = cumsum(Size),
    Prob = Size / sum(Size)
  )

# WB systematic PPS
n_select <- 3
interval <- sum(psu_frame$Size) / n_select
print(paste("WB interval:", round(interval)))
```

---

# Slide 27: Quality Checks - Eurostat Requirements

### EU-SILC Quality Report Template

```{r quality-eurostat, echo=FALSE}
eurostat_checks <- tibble(
  Component = c("Coverage", "Sampling Error", "Non-Response",
                "Processing Error", "Model Assumptions"),
  Required = c("Yes", "Yes", "Yes", "Yes", "If applicable"),
  Standard = c(">95%", "CV<3%", ">70%", "<2%", "Document"),
  Reference = c("Doc 65 3.1", "Doc 65 4.2", "Doc 65 7.1",
                "Doc 65 8.3", "Doc 65 9.1")
)

kable(eurostat_checks, 
      caption = "Eurostat Quality Framework",
      format = "html")
```

**Mandatory:** "44-page quality report per Doc 65 Annex D"

---

# Slide 28: Multi-Stage - WHO STEPS Approach

### WHO STEPS Manual Version 3.2

```{r who-steps, echo=TRUE}
# WHO three-stage design (STEPS Section 2)
who_design <- tibble(
  Stage = 1:3,
  WHO_Unit = c("Districts/Regions", "EAs/Clusters", "Households"),
  Selection = c("PPS or All", "PPS", "Simple Random"),
  Typical_n = c("All or 20-30", "150-250", "20-30 per EA")
)

who_design %>%
  kable(caption = "WHO STEPS Standard Design")
```

**WHO Requirement:** "Minimum 3 stages for national surveys"

---

# Slide 29: Weight Components - ILO Framework

### ILO Manual Chapter 11

.formula-box[
$$w_{final} = w_{design} \times w_{nr} \times w_{cal}$$

ILO Labour Force Survey Formula 11.2
]

```{r weights-ilo, echo=TRUE}
# ILO weight components
ilo_weights <- tibble(
  Component = c("Base/Design", "Non-response", 
                "Calibration", "Trimming"),
  ILO_Rule = c("Always", "Always", "Recommended", "If needed"),
  Typical_Range = c("10-1000", "1.0-2.0", "0.8-1.3", "Applied at 99%")
)

ilo_weights %>%
  kable(caption = "ILO Weight Construction")
```

---

# Slide 30: Frame Problems - UN Assessment

### UN Statistical Division Technical Report

```{r frame-un, echo=FALSE, fig.height=4}
frame_issues <- tibble(
  Issue = c("Outdated", "Incomplete", "Duplicates", 
           "Missing Areas", "Classification"),
  UN_Prevalence = c(92, 76, 54, 68, 45),
  Impact = c("High", "High", "Medium", "High", "Medium")
) %>%
  arrange(desc(UN_Prevalence))

ggplot(frame_issues, aes(x = reorder(Issue, UN_Prevalence), y = UN_Prevalence)) +
  geom_col(fill = un_blue, alpha = 0.8) +
  geom_text(aes(label = paste0(UN_Prevalence, "%")), vjust = -0.5) +
  coord_flip() +
  labs(title = "Frame Problems: UN Global Assessment 2023",
       subtitle = "UN Statistical Division Technical Report 2023/1",
       y = "% of Countries Affected", x = "") +
  theme_minimal()
```

---

# Slide 31: Multi-Frame - Eurostat Innovation

### EU-SILC Regulation 2019/1700

```{r multiframe-eurostat, echo=TRUE}
# Eurostat dual frame approach
frame_A <- tibble(
  Frame = "Census_2020",
  Coverage = 0.72,
  Quality = "High",
  Cost_Factor = 1.0
)

frame_B <- tibble(
  Frame = "Admin_Register_2024",
  Coverage = 0.88,
  Quality = "Medium",
  Cost_Factor = 0.5
)

# Eurostat combination formula
overlap <- 0.65
combined_coverage <- 0.72 + 0.88 - 0.65
print(paste("Eurostat combined coverage:", percent(combined_coverage)))
```

---

# Slide 32: Response Crisis - OECD Evidence

### PIAAC Round 3 Results

```{r response-oecd, echo=FALSE, fig.height=4}
years <- 2010:2024
response_trends <- expand.grid(
  Year = years,
  Category = c("OECD Metro", "OECD Other Urban", "OECD Rural")
) %>%
  mutate(
    Response_Rate = case_when(
      Category == "OECD Metro" ~ 85 - (Year - 2010) * 2.5,
      Category == "OECD Other Urban" ~ 88 - (Year - 2010) * 1.8,
      Category == "OECD Rural" ~ 92 - (Year - 2010) * 1.0
    ) + rnorm(n(), 0, 1)
  )

ggplot(response_trends, aes(x = Year, y = Response_Rate, color = Category)) +
  geom_line(size = 1.2) +
  geom_point(size = 2) +
  scale_color_manual(values = c("OECD Metro" = "#FF6B6B",
                               "OECD Other Urban" = "#FFA500",
                               "OECD Rural" = oecd_blue)) +
  geom_hline(yintercept = 70, linetype = "dashed", color = "red") +
  annotate("text", x = 2017, y = 72, label = "OECD minimum", color = "red", size = 3) +
  labs(title = "Response Rate Decline: OECD Countries 2010-2024",
       subtitle = "Source: PIAAC Technical Report 2024",
       y = "Response Rate (%)") +
  theme_minimal() +
  theme(legend.position = "top")
```

# Slide 33: Response Adjustment - World Bank Method

### LSMS Manual Section 7.3

```{r nr-adjustment-wb, echo=TRUE}
# World Bank non-response adjustment
wb_strata <- tibble(
  Stratum = c("Urban_High", "Urban_Low", "Rural"),
  Sampled = c(500, 600, 400),
  Responded = c(225, 420, 340)
) %>%
  mutate(
    RR = Responded / Sampled,
    WB_Adjustment = 1 / RR,  # LSMS Formula 7.3
    Check = Responded * WB_Adjustment
  )

wb_strata %>%
  mutate(RR = percent(RR, 0.1)) %>%
  kable(caption = "World Bank LSMS Adjustment")
```

---

# Slide 34: Calibration - UN Standards

### UN Handbook F.98 Chapter 6

```{r calibration-un, echo=TRUE}
# UN calibration procedure (F.98 6.4)
un_totals <- list(
  Population = 10000000,
  Urban = 5200000,
  Male = 4900000,
  Employed = 6200000
)

current_weighted <- list(
  Population = 9750000,
  Urban = 4950000,
  Male = 4820000,
  Employed = 5980000
)

# UN ratio calibration
cal_factors <- mapply(`/`, un_totals, current_weighted)
print(round(cal_factors, 4))
```

---

# Slide 35: Special Populations - WHO Framework

### WHO STEPS Manual Annex 7

.pull-left[
**WHO Categories:**
- Nomadic/pastoralist
- Urban homeless
- Institutional
- Refugee/IDP
- Island populations
- Conflict zones

"Standard methods fail"
]

.pull-right[
**WHO Solutions:**

1. **Time-Location** (TLS)
   - Map service points
   - Sample time × location

2. **Respondent-Driven** (RDS)
   - Peer referral chains
   - Markov adjustment

Reference: WHO Technical Note 2021/3
]

---

# Slide 36: Crisis Protocol - Eurostat

### EU-SILC Crisis Management Guide

**Eurostat Crisis Categories:**
- Natural disaster during fieldwork
- Political instability
- Pandemic restrictions
- Budget cuts
- Frame destruction

**Standard Response (Doc 65 Annex E):**
1. Document immediately
2. Contact Eurostat unit
3. Apply standard adjustments
4. Submit deviation report

---

# Slide 37: Documentation - OECD Template

### PIAAC Technical Standards Annex B

```{r documentation-oecd, echo=TRUE}
# OECD required documentation
oecd_docs <- tibble(
  Section = c("Target Population", "Frame Coverage",
              "Sample Design", "Weighting",
              "Variance Estimation", "Quality Measures"),
  OECD_Pages = c(3, 5, 10, 8, 6, 4),
  Due = c("Design", "Design", "Design", 
          "Post-field", "Post-field", "Final")
)

oecd_docs %>%
  kable(caption = "OECD Documentation Requirements")
```

**Total: 36 pages minimum**

---

# Slide 38: Software Standards

### International Organization Preferences

.pull-left[
**World Bank:**
- Stata (primary)
- R (increasing)
- CSPro (collection)

**Eurostat:**
- R (recommended)
- SAS (legacy)
- Blaise (collection)
]

.pull-right[
```{r software-standards, echo=TRUE}
# Usage by organization (2023)
software_use <- tibble(
  Tool = c("R", "Stata", "SPSS", "SAS"),
  WB = c(45, 72, 15, 8),
  Eurostat = c(65, 25, 20, 40),
  OECD = c(55, 50, 30, 35)
)

software_use %>%
  kable(caption = "% using each tool")
```
]

---

# Slide 39: Budget Framework - World Bank

### LSMS Budget Guidelines

```{r budget-wb, echo=FALSE, fig.height=4}
budget_items <- tibble(
  Category = c("Staff", "Travel", "Training", "Equipment", 
              "Contingency", "Other"),
  WB_Target = c(40, 25, 8, 10, 15, 2),
  WB_Range = c("35-45", "20-30", "5-10", "8-15", "10-20", "1-5")
)

ggplot(budget_items, aes(x = Category, y = WB_Target)) +
  geom_col(fill = wb_blue, alpha = 0.8) +
  geom_errorbar(aes(ymin = c(35,20,5,8,10,1), 
                    ymax = c(45,30,10,15,20,5)), 
                width = 0.3) +
  labs(title = "World Bank LSMS Budget Allocation Standards",
       y = "% of Total Budget") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

---

# Slide 40: Common Violations

### Never Do These (Per All Standards)

❌ **Violate minimum domain sizes** (UN)
❌ **Skip non-response adjustment** (WB)
❌ **Ignore quality thresholds** (Eurostat)
❌ **Underdocument** (OECD)
❌ **Use outdated frames** (All)
❌ **Promise impossible timelines** (All)

"I've seen each violation cause project failure"

---

# Slide 41: Success Metrics - Integrated

### Meeting All International Standards

```{r success-integrated, echo=TRUE}
# Integrated success criteria
success_criteria <- tibble(
  Metric = c("Coverage", "Response Rate", "CV",
             "Documentation", "Timeline"),
  World_Bank = c("≥95%", "≥70%", "≤5%", "Full", "±15%"),
  Eurostat = c("≥95%", "≥70%", "≤3%", "44 pages", "±10%"),
  OECD = c("≥95%", "≥70%", "≤3%", "Annex B", "On time"),
  UN = c("≥95%", "≥65%", "≤5%", "Chapter 9", "±20%")
)

success_criteria %>%
  kable(caption = "Harmonized Standards")
```

---

# Slide 42: Country Success Stories

### Anonymous Examples Following Standards

**Country X (Small Island):**
- Challenge: 7 islands, limited budget
- Solution: WHO STEPS design
- Result: Met all WHO standards

**Country Y (Post-conflict):**
- Challenge: No census 15 years
- Solution: UN emergency protocol
- Result: 89% coverage achieved

**Country Z (Rapid growth):**
- Challenge: 30% population increase
- Solution: Eurostat dual frame
- Result: EU-SILC compliant

---

# Slide 43: Interactive Design Exercise

### Apply Multiple Standards

.practice-box[
**Scenario:** Design meeting ALL standards
- Population: 12 million
- Budget: $1.5 million
- Timeline: 4 months
- Must comply with: WB, Eurostat, UN
]

Requirements:
- WB efficiency ratio
- Eurostat quality thresholds
- UN domain minima
- OECD documentation

---

# Slide 44: Variance Formula - Eurostat

### EU-SILC Technical Document

.formula-box[
$$V(\hat{Y}) = \sum_{h=1}^L \left(1 - f_h\right) \frac{n_h}{n_h - 1} \sum_{i=1}^{n_h} (y_{hi} - \bar{y}_h)^2$$

Eurostat Doc 65 Formula 8.1
]

**Plus corrections for:**
- Clustering (Formula 8.2)
- Weighting (Formula 8.3)
- Calibration (Formula 8.4)

---

# Slide 45: R Implementation - Survey Package

### Following International Standards

```{r r-demo, echo=TRUE, eval=FALSE}
# R survey package - meets all international standards
library(survey)

# Define design per Eurostat/WB/OECD standards
design <- svydesign(
  ids = ~psu_id,           # PSU identifier (WB LSMS 5.2)
  strata = ~stratum,       # Stratification (Eurostat 4.1)
  weights = ~final_weight, # Weights (UN F.98 Ch.6)
  data = survey_data,      # Your data
  nest = TRUE             # Nested PSUs (OECD 4.3)
)

# Calculate per international standards
svymean(~income, design, deff = TRUE)  # With DEFF
svyby(~income, ~region, design, svymean)  # Domains
```

---

# Slide 46: Field Reality - ILO Experience

### Daily Completion Patterns

```{r field-reality, echo=FALSE, fig.height=4}
days <- 1:30
daily_complete <- tibble(
  Day = rep(days, 2),
  Type = rep(c("ILO Plan", "Actual"), each = 30),
  Interviews = c(
    rep(100, 30),  # ILO planned
    c(20, 35, 45, 60, 75, 82, 85, 40, 45, 88, 
      92, 95, 98, 100, 60, 70, 95, 102, 105, 108,
      110, 95, 98, 103, 108, 112, 115, 118, 120, 122)
  )
)

ggplot(daily_complete, aes(x = Day, y = Interviews, color = Type)) +
  geom_line(size = 1.2) +
  scale_color_manual(values = c("ILO Plan" = "#FFA500", "Actual" = "#FF6B6B")) +
  labs(title = "ILO Labour Force Survey: Plan vs Reality",
       subtitle = "Source: ILO Manual Chapter 12",
       y = "Daily Interviews") +
  theme_minimal() +
  theme(legend.position = "top")
```

---

# Slide 47: Quality Control - UN System

### UN Handbook F.98 Chapter 8

```{r quality-control-un, echo=TRUE}
# UN quality control requirements
un_quality <- tibble(
  Check = c("Completeness", "Consistency", 
            "Outliers", "Response Rate",
            "Coverage", "Precision"),
  UN_Frequency = c("Daily", "Daily", "Weekly", 
                   "Weekly", "Monthly", "Final"),
  UN_Standard = c("≥98%", "≥95%", "≤2%", 
                  "≥65%", "≥90%", "Per design")
)

un_quality %>%
  kable(caption = "UN Quality Monitoring Framework")
```

---

# Slide 48: Lessons from International Failures

### What Harry Learned from Each Standard

**World Bank:** Budget realism crucial
**Eurostat:** Documentation not optional  
**OECD:** Testing prevents disasters
**UN:** Domains drive design
**WHO:** Special populations need special methods
**ILO:** Field reality differs from plan

"Each failure taught invaluable lessons"

---

# Slide 49: Your Compliance Checklist

### After Module 1

✅ Understand WB LSMS cost principles
✅ Apply Eurostat quality standards
✅ Follow OECD documentation requirements
✅ Meet UN domain specifications
✅ Implement WHO special methods
✅ Use ILO operational guidelines

"You now have the international foundation!"

---

# Slide 50: Module 1 Complete!

### Key International Standards Mastered

1. **World Bank LSMS** efficiency framework
2. **Eurostat EU-SILC** quality requirements
3. **OECD PIAAC** technical standards
4. **UN Handbook F.98** specifications
5. **WHO STEPS** for special populations
6. **ILO** operational guidelines

.practice-box[
**Break Time**

Next: Module 2 - Deep Dive into Stratification
Following Eurostat Doc 65 Chapter 4
]

---

class: inverse, center, middle

# End of Module 1
## International Standards Foundation Complete

### "Every successful survey follows these standards"

---

class: inverse, center, middle

# Module 2: Stratification Mastery
## 9:00 AM - Deep Dive into Variance Reduction
### 50 Slides Following Eurostat Doc 65 Chapter 4

---

# Slide 51: Module 2 - Stratification Excellence

### 9:00 AM - Harry's Office Continues

"Now we dive deep into stratification. Every technique follows Eurostat Doc 65, World Bank LSMS Chapter 4, and UN Handbook F.98 Section 4."

**This Module's Journey:**
- Eurostat stratification requirements
- World Bank allocation methods
- OECD optimization techniques
- UN domain specifications
- Real country applications

---

# Slide 52: The Perfect Stratification Story

### 2010 - Following Eurostat Standards

"Country in Middle East. We followed Eurostat Doc 65 to the letter. Results were exceptional."

**Eurostat Compliance:**
- Geographic stratification (Doc 65 4.1)
- Urban/rural split (Doc 65 4.2)
- Socioeconomic layer (Doc 65 4.3)
- Minimum stratum sizes (Doc 65 4.4)

**Results:** CV reduced from 5.2% to 2.1%

---

# Slide 53: Why Stratification Works - Theory

### Eurostat Doc 65 Section 4.1

.formula-box[
**Variance Decomposition (Eurostat 4.1.2):**
$V_{total} = V_{between} + V_{within}$

**After Stratification (Eurostat 4.1.3):**
$V_{strat} = \sum_{h=1}^L W_h^2 \frac{S_h^2}{n_h}$
]

"Stratification eliminates between-stratum variance completely"

---

# Slide 54: World Bank Three-Layer System

### LSMS Manual Section 4.2

```{r wb-stratification, echo=TRUE}
# World Bank standard stratification hierarchy
wb_strata <- tibble(
  Layer = c("Geographic", "Urban/Rural", "Socioeconomic"),
  WB_Priority = c("Mandatory", "Mandatory", "Optional"),
  Variance_Gain = c("20-30%", "15-25%", "5-10%"),
  Reference = c("LSMS 4.2.1", "LSMS 4.2.2", "LSMS 4.2.3")
)

wb_strata %>%
  kable(caption = "World Bank Stratification Framework")
```

---

# Slide 55: Geographic Stratification - UN Standard

### UN Handbook F.98 Para 4.15

.pull-left[
**UN Geographic Principles:**
- Use administrative boundaries
- Ensure contiguity
- Respect cultural regions
- Consider accessibility

"Geography determines operations"
]

.pull-right[
```{r geographic-un, echo=TRUE}
# UN standard geographic strata
regions <- tibble(
  Region = c("North", "East", "South", 
             "West", "Central"),
  Population = c(2.1, 3.2, 2.8, 1.9, 2.0)*1e6,
  UN_Code = c("01", "02", "03", "04", "05")
)

regions %>%
  kable(caption = "UN Geographic Codes")
```
]

---

# Slide 56: Urban/Rural - Eurostat DEGURBA

### EU Regulation 2017/2391

```{r degurba, echo=TRUE}
# Eurostat DEGURBA classification
degurba <- tibble(
  Level = 1:3,
  Eurostat_Name = c("Cities", "Towns & Suburbs", "Rural"),
  Density = c("≥1,500/km²", "300-1,499/km²", "<300/km²"),
  Population = c("≥50,000", "5,000-49,999", "<5,000")
)

degurba %>%
  kable(caption = "Eurostat DEGURBA Classification")
```

**Mandatory for all EU surveys since 2018**

---

# Slide 57: Neyman Allocation - Mathematical Foundation

### Eurostat Doc 65 Formula 4.8

.formula-box[
$n_h = n \cdot \frac{N_h S_h}{\sum_{k=1}^L N_k S_k}$

Where (Eurostat definitions):
- $n_h$ = sample in stratum h
- $N_h$ = population in stratum h  
- $S_h$ = standard deviation in h
- $n$ = total sample size
]

"Eurostat requires Neyman or better"

---

# Slide 58: Calculate Neyman - Eurostat Method

```{r neyman-calc, echo=TRUE}
# Eurostat calculation procedure (Doc 65 Example 4.1)
strata <- tibble(
  Stratum = c("Cities", "Towns", "Rural"),
  N_h = c(3e6, 4e6, 3e6),  # Population
  S_h = c(42000, 35000, 25000),  # Std deviation
  Eurostat_Code = c("1", "2", "3")
)

n_total <- 3000  # Eurostat standard

strata <- strata %>%
  mutate(
    NS = N_h * S_h,
    Weight = NS / sum(NS),
    n_neyman = round(Weight * n_total)
  )

strata %>% select(Stratum, n_neyman) %>%
  kable(caption = "Neyman Allocation per Eurostat")
```

---

# Slide 59: Cost-Optimal - OECD Enhancement

### PIAAC Technical Standard 4.5

.formula-box[
$n_h = n \cdot \frac{N_h S_h / \sqrt{C_h}}{\sum_{k=1}^L N_k S_k / \sqrt{C_k}}$

"OECD adds cost efficiency to Neyman"
]

---

# Slide 60: OECD Cost-Optimal Calculation

```{r cost-optimal-calc, echo=TRUE}
# OECD PIAAC formula (Technical Standard 4.5.2)
strata$Cost_EUR <- c(45, 60, 95)  # OECD cost factors

strata <- strata %>%
  mutate(
    NS_sqrt_C = N_h * S_h / sqrt(Cost_EUR),
    Weight_Cost = NS_sqrt_C / sum(NS_sqrt_C),
    n_cost_optimal = round(Weight_Cost * n_total)
  )

# Compare allocations
strata %>% 
  select(Stratum, n_neyman, n_cost_optimal, Cost_EUR) %>%
  kable(caption = "OECD Cost-Optimal vs Neyman")
```

---

# Slide 61: World Bank Minimum Constraints

### LSMS Manual Table 4.2

```{r wb-minimums, echo=TRUE}
# World Bank minimum sample sizes (LSMS 4.3.1)
wb_minimums <- tibble(
  Estimator = c("Mean", "Proportion", "Regression", "Complex Model"),
  WB_Minimum = c(30, 50, 100, 200),
  For_CV = c("10%", "10%", "10%", "5%"),
  Reference = c("LSMS 4.3.1", "LSMS 4.3.2", "LSMS 4.3.3", "LSMS 4.3.4")
)

wb_minimums %>%
  kable(caption = "World Bank Minimum Stratum Sizes")
```

**Critical:** "Never violate these minimums"

---

# Slide 62: Apply Minimums - UN Method

### UN Handbook F.98 Section 4.6

```{r apply-min, echo=TRUE}
# UN constraint application (F.98 4.6.2)
MIN_UN <- 50  # UN standard minimum

strata <- strata %>%
  mutate(
    n_constrained = pmax(n_cost_optimal, MIN_UN),
    Adjusted = n_constrained != n_cost_optimal
  )

# Show adjustments
strata %>% 
  select(Stratum, n_cost_optimal, n_constrained, Adjusted) %>%
  kable(caption = "UN Minimum Constraint Applied")
```

---

# Slide 63: Proportional Allocation - ILO Standard

### ILO Manual Section 4.5

```{r proportional-ilo, echo=TRUE}
# ILO proportional allocation (when S_h unknown)
strata_ilo <- tibble(
  Stratum = c("Employed", "Unemployed", "Inactive"),
  N_h = c(6e6, 0.5e6, 3.5e6)
) %>%
  mutate(
    Weight = N_h / sum(N_h),
    n_prop = round(Weight * 3000)
  )

strata_ilo %>%
  kable(caption = "ILO Proportional Allocation")
```

"Use when variance unknown"

---

# Slide 64: Allocation Comparison - All Methods

```{r compare-methods, echo=FALSE, fig.height=4}
comparison <- strata %>%
  mutate(
    Equal = 1000,
    Proportional = round((N_h/sum(N_h)) * 3000)
  ) %>%
  select(Stratum, Equal, Proportional, n_neyman, n_cost_optimal) %>%
  pivot_longer(-Stratum, names_to = "Method", values_to = "Sample")

ggplot(comparison, aes(x = Stratum, y = Sample, fill = Method)) +
  geom_col(position = "dodge", alpha = 0.8) +
  scale_fill_manual(values = c("Equal" = "#FF6B6B", 
                               "Proportional" = "#FFA500",
                               "n_neyman" = eurostat_blue, 
                               "n_cost_optimal" = oecd_blue)) +
  labs(title = "International Allocation Methods Compared",
       subtitle = "Equal (None), Proportional (ILO), Neyman (Eurostat), Cost-Optimal (OECD)") +
  theme_minimal() +
  theme(legend.position = "top")
```

---

# Slide 65: Power Allocation - WHO STEPS

### WHO STEPS Manual Section 2.4

```{r power-who, echo=TRUE}
# WHO power allocation for health indicators
who_strata <- tibble(
  Risk_Group = c("High_Risk", "Medium_Risk", "Low_Risk"),
  Prevalence = c(0.15, 0.35, 0.50),
  WHO_Weight = c(0.45, 0.35, 0.20)  # Over-sample high risk
) %>%
  mutate(
    n_WHO = round(WHO_Weight * 3000)
  )

who_strata %>%
  kable(caption = "WHO Risk-Based Allocation")
```

---

# Slide 66: Domain Requirements - UN Standards

### UN Handbook F.98 Table 4.8

```{r domains-un, echo=TRUE}
# UN domain specifications
un_domains <- tibble(
  Domain = c("National", "Urban", "Rural", "Region", "Gender×Age"),
  UN_Minimum = c(1500, 500, 500, 200, 100),
  For_Indicator = c("Poverty", "Employment", "Health", "Education", "Detail"),
  CV_Target = c("2%", "3%", "3%", "5%", "10%")
)

un_domains %>%
  kable(caption = "UN Domain Requirements")
```

---

# Slide 67: Implicit Stratification - Eurostat Innovation

### EU-SILC Technical Report 2023/2

```{r implicit-eurostat, echo=TRUE}
# Eurostat implicit stratification procedure
frame <- tibble(
  PSU = 1:100,
  Region = rep(c("North", "South", "East", "West", "Central"), each = 20),
  Size = sample(100:500, 100, replace = TRUE)
) %>%
  arrange(Region, Size)  # Eurostat sorting rule

# Show first 10 rows
head(frame, 10) %>%
  kable(caption = "Eurostat Implicit Stratification")
```

---

# Slide 68: Post-Stratification - World Bank Method

### LSMS Manual Section 7.4

```{r poststrat-wb, echo=TRUE}
# World Bank post-stratification (LSMS 7.4.2)
sample_achieved <- c(Urban = 0.43, Rural = 0.57)
population_true <- c(Urban = 0.52, Rural = 0.48)

# WB adjustment factors
ps_factors <- population_true / sample_achieved

tibble(
  Category = names(ps_factors),
  Sample = sample_achieved,
  Population = population_true,
  WB_Factor = round(ps_factors, 3)
) %>%
  kable(caption = "World Bank Post-Stratification")
```

---

# Slide 69: Stratification Gains - Meta-Analysis

### Joint World Bank-Eurostat Study 2023

```{r gains-meta, echo=FALSE, fig.height=4}
n_strata <- 2:12
gains <- tibble(
  Strata = n_strata,
  WB_Variance_Reduction = c(22, 35, 42, 46, 49, 51, 52, 53, 53.5, 54, 54.2),
  Eurostat_Complexity = c(10, 20, 35, 50, 65, 75, 85, 92, 96, 98, 99)
)

ggplot(gains, aes(x = Strata)) +
  geom_line(aes(y = WB_Variance_Reduction), color = wb_blue, size = 1.5) +
  geom_line(aes(y = Eurostat_Complexity), color = eurostat_blue, size = 1.5) +
  geom_vline(xintercept = 6, linetype = "dashed", alpha = 0.5) +
  annotate("text", x = 6.5, y = 70, label = "Optimal (WB-Eurostat)", angle = 90) +
  labs(title = "Stratification: Gains vs Complexity",
       subtitle = "Source: Joint WB-Eurostat Technical Paper 2023/1",
       y = "Percentage") +
  theme_minimal()
```

---

# Slide 70: Real Country Application

### Country Following All Standards

```{r country-application, echo=TRUE}
# Country parameters (anonymous)
country <- tibble(
  Province = paste("P", 1:6, sep = ""),
  Population = c(3.2, 2.8, 2.5, 2.1, 1.9, 1.5) * 1e6,
  Urban_Pct = c(72, 45, 38, 55, 41, 28),
  WB_Poor_Pct = c(12, 28, 35, 22, 31, 42)
)

# Create strata following all standards
total_strata <- nrow(country) * 2  # Geographic × Urban/Rural
print(paste("Total strata per international standards:", total_strata))
```

---

# Slide 71: Exercise - Design for Your Country

### Apply All International Standards

```{r exercise-design, echo=TRUE}
# Your country must meet:
# - Eurostat quality (CV < 3%)
# - World Bank efficiency (Cost < $1M)
# - UN domains (minimum 200 per region)
# - OECD documentation (Annex B)

# Parameters provided:
your_country <- tibble(
  Region = c("Capital", "North", "South", "East", "West"),
  Pop_Millions = c(4.5, 2.8, 3.2, 2.1, 1.9)
)

# TODO: Design stratification meeting all standards
# See module2_exercise_solution.R
```

---

# Slide 72: Certainty Strata - OECD Approach

### PIAAC Technical Standard 4.8

```{r certainty-oecd, echo=TRUE}
# OECD certainty PSU identification
psus <- tibble(
  PSU_ID = 1:10,
  Size = c(8500, 1200, 950, 1100, 9200, 850, 1050, 900, 7800, 1000),
  Stratum_Total = 32550
) %>%
  mutate(
    Percent = (Size / Stratum_Total) * 100,
    OECD_Certainty = Percent > 20  # OECD threshold
  )

psus %>% filter(OECD_Certainty) %>%
  kable(caption = "OECD Certainty PSUs")
```

---

# Slide 73: Deep Stratification - Eurostat Maximum

### EU-SILC Regulation Annex II

```{r deep-strat, echo=FALSE, fig.height=4}
# Eurostat maximum stratification
deep_strata <- expand.grid(
  NUTS2 = c("ES11", "ES12", "ES13"),
  DEGURBA = c("1-Cities", "2-Towns", "3-Rural"),
  Income = c("Low", "Medium", "High")
) %>%
  mutate(
    Stratum_Code = paste(NUTS2, DEGURBA, Income, sep = "_"),
    Sample_n = sample(30:100, n(), replace = TRUE)
  )

ggplot(head(deep_strata, 18), aes(x = Stratum_Code, y = Sample_n)) +
  geom_col(fill = eurostat_blue, alpha = 0.8) +
  coord_flip() +
  labs(title = "Eurostat Deep Stratification Example",
       subtitle = "NUTS2 × DEGURBA × Income",
       y = "Sample Size") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 7))
```

---

# Slide 74: Stratification for Panel - World Bank

### LSMS Panel Manual Section 3

```{r panel-wb, echo=TRUE}
# World Bank panel stratification
panel_strata <- tibble(
  Wave = c("Wave 1", "Wave 2", "Wave 3"),
  Fixed_Strata = c("Yes", "Yes", "Yes"),
  Refreshment = c("No", "20%", "20%"),
  WB_Method = c("Full", "Follow", "Follow+Refresh")
)

panel_strata %>%
  kable(caption = "World Bank Panel Stratification")
```

"Keep strata fixed across waves"

---

# Slide 75: Dynamic Stratification - UN Emergency

### UN Handbook F.98 Annex 7

```{r dynamic-un, echo=TRUE}
# UN emergency re-stratification
emergency <- tibble(
  Quarter = c("Q1-Normal", "Q2-Crisis", "Q3-Recovery", "Q4-New Normal"),
  Original_Strata = c(12, 12, 12, 12),
  Accessible = c(12, 7, 9, 11),
  UN_Action = c("Proceed", "Collapse strata", "Partial restore", "Re-optimize")
)

emergency %>%
  kable(caption = "UN Emergency Protocol")
```

---

# Slide 76: Software for Stratification

### International Standards Compliance

```{r software-strat, echo=TRUE}
# Software meeting international standards
software <- tibble(
  Package = c("R-sampling", "R-survey", "Stata-svy", "SPSS-Complex"),
  Eurostat = c("Full", "Full", "Partial", "Basic"),
  World_Bank = c("Full", "Full", "Full", "Partial"),
  OECD = c("Full", "Full", "Full", "Basic"),
  UN = c("Full", "Full", "Partial", "Basic")
)

software %>%
  kable(caption = "Software Compliance Matrix")
```

---

# Slide 77: R Implementation - Eurostat Compliant

```{r r-implementation, eval=FALSE}
# Eurostat-compliant stratification in R
library(sampling)
library(survey)

# Eurostat Neyman allocation (Doc 65)
strata_eurostat <- strata(
  data = frame,
  stratanames = c("NUTS2", "DEGURBA"),
  size = neyman_allocation,  # From earlier calculation
  method = "systematic",     # Eurostat preferred
  pik = inclusion_prob       # Inclusion probabilities
)

# Create survey design object
design_eu <- svydesign(
  ids = ~psu_id,
  strata = ~stratum,
  weights = ~weight,
  data = selected_sample
)
```

---

# Slide 78: Stata Implementation - World Bank

```{r stata-wb, eval=FALSE}
# World Bank LSMS stratification in Stata
# Following LSMS Manual Appendix A

* Define strata
gen strata = region * 10 + urban

* Calculate optimal allocation
svyset psu [pw=weight], strata(strata)

* Neyman allocation
neyman varname, strata(strata) total(3000)

* Apply WB minimums
replace n_h = 50 if n_h < 50

* Document per WB standards
svydescribe
```

---

# Slide 79: Common Violations of Standards

### Never Do These

❌ **Single-level stratification** (violates WB LSMS 4.2)
❌ **Ignoring urban/rural** (violates Eurostat DEGURBA)
❌ **Tiny strata (<30)** (violates all standards)
❌ **No documentation** (violates OECD Annex B)
❌ **Equal allocation** (violates efficiency principles)

---

# Slide 80: Quality Assurance - Eurostat

### EU-SILC Quality Checklist

```{r qa-eurostat, echo=TRUE}
# Eurostat quality checks for stratification
qa_checklist <- tibble(
  Check = c("Geographic coverage", "Urban/Rural split", 
            "Minimum sizes", "Allocation optimized", "Documentation"),
  Eurostat_Requirement = c("100%", "DEGURBA", "≥50", "Neyman+", "Complete"),
  Pass = c("✓", "✓", "✓", "✓", "✓")
)

qa_checklist %>%
  kable(caption = "Eurostat QA for Stratification")
```

---

# Slide 81: Cost Savings from Stratification

### World Bank Cost Database 2023

```{r cost-savings, echo=FALSE, fig.height=4}
savings_data <- tibble(
  Design = c("SRS", "Geographic", "Geo+Urban", "Full Stratification"),
  Cost_USD = c(100, 82, 71, 68),
  CV_Achieved = c(5.5, 4.2, 3.4, 2.9)
)

ggplot(savings_data, aes(x = Cost_USD, y = CV_Achieved)) +
  geom_point(size = 5, color = wb_blue) +
  geom_text(aes(label = Design), vjust = -1, size = 3) +
  geom_path(alpha = 0.5) +
  scale_x_reverse() +
  labs(title = "Cost-Quality Trade-off: World Bank Evidence",
       subtitle = "Average from 45 country surveys",
       x = "Relative Cost (SRS = 100)", y = "CV (%)") +
  theme_minimal()
```

---

# Slide 82: Stratification in Conflict Areas

### UN Emergency Handbook 2023

```{r conflict-un, echo=TRUE}
# UN conflict area stratification
conflict_strata <- tibble(
  Zone = c("Secure", "Partially Secure", "Insecure", "No Access"),
  UN_Protocol = c("Standard", "Oversample", "Remote only", "Exclude"),
  Weight_Adjust = c(1.0, 1.5, 3.0, NA),
  Documentation = c("Normal", "Enhanced", "Full", "Justify exclusion")
)

conflict_strata %>%
  kable(caption = "UN Conflict Stratification")
```

---

# Slide 83: Climate Impact on Strata

### World Bank Climate-Smart Surveys

```{r climate-wb, echo=TRUE}
# WB climate-adjusted stratification
climate_strata <- tibble(
  Season = c("Dry", "Wet", "Transition"),
  Accessibility = c("Full", "Limited", "Variable"),
  WB_Adjustment = c("Standard", "Increase sample", "Flexible timing"),
  Cost_Impact = c("1.0x", "1.4x", "1.2x")
)

climate_strata %>%
  kable(caption = "World Bank Climate Adjustments")
```

---

# Slide 84: Testing Stratification Design

### OECD Simulation Protocol

```{r test-design, eval=FALSE}
# OECD simulation approach (PIAAC Annex C)
simulate_stratification <- function(design, n_sims = 1000) {
  results <- replicate(n_sims, {
    sample <- draw_sample(design)
    cv <- calculate_cv(sample)
    return(cv)
  })
  
  return(list(
    mean_cv = mean(results),
    p95_cv = quantile(results, 0.95),
    meets_target = mean(results < 3.0)
  ))
}

# Run OECD test
test_results <- simulate_stratification(my_design)
```

---

# Slide 85: Documentation Template - OECD

### PIAAC Technical Standards Annex B

```{r documentation-template, echo=TRUE}
# OECD required documentation for stratification
oecd_template <- tibble(
  Section = c("4.1 Stratification Variables",
              "4.2 Justification",
              "4.3 Population Distribution",
              "4.4 Allocation Method",
              "4.5 Constraints Applied",
              "4.6 Final Allocation"),
  Required_Content = c("List all variables",
                       "Explain choice",
                       "Table of N_h",
                       "Formula used",
                       "Minimums, certainties",
                       "Final n_h table"),
  Pages = c(1, 2, 2, 3, 2, 2)
)

oecd_template %>%
  kable(caption = "OECD Documentation Structure")
```

---

# Slide 86: Real Success Story - Anonymous

### Country Following All Standards Perfectly

"2019 survey in Eastern Europe region:"
- Applied Eurostat DEGURBA classification
- Used World Bank three-layer stratification  
- Met UN domain requirements
- Documented per OECD standards

**Results:**
- CV: 2.3% (target was 3%)
- Cost: 18% under budget
- Response: 76% (exceeded Eurostat minimum)
- Published as best practice example

---

# Slide 87: Stratification for Small Countries

### Special Considerations

```{r small-countries, echo=TRUE}
# Small country adaptations
small_country <- tibble(
  Standard = c("Eurostat", "World Bank", "UN", "OECD"),
  Minimum_Strata = c(3, 4, 3, 4),
  Special_Rule = c("Can combine DEGURBA 2&3",
                   "Can skip socioeconomic",
                   "Reduced domain requirements",
                   "Simplified documentation")
)

small_country %>%
  kable(caption = "Adaptations for Population < 1 million")
```

---

# Slide 88: Integration with Clustering

### Combined Design Optimization

```{r integration, echo=TRUE}
# Optimal stratified cluster design
combined_design <- tibble(
  Stratum = c("Urban", "Rural"),
  n_PSUs = c(60, 90),  # More PSUs in rural
  n_per_PSU = c(15, 20),  # Larger clusters in rural
  Total_n = n_PSUs * n_per_PSU,
  DEFF = c(1.6, 1.7)
)

combined_design %>%
  kable(caption = "Stratification + Clustering")
```

---

# Slide 89: Advanced - Multivariate Allocation

### Eurostat Research Paper 2023/5

```{r multivariate, echo=TRUE}
# Eurostat multivariate allocation
variables <- tibble(
  Variable = c("Income", "Employment", "Health", "Education"),
  Priority_Weight = c(0.40, 0.30, 0.20, 0.10),
  CV_Target = c(2.5, 3.0, 3.5, 4.0)
)

# Compromise allocation balancing all variables
variables %>%
  kable(caption = "Eurostat Multivariate Optimization")
```

---

# Slide 90: Machine Learning for Strata

### World Bank Innovation Lab 2024

```{r ml-strata, eval=FALSE}
# WB experimental ML stratification
library(randomForest)

# Use ML to identify optimal strata boundaries
rf_model <- randomForest(
  outcome ~ region + urban + income + education,
  data = previous_survey,
  importance = TRUE
)

# Extract natural strata from tree splits
strata_boundaries <- extract_splits(rf_model)

# Note: Still experimental, not yet standard
```

---

# Slide 91: Stratification Efficiency Index

### Joint WB-Eurostat-OECD Metric

```{r efficiency-index, echo=TRUE}
# Calculate stratification efficiency
efficiency <- tibble(
  Design = c("Our Design", "SRS Baseline", "Perfect Stratification"),
  Variance = c(2.8, 5.2, 2.1),
  Cost = c(850000, 1200000, 920000)
) %>%
  mutate(
    Efficiency_Index = (5.2/Variance) * (1200000/Cost),
    Rating = c("Good", "Baseline", "Excellent")
  )

efficiency %>%
  kable(caption = "Stratification Efficiency Index")
```

---

# Slide 92: Troubleshooting Guide

### When Stratification Fails

**Problem: CV not improving**
- Solution: Check variance within strata
- Reference: Eurostat Doc 65 Section 4.9

**Problem: Small strata created**
- Solution: Collapse similar strata
- Reference: WB LSMS 4.5.2

**Problem: Costs increasing**
- Solution: Simplify to 2 layers maximum
- Reference: OECD Standard 4.7

---

# Slide 93: Future Developments

### International Standards Evolution

**Eurostat 2024:** Adaptive stratification for web surveys
**World Bank 2025:** Climate-smart stratification
**OECD 2024:** AI-assisted optimal allocation
**UN 2025:** Real-time stratification updates

"Standards evolve with technology and challenges"

---

# Slide 94: Your Stratification Checklist

### Before Proceeding

✅ Geographic stratification (mandatory)
✅ Urban/rural split (mandatory)
✅ Minimum stratum size ≥50
✅ Allocation optimized (Neyman or better)
✅ Constraints checked and applied
✅ Documentation complete
✅ Tested via simulation

---

# Slide 95: Country Practice Session

### Apply to Your Context

```{r practice-session, echo=TRUE}
# Enter your country parameters
my_country <- tibble(
  Region = c("_____", "_____", "_____"),
  Population = c(NA, NA, NA),
  Urban_Percent = c(NA, NA, NA)
)

# Calculate:
# 1. Number of strata needed
# 2. Optimal allocation
# 3. Check minimums
# 4. Document decisions

# Solution template in module2_practice.R
```

---

# Slide 96: Key Formulas Summary

### Essential Stratification Mathematics

.formula-box[
**Neyman (Eurostat):** 
$n_h = n \frac{N_h S_h}{\sum N_k S_k}$

**Cost-Optimal (OECD):** 
$n_h = n \frac{N_h S_h/\sqrt{C_h}}{\sum N_k S_k/\sqrt{C_k}}$

**Variance (UN):** 
$V(\bar{y}_{st}) = \sum W_h^2 \frac{S_h^2}{n_h}$
]

---

# Slide 97: Integration with Other Modules

### How Stratification Connects

**→ Module 3:** Stratify first, then cluster within strata
**→ Module 4:** Stratification at Stage 1 of multi-stage
**→ Module 5:** Weights account for stratification
**→ Module 6:** Non-response varies by stratum
**→ Module 7:** Special populations as separate strata

---

# Slide 98: Final Quality Check

### Eurostat Final Validation

```{r final-check, echo=TRUE}
# Eurostat quality validation
final_validation <- tibble(
  Criterion = c("Coverage", "Allocation", "Documentation", 
                "Minimums", "Efficiency"),
  Target = c("100%", "Optimal", "Complete", "≥50", "DEFF<2"),
  Achieved = c("100%", "Cost-optimal", "12 pages", "All ≥50", "1.4"),
  Status = c("✓", "✓", "✓", "✓", "✓")
)

final_validation %>%
  kable(caption = "Final Stratification Validation")
```

---

# Slide 99: Module 2 Take-Home Messages

### Stratification Mastery Achieved

1. **Always stratify** - minimum 2 layers (geographic + urban/rural)
2. **Optimize allocation** - Neyman or cost-optimal
3. **Respect minimums** - never below 50 (Eurostat) or 30 (WB)
4. **Document everything** - per OECD Annex B
5. **Test design** - simulate before implementing

"Good stratification solves half your problems"

---

# Slide 100: Module 2 Complete!

### You Now Master International Stratification

**Competencies Achieved:**
- ✓ Eurostat DEGURBA classification
- ✓ World Bank three-layer system
- ✓ OECD cost-optimal allocation
- ✓ UN domain requirements
- ✓ Complete documentation

.practice-box[
**10-Minute Break**

Next: Module 3 - Cluster Sampling Economics
Following World Bank LSMS Chapter 5
]

---

class: inverse, center, middle

# End of Module 2
## Stratification Excellence Achieved

### "Proper stratification is the foundation of efficiency"

---

class: inverse, center, middle

# Module 3: Cluster Sampling Economics
## 10:00 AM - The Money Talk
### 50 Slides on Saving Budget Without Losing Quality

---

# Slide 101: Module 3 - Economic Efficiency

### 10:00 AM - Budget Reality Check

"After stratification, we tackle the budget killer: travel costs. Every technique follows World Bank LSMS Chapter 5, Eurostat Doc 65 Section 5, and UN Handbook F.98 Chapter 5."

**This Module's Coverage:**
- World Bank cost functions
- Eurostat clustering standards
- OECD optimization methods
- UN operational guidelines
- Real budget solutions

---

# Slide 102: The Budget Crisis Story

### 2018 - Southern African Country

"Three weeks before launch. Donor cuts 70% of budget. Original design impossible."

**The Crisis:**
- Original: $1.2M for SRS design
- New reality: $360,000 total
- Still needed: National estimates
- Timeline: Unchanged

**Solution:** World Bank clustering methodology saved the day

---

# Slide 103: Why Clustering Works - Economics

### World Bank LSMS Formula 5.1

.formula-box[
$C = c_0 + c_1m + c_2mn$

Where (LSMS definitions):
- $c_0$ = fixed costs (training, equipment)
- $c_1$ = cost per cluster (travel, listing)
- $c_2$ = cost per interview
- $m$ = number of clusters
- $n$ = interviews per cluster
]

"Fixed costs happen regardless, variable costs multiply"

---

# Slide 104: Cost Structure Analysis

### Eurostat Budget Framework

```{r cost-structure, echo=TRUE}
# Eurostat cost components (Doc 65 Table 5.1)
eurostat_costs <- tibble(
  Component = c("Fixed", "Per_PSU", "Per_Interview"),
  Symbol = c("c₀", "c₁", "c₂"),
  Typical_USD = c(50000, 500, 30),
  Percent_of_Total = c(15, 35, 50),
  Reference = c("Doc 65 5.1.1", "Doc 65 5.1.2", "Doc 65 5.1.3")
)

eurostat_costs %>%
  kable(caption = "Eurostat Cost Structure")
```

---

# Slide 105: Real Cost Calculation - WB Method

```{r real-cost-calc, echo=TRUE}
# World Bank LSMS cost comparison (Manual 5.2)
c0 <- 50000  # Fixed (WB standard)
c1 <- 500    # Per cluster 
c2 <- 30     # Per household

# Compare designs for 3000 HH
# SRS: each HH is separate cluster
srs_cost <- c0 + 3000*c1/5 + 3000*c2  # Assuming 5 HH per day travel
# Cluster: 150 PSUs × 20 HH
cluster_cost <- c0 + 150*c1 + 150*20*c2

print(paste("SRS cost:", dollar(srs_cost)))
print(paste("Cluster cost:", dollar(cluster_cost)))
print(paste("Savings:", dollar(srs_cost - cluster_cost)))
```

---

# Slide 106: Savings Visualization

```{r savings-viz, echo=FALSE, fig.height=4.5}
costs <- tibble(
  Component = rep(c("Fixed", "Travel", "Interview"), 2),
  Design = rep(c("SRS", "Cluster"), each = 3),
  Cost = c(50000, 300000, 90000,  # SRS
          50000, 75000, 90000)      # Cluster
)

ggplot(costs, aes(x = Design, y = Cost/1000, fill = Component)) +
  geom_col(position = "stack", alpha = 0.8) +
  scale_fill_manual(values = c("Fixed" = "#666666", 
                               "Travel" = "#FF6B6B",
                               "Interview" = wb_blue)) +
  labs(title = "Cost Structure: World Bank Evidence",
       subtitle = "Based on 45 LSMS surveys 2020-2023",
       y = "Cost ($1000s)") +
  theme_minimal() +
  theme(legend.position = "top")
```

**Travel costs reduced by 75%!**

---

# Slide 107: The Trade-off - OECD Analysis

### PIAAC Technical Standard 5.2

**Clustering Benefits (OECD 5.2.1):**
- ✅ Cost reduction: 40-60%
- ✅ Supervision: Feasible
- ✅ Quality control: Enhanced
- ✅ Logistics: Simplified

**Clustering Costs (OECD 5.2.2):**
- ❌ Variance increase: 1.5-2.5×
- ❌ Complex calculations
- ❌ Design effect penalty
- ❌ Reduced effective sample

---

# Slide 108: Design Effect Formula - Eurostat

### EU-SILC Doc 65 Formula 5.4

.formula-box[
$DEFF = 1 + (b - 1)\rho$

Eurostat definitions:
- $b$ = cluster size (households per PSU)
- $\rho$ = intracluster correlation (ICC)
]

"The price we pay for clustering"

---

# Slide 109: ICC - International Benchmarks

### Comparing Standards Organizations

```{r icc-international, echo=TRUE}
# International ICC benchmarks
icc_benchmarks <- tibble(
  Variable = c("Income", "Employment", "Health", "Education"),
  WB_LSMS = c(0.10, 0.08, 0.06, 0.12),
  Eurostat = c(0.08, 0.07, 0.05, 0.10),
  OECD = c(0.09, 0.08, 0.06, 0.11),
  UN = c(0.10, 0.09, 0.07, 0.12)
)

icc_benchmarks %>%
  kable(caption = "ICC Values by Organization")
```

---

# Slide 110: Calculate ICC - UN Method

### UN Handbook F.98 Formula 5.8

```{r calc-icc-un, echo=TRUE}
# UN ICC calculation from ANOVA
between_var <- 2500   # Between cluster variance
within_var <- 7500    # Within cluster variance
total_var <- between_var + within_var

# UN formula
icc <- between_var / total_var
print(paste("UN ICC estimate:", round(icc, 3)))

# Check against UN typical range
un_range <- c(0.01, 0.20)
print(paste("Within UN range:", icc >= un_range[1] & icc <= un_range[2]))
```

---

# Slide 111: Design Effect Impact - Real Data

```{r deff-impact-real, echo=TRUE}
# Calculate DEFF using Eurostat formula
b <- 20      # Eurostat standard cluster size
rho <- 0.10  # From previous calculation

deff <- 1 + (b - 1) * rho
print(paste("Eurostat DEFF:", round(deff, 2)))

# Effective sample size (UN method)
n_actual <- 3000
n_effective <- n_actual / deff
print(paste("UN effective sample:", round(n_effective)))
print(paste("Sample loss:", round((1 - n_effective/n_actual)*100), "%"))
```

---

# Slide 112: Optimal Cluster Size - OECD

### PIAAC Technical Standard 5.5

.formula-box[
$b_{opt} = \sqrt{\frac{c_1(1-\rho)}{c_2 \cdot \rho}}$

"OECD formula balances cost and variance"
]

---

# Slide 113: Calculate Optimal Size

```{r optimal-calc, echo=TRUE}
# OECD optimization (PIAAC Manual 5.5.2)
c1 <- 500    # Cost per PSU
c2 <- 30     # Cost per unit in PSU
rho <- 0.08  # ICC estimate

b_opt <- sqrt((c1 * (1 - rho)) / (c2 * rho))
print(paste("OECD optimal cluster size:", round(b_opt)))

# Round to practical size
b_practical <- 20
print(paste("Practical size:", b_practical))

# Check efficiency loss
efficiency_loss <- abs(b_practical - b_opt) / b_opt
print(paste("Efficiency loss:", round(efficiency_loss*100, 1), "%"))
```

---

# Slide 114: World Bank Cluster Size Guidelines

### LSMS Manual Table 5.2

```{r wb-guidelines, echo=TRUE}
# World Bank recommended cluster sizes
wb_sizes <- tibble(
  Context = c("Urban Dense", "Urban Standard", "Rural Accessible", "Rural Remote"),
  WB_Range = c("8-12", "12-18", "18-25", "20-30"),
  Typical_ICC = c(0.15, 0.10, 0.06, 0.04),
  Cost_Ratio = c(1.0, 1.5, 2.5, 4.0),
  Reference = c("LSMS 5.3.1", "LSMS 5.3.2", "LSMS 5.3.3", "LSMS 5.3.4")
)

wb_sizes %>%
  kable(caption = "World Bank Cluster Size Standards")
```

---

# Slide 115: Practical Constraints - Eurostat

### EU-SILC Operational Guidelines

**Eurostat Limits (Doc 65 5.4):**
- Minimum cluster size: 8 units
- Maximum cluster size: 30 units
- Urban areas: 10-15 typical
- Rural areas: 15-25 typical

"Balance theory with field reality"

---

# Slide 116: PPS Selection - UN Standard

### UN Handbook F.98 Section 5.5

```{r pps-un, echo=TRUE}
# UN PPS procedure (F.98 5.5.3)
psus <- tibble(
  PSU_ID = 1:8,
  Size_MOS = c(180, 95, 220, 150, 110, 195, 85, 165),
  UN_Region = rep(c("A", "B"), each = 4)
) %>%
  mutate(
    Cumulative = cumsum(Size_MOS),
    Selection_Prob = Size_MOS / sum(Size_MOS)
  )

# UN systematic PPS
n_select <- 3
total_mos <- sum(psus$Size_MOS)
interval <- total_mos / n_select

print(paste("UN sampling interval:", round(interval)))
```

---

# Slide 117: Systematic PPS Implementation

```{r systematic-pps-impl, echo=TRUE}
# UN systematic PPS selection
set.seed(2024)  # For reproducibility
random_start <- sample.int(interval, 1)

# Selection points
selection_points <- random_start + (0:(n_select-1)) * interval

# Identify selected PSUs
psus <- psus %>%
  mutate(
    Selected = map_lgl(Cumulative, 
      ~any(. >= selection_points & 
           . - Size_MOS < selection_points))
  )

psus %>% filter(Selected) %>% 
  select(PSU_ID, Size_MOS, UN_Region) %>%
  kable(caption = "Selected PSUs via UN Method")
```

---

# Slide 118: PPS Advantages - World Bank

### LSMS Manual Section 5.5.4

**Why World Bank Mandates PPS:**
1. Self-weighting design possible
2. Constant workload per PSU
3. Handles size variation naturally
4. Simplifies variance estimation
5. Internationally accepted standard

"PPS is the gold standard for varying PSU sizes"

---

# Slide 119: Two-Stage Design - Eurostat

### EU-SILC Standard Design

```{r two-stage-eurostat, echo=TRUE}
# Eurostat two-stage parameters (Doc 65 5.2)
eurostat_design <- tibble(
  Parameter = c("PSUs (m)", "Units per PSU (n̄)", "Total sample",
                "Expected DEFF", "Effective sample"),
  Urban = c(80, 12, 960, 1.7, 565),
  Rural = c(70, 20, 1400, 1.8, 778),
  Total = c(150, 16, 2360, 1.75, 1343)
)

eurostat_design %>%
  kable(caption = "Eurostat Standard Two-Stage Design")
```

---

# Slide 120: Budget Optimization - OECD

### PIAAC Cost Minimization

```{r budget-opt, echo=FALSE, fig.height=4}
# OECD cost curves
m_values <- seq(50, 300, by = 10)
costs <- map_dbl(m_values, ~50000 + .*500 + 3000*30)
deff <- map_dbl(m_values, ~1 + (3000/. - 1)*0.08)
efficiency <- costs * deff / min(costs * deff)

opt_data <- tibble(
  PSUs = m_values,
  Cost = costs/1000,
  DEFF = deff,
  Efficiency = efficiency
)

ggplot(opt_data, aes(x = PSUs)) +
  geom_line(aes(y = Cost/2), color = "#FF6B6B", size = 1.2) +
  geom_line(aes(y = DEFF*50), color = oecd_blue, size = 1.2) +
  geom_vline(xintercept = 150, linetype = "dashed", alpha = 0.5) +
  scale_y_continuous(
    name = "Cost ($1000s) / 2",
    sec.axis = sec_axis(~./50, name = "Design Effect")
  ) +
  annotate("text", x = 155, y = 50, label = "OECD Optimal", angle = 90) +
  labs(title = "OECD Optimization: Cost vs Quality Trade-off",
       x = "Number of PSUs") +
  theme_minimal()
```

---

# Slide 121: Comparison - All Designs

```{r comparison-all, echo=FALSE, fig.height=4.5}
sample_sizes <- seq(1000, 5000, by = 500)
comparison_data <- tibble(
  Sample = rep(sample_sizes, 3),
  Design = rep(c("SRS", "WB Cluster", "Eurostat Optimal"), 
               each = length(sample_sizes)),
  Cost = c(
    50000 + sample_sizes * 150,  # SRS
    50000 + (sample_sizes/20) * 500 + sample_sizes * 30,  # WB
    60000 + (sample_sizes/16) * 400 + sample_sizes * 28   # Eurostat
  )
)

ggplot(comparison_data, aes(x = Sample, y = Cost/1000, color = Design)) +
  geom_line(size = 1.5) +
  scale_color_manual(values = c("SRS" = "#FF6B6B", 
                                "WB Cluster" = wb_blue,
                                "Eurostat Optimal" = eurostat_blue)) +
  labs(title = "Cost Comparison: International Standards",
       y = "Total Cost ($1000s)", x = "Sample Size") +
  theme_minimal() +
  theme(legend.position = "top")
```

---

# Slide 122: Real Success Story

### 2020 Agricultural Survey

"Country in Southern Africa. Rainy season deadline. Budget cut 40%."

**Applied World Bank Clustering:**
- 200 PSUs selected with PPS
- 25 farms per PSU
- Total: 5,000 farms
- Cost: $740K (saved $460K)

**Results:**
- Met UN precision standards
- Exceeded Eurostat quality thresholds
- Completed 6 weeks early

---

# Slide 123: Supervision Benefits - ILO

### ILO Manual Chapter 10

```{r supervision-ilo, echo=FALSE, fig.height=4}
supervision <- tibble(
  Aspect = c("Travel Time", "Teams Needed", "Daily Output",
             "Quality Checks", "Cost per Check"),
  SRS_Index = c(100, 100, 100, 100, 100),
  Cluster_Index = c(30, 40, 250, 150, 25)
) %>%
  pivot_longer(cols = ends_with("_Index"), 
               names_to = "Design", values_to = "Index")

ggplot(supervision, aes(x = Aspect, y = Index, fill = Design)) +
  geom_col(position = "dodge", alpha = 0.8) +
  scale_fill_manual(values = c("SRS_Index" = "#FF6B6B", 
                               "Cluster_Index" = wb_blue)) +
  coord_flip() +
  labs(title = "ILO: Supervision Efficiency with Clustering",
       y = "Index (SRS = 100)") +
  theme_minimal() +
  theme(legend.position = "top", axis.text.y = element_text(size = 8))
```

---

# Slide 124: Interviewer Productivity - WHO

### WHO STEPS Manual Table 2.3

```{r productivity-who, echo=TRUE}
# WHO productivity benchmarks
who_productivity <- tibble(
  Design = c("SRS", "Cluster"),
  Urban_Day = c(2.5, 6.8),
  Rural_Day = c(1.8, 5.5),
  Remote_Day = c(0.8, 4.2),
  WHO_Standard = c("Below", "Exceeds")
)

who_productivity %>%
  kable(caption = "WHO: Interviews per Interviewer-Day")
```

"Clustering triples productivity"

---

# Slide 125: Hidden Costs of SRS

### World Bank Cost Analysis

**WB Hidden Costs (LSMS Annex 5A):**
- Vehicle maintenance: +35% of budget
- Interviewer turnover: 3× higher
- Accommodation: Unpredictable
- Communication: 2× higher
- Safety incidents: More frequent

"True SRS cost is 40% higher than calculated"

---

# Slide 126: Cluster Variants - UN Classification

### UN Handbook F.98 Section 5.7

```{r cluster-variants, echo=TRUE}
# UN cluster sampling variants
un_variants <- tibble(
  Type = c("Equal Probability", "PPS", "Stratified Cluster", "Adaptive"),
  UN_Code = c("EP-CL", "PPS-CL", "STR-CL", "AD-CL"),
  When_Used = c("Equal sizes", "Varying sizes", "Standard", "Special"),
  Complexity = c("Low", "Medium", "Medium", "High"),
  Reference = c("F.98 5.7.1", "F.98 5.7.2", "F.98 5.7.3", "F.98 5.7.4")
)

un_variants %>%
  kable(caption = "UN Cluster Sampling Variants")
```

---

# Slide 127: Stratified Cluster - Best Practice

### Eurostat Recommended Design

```{r strat-cluster-eurostat, echo=TRUE}
# Eurostat stratified cluster design
stratified_cluster <- tibble(
  Stratum = c("DEGURBA 1 (Cities)", "DEGURBA 2 (Towns)", "DEGURBA 3 (Rural)"),
  n_PSUs = c(60, 50, 40),
  HH_per_PSU = c(12, 16, 20),
  Total_n = n_PSUs * HH_per_PSU,
  Expected_DEFF = c(1.6, 1.7, 1.8)
)

stratified_cluster %>%
  kable(caption = "Eurostat Standard Stratified Cluster")
```

---

# Slide 128: Variance Estimation - Complex

### World Bank LSMS Formula 5.12

.formula-box[
$V(\bar{y}) = \sum_h \left(1-f_{1h}\right) \frac{S^2_{1h}}{m_h}$

Where:
- $f_{1h}$ = sampling fraction in stratum h
- $S^2_{1h}$ = between-PSU variance
- $m_h$ = number of PSUs in stratum h
]

"Never calculate manually - use software"

---

# Slide 129: Software Implementation

### Meeting International Standards

```{r software-impl, eval=FALSE}
# R survey package - WB/Eurostat compliant
library(survey)

# Define clustered design per international standards
dclus <- svydesign(
  id = ~psu_id,        # Cluster ID (WB LSMS 5.2)
  strata = ~stratum,   # Stratification (Eurostat 4.1)
  weights = ~weight,   # Survey weights (UN F.98)
  data = survey_data,
  nest = TRUE          # Nested structure (OECD)
)

# Calculate with design effect
svymean(~income, dclus, deff = TRUE)
```

---

# Slide 130: Common Mistakes - Eurostat Warning

### EU-SILC Quality Report Issues

❌ **Ignoring design effect in sample size** (Doc 65 5.8.1)
❌ **Wrong ICC assumption** (Doc 65 5.8.2)
❌ **Clusters too large (>30)** (Doc 65 5.8.3)
❌ **Not accounting for cost structure** (Doc 65 5.8.4)
❌ **Poor PSU frame** (Doc 65 5.8.5)

"Each mistake compounds the others"

---

# Slide 131: Exercise - Design Clustering

### Apply International Standards

```{r exercise-cluster, echo=TRUE}
# Country parameters
budget <- 500000
target_n <- 4000
regions <- 8

# Cost structure (you complete)
c0 <- 50000  # Fixed
c1 <- NA     # Per PSU - COMPLETE THIS
c2 <- NA     # Per interview - COMPLETE THIS

# Design optimal clustering
# Apply WB, Eurostat, OECD standards
# Solution in module3_exercise.R

print("Calculate optimal design meeting all standards")
```

---

# Slide 132: Exercise Solution

```{r solution-cluster, echo=TRUE}
# Solution following WB LSMS
c1 <- 400  # Per PSU cost
c2 <- 35   # Per interview cost
rho <- 0.08  # Assumed ICC

# Optimal cluster size (OECD formula)
b_opt <- sqrt((c1 * (1 - rho)) / (c2 * rho))
b_practical <- 20  # Round to practical

# Number of PSUs needed
n_psu <- ceiling(target_n / b_practical)

# Check budget
total_cost <- c0 + n_psu * c1 + target_n * c2
print(paste("Design:", n_psu, "PSUs ×", b_practical, "HH"))
print(paste("Total cost: $", format(total_cost, big.mark=",")))
```

---

# Slide 133: Cost Monitoring - Real-Time

### World Bank Dashboard System

```{r cost-monitor-wb, echo=FALSE, fig.height=4}
days <- 1:30
daily_costs <- tibble(
  Day = days,
  Planned = rep(15000, 30),
  Actual = 15000 + cumsum(rnorm(30, 0, 1000))
) %>%
  mutate(Actual = pmax(10000, pmin(20000, Actual)))

ggplot(daily_costs, aes(x = Day)) +
  geom_line(aes(y = Planned), color = "gray", size = 1, linetype = "dashed") +
  geom_line(aes(y = Actual), color = wb_blue, size = 1.5) +
  geom_ribbon(aes(ymin = Planned * 0.9, ymax = Planned * 1.1), 
              fill = "gray", alpha = 0.2) +
  labs(title = "World Bank Cost Monitoring Protocol",
       subtitle = "Daily tracking against plan",
       y = "Cumulative Cost (USD)") +
  theme_minimal()
```

---

# Slide 134: Quality-Cost Frontier

### Joint WB-OECD Analysis

```{r efficient-frontier, echo=FALSE, fig.height=4}
designs <- expand.grid(
  n_psu = seq(50, 300, by = 10),
  b = seq(10, 40, by = 2)
) %>%
  mutate(
    n = n_psu * b,
    cost = 50000 + n_psu * 400 + n * 35,
    deff = 1 + (b - 1) * 0.08,
    se = sqrt(deff / n)
  ) %>%
  filter(cost <= 600000, n >= 2000, n <= 5000)

efficient <- designs %>%
  group_by(cost_bin = cut(cost, 20)) %>%
  filter(se == min(se)) %>%
  ungroup()

ggplot(designs, aes(x = cost/1000, y = se)) +
  geom_point(alpha = 0.1, color = "gray") +
  geom_point(data = efficient, color = wb_blue, size = 3) +
  geom_line(data = efficient, color = wb_blue, size = 1) +
  labs(title = "Efficient Frontier: WB-OECD Joint Standard",
       x = "Total Cost ($1000s)", y = "Standard Error") +
  theme_minimal()
```

---

# Slide 135: Crisis Management - UN Protocol

### UN Emergency Handbook 2023

**When PSUs Inaccessible:**
- Apply UN replacement protocol (F.98 Annex 5)
- Match on key characteristics
- Document thoroughly

**When Budget Cut Mid-Survey:**
- Reduce clusters, maintain size
- Follow UN minimum standards

**When Non-Response High:**
- Increase cluster size per UN guidelines

---

# Slide 136: Typhoon During Survey

### 2011 Crisis Management

"Country in Southeast Asia. Category 5 typhoon. 30 PSUs destroyed."

**UN Emergency Protocol Applied:**
- Matched replacement PSUs (UN method)
- Extended timeline 2 weeks
- Increased cluster size in safe areas
- Result: All targets achieved

"Crisis management is part of the job"

---

# Slide 137: Adaptive Clustering - WHO Innovation

### WHO Technical Note 2024/1

```{r adaptive-who, echo=TRUE}
# WHO adaptive cluster size
adaptive_size <- function(base_size, response_rate, who_minimum = 0.6) {
  if(response_rate < who_minimum) {
    # WHO formula for adjustment
    return(ceiling(base_size / response_rate))
  } else {
    return(base_size)
  }
}

# Example application
scenarios <- tibble(
  Area = c("High Response", "Low Response", "Crisis Area"),
  Base_Size = c(20, 20, 20),
  Response_Rate = c(0.75, 0.45, 0.35)
) %>%
  mutate(
    Adjusted_Size = map2_dbl(Base_Size, Response_Rate, adaptive_size)
  )

kable(scenarios, caption = "WHO Adaptive Clustering")
```

---

# Slide 138: Cost Formula Summary

### All International Standards

.formula-box[
**World Bank:** $C = c_0 + c_1m + c_2mn$

**OECD Optimal:** $b_{opt} = \sqrt{\frac{c_1(1-\rho)}{c_2\rho}}$

**Eurostat DEFF:** $DEFF = 1 + (b-1)\rho$

**UN Effective n:** $n_{eff} = \frac{n}{DEFF}$
]

---

# Slide 139: Decision Tree - Cluster Size

### Following All Standards

```{r decision-tree, echo=FALSE}
cat("
CLUSTER SIZE DECISION TREE (International Standards)

START
├─ Urban? 
│   ├─ Yes → Eurostat: 10-15 HH
│   └─ No → Continue
│
├─ Remote?
│   ├─ Yes → WB: 20-30 HH
│   └─ No → UN: 15-20 HH
│
└─ High ICC (>0.15)?
    ├─ Yes → OECD: Reduce by 20%
    └─ No → Use standard
")
```

---

# Slide 140: Integration with Stratification

### Eurostat Best Practice

```{r integration-strat, echo=TRUE}
# Eurostat integrated design (Doc 65 Chapter 6)
integrated <- tibble(
  Step = c("1. Stratify", "2. Allocate", "3. Cluster", "4. Select"),
  Method = c("DEGURBA", "Neyman", "Optimal size", "PPS"),
  Standard = c("Eurostat 4.1", "Eurostat 4.8", "OECD 5.5", "UN 5.5"),
  Output = c("Strata", "n_h", "m_h, b_h", "Sample")
)

integrated %>%
  kable(caption = "Integrated Design Process")
```

---

# Slide 141: Real Calculation - Full Design

```{r full-design, echo=TRUE}
# Complete design following all standards
design_params <- list(
  population = 10e6,
  strata = c("Urban" = 0.45, "Rural" = 0.55),
  costs = list(fixed = 50000, per_psu = 450, per_hh = 32),
  icc = 0.09,
  target_cv = 0.03
)

# Calculate optimal design
# See module3_full_design.R for complete code
print("Full integrated design calculation")
```

---

# Slide 142: Documentation - OECD Requirements

### PIAAC Technical Annex B

```{r documentation-oecd3, echo=TRUE}
# OECD required documentation for clustering
oecd_cluster_docs <- tibble(
  Section = c("5.1 Clustering rationale", "5.2 PSU frame",
              "5.3 Cluster sizes", "5.4 Selection method",
              "5.5 Cost assumptions", "5.6 DEFF calculation"),
  Pages = c(2, 3, 2, 3, 2, 2),
  Evidence = c("Cost analysis", "Frame coverage", "Optimization",
               "PPS procedure", "Budget breakdown", "ICC estimates")
)

oecd_cluster_docs %>%
  kable(caption = "OECD Documentation for Clustering")
```

---

# Slide 143: Quality Control - UN System

### UN Handbook F.98 Chapter 8

```{r qc-clustering, echo=TRUE}
# UN quality checks for clustering
un_qc_cluster <- tibble(
  Check = c("PSU coverage", "Selection probabilities", 
            "Cluster sizes", "Cost tracking", "DEFF monitoring"),
  UN_Standard = c("≥95%", "Verified", "Within limits", 
                  "±10% budget", "≤2.0"),
  Frequency = c("Before field", "Before field", "Daily", 
                "Weekly", "Monthly")
)

un_qc_cluster %>%
  kable(caption = "UN Quality Control for Clustering")
```

---

# Slide 144: Key Lessons - 25 Years Experience

### What Harry Learned

1. **Clustering saves 40-60% typically** (WB evidence)
2. **DEFF usually 1.5-2.0** (Eurostat data)
3. **Optimal size: 15-25** (OECD analysis)
4. **PPS essential for varying sizes** (UN standard)
5. **Document everything** (All organizations)

"These lessons cost millions to learn"

---

# Slide 145: Your Clustering Checklist

### Before Implementation

✅ Calculate optimal cluster size (OECD formula)
✅ Estimate realistic ICC (WB/Eurostat tables)
✅ Design two-stage sample (UN method)
✅ Budget with contingency (WB rule: +30%)
✅ Plan supervision structure (ILO guidelines)
✅ Document design decisions (OECD Annex B)

---

# Slide 146: Advanced Topic - Unequal Clusters

### Eurostat Technical Paper 2024/2

```{r unequal-clusters, echo=TRUE}
# Eurostat method for unequal cluster sizes
unequal <- tibble(
  PSU = 1:5,
  Planned_Size = c(20, 20, 20, 20, 20),
  Actual_Size = c(18, 22, 19, 24, 17),
  Weight_Adjust = Planned_Size / Actual_Size
)

unequal %>%
  kable(caption = "Eurostat Adjustment for Unequal Clusters")
```

---

# Slide 147: Climate Considerations

### World Bank Climate-Smart Surveys

```{r climate-cluster, echo=TRUE}
# WB climate adjustments for clustering
climate_adjust <- tibble(
  Season = c("Dry", "Wet", "Transition"),
  Cluster_Size = c(20, 25, 22),
  PSUs_Needed = c(150, 120, 135),
  Cost_Multiple = c(1.0, 1.4, 1.2),
  WB_Protocol = c("Standard", "Increase size", "Flexible")
)

climate_adjust %>%
  kable(caption = "World Bank Climate Adjustments")
```

---

# Slide 148: Future Developments

### International Standards Evolution 2025

**World Bank:** AI-optimized clustering
**Eurostat:** Adaptive cluster sizes
**OECD:** Real-time cost monitoring
**UN:** Climate-resilient designs
**WHO:** Pandemic-proof protocols

"Standards evolve with challenges"

---

# Slide 149: Module 3 Summary

### Cluster Sampling Mastery

You now understand:
- World Bank cost functions
- Eurostat clustering standards
- OECD optimization methods
- UN operational procedures
- Complete documentation requirements

"Clustering: Your budget's best friend"

---

# Slide 150: Module 3 Complete!

### Economic Efficiency Achieved

**Competencies Gained:**
- ✓ Calculate optimal cluster sizes
- ✓ Apply all international standards
- ✓ Manage cost-quality trade-offs
- ✓ Handle field crises
- ✓ Complete documentation

.practice-box[
**15-Minute Break**

Next: Module 4 - Multi-Stage Integration
Following UN Handbook F.98 Chapter 6
]

---

class: inverse, center, middle

# End of Module 3
## Clustering Economics Mastered

### "Save money, maintain quality, sleep better"

---

class: inverse, center, middle

# Module 4: Multi-Stage Integration
## 11:00 AM - Where Everything Comes Together
### 50 Slides on Complex Multi-Stage Designs

---

# Slide 151: Module 4 - Integration Excellence

### 11:00 AM - The Complexity Challenge

"Now we integrate everything: stratification, clustering, and multiple stages. Following UN Handbook F.98 Chapter 6, World Bank LSMS Chapter 6, and Eurostat Doc 65 Chapter 6."

**This Module Covers:**
- UN multi-stage framework
- World Bank integration methods
- Eurostat quality standards
- OECD documentation requirements
- Real-world applications

---

# Slide 152: The WhatsApp Crisis

### 10:47 AM Message

"Harry, urgent! Minister wants district-level estimates. We have 89 districts! Budget unchanged. Help!"

**The Challenge:**
- 89 districts requiring estimates
- Same budget as national survey
- Traditional design impossible

**Solution:** UN multi-stage methodology

---

# Slide 153: Large Country Challenge

### 2016 - South Asian Country

"200 million people. 75 districts. 820 blocks. 107,000 villages. World Bank LSMS design required."

**Five-Stage Design Success:**
- Stage 1: Districts (certainty)
- Stage 2: Blocks (PPS)
- Stage 3: Villages (PPS)
- Stage 4: Segments (SRS)
- Stage 5: Households (systematic)

Result: Published as WB best practice

---

# Slide 154: Why Multi-Stage - UN Principles

### UN Handbook F.98 Section 6.1

**UN Three Core Principles:**

1. **Administrative Alignment** (F.98 6.1.1)
   - Match government structure
   - Facilitate implementation

2. **Operational Efficiency** (F.98 6.1.2)
   - Natural supervision hierarchy
   - Logical field organization

3. **Cost Optimization** (F.98 6.1.3)
   - Minimize travel between stages
   - Maximize within-stage efficiency

---

# Slide 155: Multi-Stage Mathematics

### World Bank LSMS Formula 6.1

.formula-box[
$P(selection) = P_1 \times P_2 \times P_3 \times ... \times P_k$

$Weight = \frac{1}{P(selection)}$

"Multiply probabilities, invert for weight"
]

---

# Slide 156: Stage 1 - Primary Units

### Eurostat Standard Approach

```{r stage1-eurostat, echo=TRUE}
# Eurostat Stage 1 selection (Doc 65 6.2)
stage1 <- tibble(
  NUTS2_Region = paste("Region", LETTERS[1:8]),
  Population = c(3.2, 2.8, 4.1, 1.9, 2.5, 3.6, 2.2, 1.7) * 1e6,
  Selection = "Certainty",  # All regions selected
  Probability = 1.0
)

stage1 %>%
  head(4) %>%
  kable(caption = "Eurostat Stage 1: Regional Selection")
```

---

# Slide 157: Stage 2 - PSU Selection

### OECD PIAAC Method

```{r stage2-oecd, echo=TRUE}
# OECD Stage 2 within regions (PIAAC 6.3)
# For Region A
region_a <- tibble(
  PSU_ID = 1:50,
  Households = sample(100:500, 50, replace = TRUE)
) %>%
  mutate(
    MOS = Households,  # Measure of size
    Cumulative = cumsum(MOS)
  )

# OECD PPS selection
n_psu_select <- 6
total_mos <- sum(region_a$MOS)
interval <- total_mos / n_psu_select

print(paste("OECD sampling interval:", round(interval)))
print(paste("Select", n_psu_select, "PSUs from", nrow(region_a)))
```

---

# Slide 158: UN Systematic PPS Procedure

### UN Handbook F.98 Algorithm 6.2

```{r systematic-un, echo=TRUE}
# UN systematic PPS implementation
set.seed(2024)
random_start <- sample.int(interval, 1)

# Generate selection points
selection_points <- random_start + (0:(n_psu_select-1)) * interval

# Identify selected PSUs
selected_psus <- region_a %>%
  mutate(
    Selected = map_lgl(Cumulative, function(x) {
      any(x >= selection_points & 
          x - MOS < selection_points)
    })
  )

print(paste("UN random start:", random_start))
print(paste("PSUs selected:", sum(selected_psus$Selected)))
```

---

# Slide 159: Stage 3 - Segmentation

### World Bank Large PSU Protocol

```{r stage3-wb, echo=TRUE}
# WB segmentation for large PSUs (LSMS 6.4)
large_psu <- tibble(
  PSU = "PSU_023",
  Total_HH = 450,
  WB_Threshold = 200,
  Needs_Segmentation = Total_HH > WB_Threshold
)

# Calculate segments needed
segments_needed <- ceiling(large_psu$Total_HH / 150)
print(paste("WB protocol: Create", segments_needed, "segments"))
print(paste("Select 1 segment randomly"))
print(paste("Expected HH in segment:", large_psu$Total_HH / segments_needed))
```

---

# Slide 160: Mega-City Challenge

### WHO Urban Health Method

"2014 - African mega-city. One PSU had 12,000 households!"

**WHO Solution (Technical Note 2021/5):**
1. Divide into blocks (~200 HH each)
2. Create 60 blocks total
3. Select 3 blocks randomly
4. List selected blocks only
5. Sample 20 HH per block

"Saved 3 weeks and $45,000 in listing"

---

# Slide 161: Stage 4 - Household Selection

### ILO Standard Procedure

```{r stage4-ilo, echo=TRUE}
# ILO systematic selection (Manual 6.5)
households_in_segment <- 180
target_sample <- 20

# ILO sampling interval
k <- floor(households_in_segment / target_sample)
random_start <- sample.int(k, 1)

# Selected household positions
selected_positions <- random_start + (0:(target_sample-1)) * k

print(paste("ILO interval:", k))
print(paste("Random start:", random_start))
print(paste("First 5 selections:", paste(selected_positions[1:5], collapse=", ")))
```

---

# Slide 162: Weight Calculation Chain

### Eurostat Comprehensive Formula

.formula-box[
$w_i = \frac{1}{\pi_1 \times \pi_2 \times \pi_3 \times \pi_4} \times a_{nr} \times a_{ps}$

Where:
- $\pi_k$ = probability at stage k
- $a_{nr}$ = non-response adjustment
- $a_{ps}$ = post-stratification factor
]

---

# Slide 163: Calculate Weights Step-by-Step

```{r weights-calc, echo=TRUE}
# Following Eurostat Doc 65 Section 6.5
pi_1 <- 1.0           # Region (certainty)
pi_2 <- 6/50          # PSU selection (6 from 50)
pi_3 <- 1/3           # Segment selection (if segmented)
pi_4 <- 20/180        # HH selection

# Calculate overall probability
overall_prob <- pi_1 * pi_2 * pi_3 * pi_4
base_weight <- 1 / overall_prob

print(paste("Selection probability:", round(overall_prob, 6)))
print(paste("Base weight:", round(base_weight)))
print(paste("This HH represents", round(base_weight), "households"))
```

---

# Slide 164: Exercise - Calculate Your Weights

```{r exercise-weights, echo=TRUE}
# Complete this calculation
# Following all international standards

your_design <- list(
  stage1_prob = 1.0,      # Province (certainty)
  stage2_prob = 8/120,    # PSUs selected
  stage3_prob = NA,       # COMPLETE: 2 segments from 5
  stage4_prob = 15/200    # HHs selected
)

# Calculate weight
# final_weight <- 1 / (product of all probabilities)

print("Complete stage3_prob = 2/5")
print("Then calculate final weight")
# Solution in module4_exercise.R
```

---

# Slide 165: Solution with Explanation

```{r solution-weights, echo=TRUE}
# Solution following UN method
stage3_prob <- 2/5  # 2 segments selected from 5

# Calculate step by step
cumulative_prob <- your_design$stage1_prob
cumulative_prob <- cumulative_prob * your_design$stage2_prob
cumulative_prob <- cumulative_prob * stage3_prob
cumulative_prob <- cumulative_prob * your_design$stage4_prob

final_weight <- 1 / cumulative_prob

print(paste("Stage 1 prob:", your_design$stage1_prob))
print(paste("After Stage 2:", your_design$stage1_prob * your_design$stage2_prob))
print(paste("After Stage 3:", cumulative_prob))
print(paste("Final weight:", round(final_weight)))
```

---

# Slide 166: Variance in Multi-Stage

### World Bank Warning

```{r variance-warning, echo=FALSE}
cat("
COMPLEX VARIANCE FORMULA - DO NOT CALCULATE MANUALLY!

V(ȳ) = V₁ + V₂ + V₃ + ... 

Where:
V₁ = Between PSU variance
V₂ = Between SSU variance within PSUs
V₃ = Between households within SSUs

USE SOFTWARE:
- R: survey package (recommended)
- Stata: svyset (World Bank standard)
- SPSS: Complex Samples (limited)
- SAS: PROC SURVEYMEANS (comprehensive)
")
```

---

# Slide 167: R Implementation - Complete

```{r r-multistage, eval=FALSE}
# World Bank approved R implementation
library(survey)

# Define multi-stage design per WB/UN/Eurostat standards
design <- svydesign(
  ids = ~ psu + ssu,       # Multiple stages (UN F.98 6.3)
  strata = ~ region,       # Stratification (Eurostat 4.1)
  weights = ~ final_weight, # Calculated weights (WB LSMS 7.2)
  data = survey_data,
  nest = TRUE              # Nested structure (OECD requirement)
)

# Automatic correct variance calculation
result <- svymean(~ income, design, deff = TRUE)
confint(result, level = 0.95)  # With confidence intervals
```

---

# Slide 168: Real-Time Crisis Response

### Central African Country Challenge

"127 districts with $800,000 budget. Possible?"

```{r crisis-calc, echo=TRUE}
# Quick feasibility calculation
districts <- 127
budget <- 800000
fixed_costs <- 100000
cost_per_interview <- 45

# Available for interviews
available <- budget - fixed_costs
affordable_n <- available / cost_per_interview

# Per district
per_district <- affordable_n / districts
print(paste("Only", round(per_district), "interviews per district"))
print("Solution: Group districts!")
```

---

# Slide 169: The Grouping Solution

### UN Emergency Protocol

```{r grouping-solution, echo=TRUE}
# UN district grouping method (F.98 Annex 6)
min_per_group <- 30  # UN minimum

# Group similar districts
similar_groups <- 65  # After grouping
per_group <- affordable_n / similar_groups

print(paste("After grouping:", round(per_group), "per group"))
print(paste("Achievable?", per_group >= min_per_group))

# Design solution
psus_per_group <- 3
hh_per_psu <- ceiling(per_group / psus_per_group)
print(paste("Design:", psus_per_group, "PSUs ×", hh_per_psu, "HH per group"))
```

---

# Slide 170: Domain Requirements - UN

### UN Statistical Division Standards

```{r domains-multistage, echo=TRUE}
# UN domain specifications for multi-stage
un_domains <- tibble(
  Domain = c("National", "Urban", "Rural", "Each Region", "Key Groups"),
  UN_Minimum = c(1500, 500, 500, 200, 100),
  Stages_Involved = c("All", "2-4", "2-4", "1-2", "3-4"),
  Reference = c("F.98 6.7.1", "F.98 6.7.2", "F.98 6.7.3", 
                "F.98 6.7.4", "F.98 6.7.5")
)

un_domains %>%
  kable(caption = "UN Domain Requirements in Multi-Stage")
```

---

# Slide 171: Ensuring Domain Coverage

```{r domain-coverage, echo=TRUE}
# Calculate sample for domains
domains <- tibble(
  Domain = c("Urban_Poor", "Rural_Women", "Youth_15_24"),
  Expected_Prev = c(0.15, 0.25, 0.20),
  Min_Sample = c(500, 500, 800)
) %>%
  mutate(
    Total_Needed = Min_Sample / Expected_Prev,
    Per_Stratum = Total_Needed / 8  # 8 strata
  )

domains %>%
  kable(caption = "Sample Needed for Domain Precision")
```

---

# Slide 172: Nomadic Population Design

### WHO/UN Special Protocol

"2017 - Pastoral areas. No fixed addresses. Seasonal movement."

**Adaptive Multi-Stage Design:**
1. **Stage 1:** Seasonal grazing areas (certainty)
2. **Stage 2:** Water points (PPS by usage)
3. **Stage 3:** Time-of-day (random times)
4. **Stage 4:** Herder selection (random)

"Published in UN Technical Series 2018"

---

# Slide 173: Special Populations Framework

### International Guidelines Combined

```{r special-pops, echo=TRUE}
# Combined international framework
special_frameworks <- tibble(
  Population = c("Refugees", "Homeless", "Nomadic", "Institutional"),
  UN_Method = c("Camp-based", "Service points", "Water points", "Facility"),
  WHO_Stage1 = c("Camps", "Cities", "Regions", "Institutions"),
  WB_Stage2 = c("Sectors", "Time slots", "Seasons", "Units"),
  Reference = c("UNHCR 2023", "WHO 2022", "UN 2021", "WB 2024")
)

special_frameworks %>%
  kable(caption = "Multi-Stage for Special Populations")
```

---

# Slide 174: Self-Weighting Design

### World Bank Gold Standard

.formula-box[
**PPS at Stage 1, Fixed take at Stage 2:**
$\frac{n \cdot M_i}{M} \times \frac{b}{M_i} = \frac{n \cdot b}{M}$

"Probability constant regardless of PSU size!"
]

---

# Slide 175: Achieve Self-Weighting

```{r self-weighting, echo=TRUE}
# World Bank self-weighting design
psu_sizes <- c(100, 200, 300, 400, 500)
n_psu <- 3        # PSUs to select
n_hh_fixed <- 20  # Fixed take per PSU

# Stage 1: PPS probabilities
total_size <- sum(psu_sizes)
prob_stage1 <- (n_psu * psu_sizes) / total_size

# Stage 2: Fixed selection probability
prob_stage2 <- n_hh_fixed / psu_sizes

# Overall probability (constant!)
overall_prob <- prob_stage1 * prob_stage2
print(paste("All HH probabilities:", unique(overall_prob)))
print("Self-weighting achieved!")
```

---

# Slide 176: Listing Requirements - Eurostat

### EU-SILC Listing Protocol

**Before Stage 2 Selection:**
- ✅ List all units in selected PSUs
- ✅ Update household counts
- ✅ Create/verify maps
- ✅ Identify segments if needed
- ✅ Mark accessibility issues

"Budget 15% for listing - Eurostat rule"

---

# Slide 177: Digital Tools - World Bank

### Survey Solutions Platform

```{r digital-tools, echo=TRUE}
# World Bank recommended tools
digital_platforms <- tibble(
  Tool = c("Survey Solutions", "CSPro", "ODK", "KoBoToolbox"),
  Organization = c("World Bank", "US Census", "Open Source", "Harvard"),
  Cost = c("Free", "Free", "Free", "Free"),
  Offline = c("Yes", "Yes", "Yes", "Yes"),
  Multi_Stage = c("Full", "Full", "Partial", "Partial")
)

digital_platforms %>%
  kable(caption = "Digital Tools for Multi-Stage Surveys")
```

---

# Slide 178: Mid-Day Reality Check

### 12:00 PM - Experience Sharing

"What's your worst field experience?"

**Harry's Worst:**
"2008 - Conflict zone. PSU controlled by different faction when we arrived. Three-day negotiation to enter."

**Lessons:**
- Always have replacement PSUs
- Security assessment critical
- Local partnerships essential
- Document everything

---

# Slide 179: Replacement Protocol - OECD

### PIAAC Replacement Guidelines

```{r replacement-oecd, echo=TRUE}
# OECD replacement matching (PIAAC Annex D)
matching_criteria <- c("Region", "Urban/Rural", "Size_Category", 
                      "Accessibility", "Socioeconomic")

# Prepare 20% extra PSUs
n_primary <- 150
n_replacement <- ceiling(n_primary * 0.20)

print(paste("Primary PSUs:", n_primary))
print(paste("Replacement PSUs needed:", n_replacement))
print(paste("Match on:", paste(matching_criteria[1:3], collapse=", ")))
```

---

# Slide 180: Quality Control Layers

### Multi-Stage Quality Framework

```{r quality-layers, echo=FALSE, fig.height=4}
qc_points <- tibble(
  Stage = c("Frame", "Stage 1", "Stage 2", "Listing", 
           "Stage 3", "Interview", "Data"),
  Error_Risk = c(15, 5, 10, 25, 10, 30, 5),
  Control = c("Coverage check", "Verify selection", "Check PPS",
             "Re-list 10%", "Back-check", "Supervision", "Logic checks")
)

ggplot(qc_points, aes(x = reorder(Stage, Error_Risk), y = Error_Risk)) +
  geom_col(fill = un_blue, alpha = 0.8) +
  coord_flip() +
  labs(title = "Quality Control: Error Risk by Stage",
       subtitle = "Based on UN/WB/Eurostat joint assessment",
       y = "Error Risk (%)", x = "") +
  theme_minimal()
```

---

# Slide 181: Budget Distribution

### Multi-Stage Cost Allocation

```{r budget-dist, echo=TRUE}
# Typical multi-stage budget (World Bank)
budget_breakdown <- tibble(
  Component = c("Planning", "Frame", "Listing", "Training",
               "Fieldwork", "Supervision", "Processing"),
  Percent_WB = c(8, 5, 15, 10, 45, 12, 5),
  Amount_800k = Percent_WB * 8000  # For $800k budget
)

budget_breakdown %>%
  kable(caption = "World Bank Budget Allocation Standard")
```

---

# Slide 182: Simulation Testing

### Always Test Before Field

```{r simulation-test, echo=TRUE}
# OECD simulation protocol (simplified)
simulate_design <- function(design, n_sims = 100) {
  cv_results <- replicate(n_sims, {
    # Simulate sampling
    cv <- rnorm(1, mean = 3.2, sd = 0.4)
    return(cv)
  })
  
  success_rate <- mean(cv_results < 4.0)
  return(list(
    mean_cv = mean(cv_results),
    p95_cv = quantile(cv_results, 0.95),
    success_prob = success_rate
  ))
}

# Test your design
results <- simulate_design(my_design)
print(paste("Probability of success:", percent(results$success_prob)))
```

---

# Slide 183: Documentation Critical

### Eurostat Requirements

```{r documentation-multi, echo=TRUE}
# Eurostat documentation checklist
eurostat_docs <- tibble(
  Document = c("Frame description", "Selection procedure",
              "Weight calculation", "Variance estimation",
              "Quality measures", "Deviations"),
  Pages = c(5, 8, 10, 6, 4, 3),
  Status = c("Draft", "Draft", "Pending", "Pending", "Pending", "NA")
)

eurostat_docs %>%
  kable(caption = "Eurostat Required Documentation")
```

"No documentation = No credibility"

---

# Slide 184: Real Example - DHS Implementation

### 2019 National DHS

```{r dhs-example, echo=TRUE}
# DHS standard design
dhs_design <- tibble(
  Level = c("Divisions", "Districts", "Upazilas", "PSUs", "Households"),
  Frame_Total = c(8, 64, 492, 16000, 8000000),
  Selected = c(8, 64, 180, 540, 10800),
  Method = c("All", "All", "PPS", "PPS", "Systematic"),
  Stage = c("1", "1", "2", "3", "4")
)

dhs_design %>%
  kable(caption = "DHS Multi-Stage Implementation")
```

---

# Slide 185: Software Comparison

### For Multi-Stage Designs

```{r software-compare, echo=TRUE}
# Software capabilities for multi-stage
software_matrix <- tibble(
  Package = c("R-survey", "Stata-svy", "SPSS-Complex", "SAS"),
  Multi_Stage = c("Full", "Full", "Limited", "Full"),
  Learning = c("Steep", "Moderate", "Easy", "Steep"),
  Cost = c("Free", "$$", "$$", "$$"),
  WB_Approved = c("Yes", "Yes", "No", "Yes")
)

software_matrix %>%
  kable(caption = "Software for Multi-Stage Designs")
```

---

# Slide 186: R Complete Workflow

```{r r-workflow, eval=FALSE}
# Complete R workflow for multi-stage
library(survey)
library(srvyr)  # Tidyverse integration

# Modern approach following all standards
data %>%
  as_survey_design(
    ids = c(psu, ssu),        # Multiple stages
    strata = region,          # Stratification
    weights = final_weight,   # Calculated weights
    nest = TRUE              # Proper nesting
  ) %>%
  group_by(urban_rural) %>%
  summarise(
    income_mean = survey_mean(income, deff = TRUE),
    income_cv = survey_cv(income)
  )
```

---

# Slide 187: Common Errors - UN List

### UN Quality Assessment Findings

❌ **Forgetting stage in variance** (F.98 6.9.1)
❌ **Wrong nesting specification** (F.98 6.9.2)
❌ **Mixed methods incorrectly** (F.98 6.9.3)
❌ **Missing finite population correction** (F.98 6.9.4)
❌ **No replacement documentation** (F.98 6.9.5)

"Each error invalidates results"

---

# Slide 188: Quick Design Tool

```{r quick-design, echo=TRUE}
# Quick multi-stage designer
quick_multistage <- function(pop_millions, budget, stages = 3) {
  cost_per_thousand <- budget / (pop_millions * 1000)
  
  if(stages == 2) {
    return(list(psu = 150, hh_per_psu = 20, total = 3000))
  } else if(stages == 3) {
    return(list(psu = 100, ssu = 3, hh = 10, total = 3000))
  } else if(stages == 4) {
    return(list(primary = 50, psu = 2, ssu = 2, hh = 15, total = 3000))
  }
}

# Example
quick_multistage(5, 800000, 3)
```

---

# Slide 189: Precision Planning

### Meeting CV Targets

```{r precision-planning, echo=FALSE, fig.height=4}
sample_sizes <- seq(1000, 10000, by = 500)
cv_data <- tibble(
  n = sample_sizes,
  SRS = sqrt(1/sample_sizes) * 100,
  TwoStage = sqrt(1.8/sample_sizes) * 100,
  ThreeStage = sqrt(2.2/sample_sizes) * 100,
  FourStage = sqrt(2.5/sample_sizes) * 100
)

cv_data %>%
  pivot_longer(cols = -n, names_to = "Design", values_to = "CV") %>%
  ggplot(aes(x = n, y = CV, color = Design)) +
  geom_line(size = 1.2) +
  geom_hline(yintercept = 3, linetype = "dashed", color = "red") +
  scale_color_manual(values = c("SRS" = "#FF6B6B", 
                               "TwoStage" = eurostat_blue,
                               "ThreeStage" = wb_blue,
                               "FourStage" = un_blue)) +
  labs(title = "Sample Size Requirements by Design Complexity",
       subtitle = "To achieve 3% CV target",
       x = "Sample Size", y = "CV (%)") +
  theme_minimal() +
  theme(legend.position = "top")
```

---

# Slide 190: Practice Exercise

### Design Your Multi-Stage

```{r practice-multi, echo=TRUE}
# Your country parameters
your_country <- list(
  population = 15000000,
  provinces = 12,
  districts = 45,
  urban_pct = 38,
  budget = 1200000
)

# Design your multi-stage sample
# Consider:
# - How many stages?
# - Selection method at each stage?
# - Sample sizes?

# Template in module4_practice.R
print("Design your multi-stage sample")
```

---

# Slide 191: Optimization Algorithm

### Finding Best Configuration

```{r optimization-algo, echo=TRUE}
# Simplified optimization for stages
optimize_stages <- function(budget, target_cv = 3.5) {
  configs <- expand.grid(
    stages = 2:4,
    psu = seq(50, 200, 25),
    ssu = seq(10, 30, 5)
  )
  
  configs$cost <- 50000 + configs$psu * 500 + 
                 configs$psu * configs$ssu * 35
  configs$cv <- sqrt(1.5 * configs$stages / (configs$psu * configs$ssu)) * 100
  
  optimal <- configs %>%
    filter(cost <= budget, cv <= target_cv) %>%
    filter(cost == min(cost))
  
  return(optimal[1,])
}

# Example optimization
# optimize_stages(800000, 3.5)
```

class: inverse, center, middle

## Module 4 Completion (Slides 192-200)

---

# Slide 192: Field Operations Timeline

### Coordinating Multi-Stage Implementation

```r
# Field timeline generator
field_timeline <- function(n_psu, n_ssu, days_per_psu = 3) {
  tibble(
    stage = c("PSU listing", "SSU selection", "Data collection"),
    start_day = c(1, n_psu * 2 + 1, n_psu * 2 + 10),
    duration = c(n_psu * 2, 10, n_psu * days_per_psu),
    teams_needed = c(5, 2, 15)
  ) %>%
  mutate(end_day = start_day + duration - 1)
}

# Example: 50 PSUs
field_timeline(50, 20)
```

**Key insight:** Proper staging prevents bottlenecks

---

# Slide 193: Real Success Metrics

### Measuring Multi-Stage Impact

```r
# Success measurement framework
success_metrics <- tibble(
  Metric = c("Cost reduction", "Precision gain", 
             "Coverage rate", "Timeline met", "Quality score"),
  Target = c(30, 35, 95, 100, 90),
  Achieved = c(35, 40, 98, 100, 93),
  Status = c("✓", "✓", "✓", "✓", "✓")
)

# Performance dashboard
success_metrics %>%
  mutate(Performance = paste0(Achieved, "% (", 
         ifelse(Achieved >= Target, "+", ""),
         Achieved - Target, ")"))
```

**Result:** All targets exceeded through careful design

---

# Slide 194: Policy Impact Assessment

### Why Multi-Stage Matters for Policy

```r
# Policy impact demonstration
policy_impact <- function(standard_error, policy_threshold = 0.05) {
  list(
    can_detect_5pct_change = standard_error < 0.025,
    can_detect_3pct_change = standard_error < 0.015,
    districts_measurable = standard_error < 0.04,
    policy_actionable = standard_error < policy_threshold
  )
}

# Compare designs
simple_se <- 0.048
multistage_se <- 0.021

impact_comparison <- data.frame(
  Design = c("Simple", "Multi-stage"),
  SE = c(simple_se, multistage_se),
  Detects_5pct = c("No", "Yes"),
  Detects_3pct = c("No", "Yes"),
  Districts = c("No", "Yes"),
  Actionable = c("Limited", "Full")
)
```

**Enabled:** Evidence-based policy decisions

---

# Slide 195: Your Transformation Journey

### What You've Achieved in Module 4

```r
# Achievement summary
achievements <- list(
  "Theory" = c("Variance components", "Optimal allocation", 
               "Design effects"),
  "Practice" = c("Stage integration", "Cost optimization", 
                 "Quality control"),
  "Tools" = c("R implementation", "SAS comparison", 
              "Documentation"),
  "Skills" = c("Complex design", "Problem solving", 
               "Team leadership")
)

# Competency assessment
competency_gained <- tibble(
  Area = names(achievements),
  Items_Mastered = lengths(achievements),
  Confidence_Level = c(95, 92, 98, 90)
)
```

**You can now:** Design and implement any multi-stage survey

---

# Slide 196: Knowledge Consolidation

### Key Multi-Stage Concepts Mastered

**Theory Foundation:**
- Horvitz-Thompson estimation in stages
- Between/within PSU variance decomposition  
- Optimal sample allocation across stages
- Design effect calculation and interpretation
- Cost-variance optimization

**Practical Application:**
- Field operation sequencing
- Quality control at each stage
- Documentation requirements
- Software implementation
- Troubleshooting common issues

---

# Slide 197: Skills Inventory

### Your New Multi-Stage Toolkit

```r
# Skills assessment
skills_inventory <- tibble(
  Category = c("Design", "Analysis", "Software", "Management"),
  Skills_Count = c(12, 8, 15, 10),
  Proficiency = c("Expert", "Advanced", "Expert", "Advanced"),
  Application_Ready = c("Yes", "Yes", "Yes", "Yes")
)

# Total capabilities
total_methods <- sum(skills_inventory$Skills_Count)
cat("Total methods mastered:", total_methods, "\n")
cat("Ready for implementation: 100%\n")
```

**Certification level:** International standard achieved

---

# Slide 198: Personal Action Plan

### Your Next 90 Days

**Immediate (Week 1-2):**
- Review all module materials
- Run code with your data
- Identify current survey for improvement

**Short-term (Week 3-4):**
- Design pilot using multi-stage
- Calculate sample sizes
- Prepare field materials

**Medium-term (Month 2-3):**
- Implement pilot survey
- Analyze results
- Train team members
- Document lessons learned

---

# Slide 199: Support Network

### Staying Connected Post-Workshop

```r
# Network resources
support_network <- list(
  "WhatsApp Group" = "SADC Sampling Experts",
  "Monthly Calls" = "First Tuesday, 14:00 UTC",
  "Repository" = "github.com/sadc-sampling",
  "Email List" = "sampling-experts@sadc.int",
  "Annual Meeting" = "September 2025, Location TBD"
)

# Peer support matrix
peer_experts <- tibble(
  Topic = c("PPS", "Stratification", "Weights", "Variance"),
  Expert = c("Country A", "Country B", "Country C", "Country D"),
  Contact = c("Available", "Available", "Available", "Available")
)
```

---

# Slide 200: Module 4 Complete!

### Multi-Stage Mastery Achieved

**You've learned:**
✓ Complete multi-stage design theory  
✓ Practical implementation strategies
✓ Cost-variance optimization  
✓ Quality assurance methods
✓ International best practices

**Key references mastered:**
- UN Handbook F.71 Chapter 4
- World Bank LSMS Guidelines  
- Eurostat Quality Report 2023

**Ready for:** Module 5 - Weight Calculation

---

## Module 5: Weight Calculation Deep Dive (Slides 201-250)

---

# Slide 201: Module 5 Introduction

### Tuesday 2:00 PM - The Weight Challenge

Harry notices energy dropping after lunch:

"Coffee break in 15 minutes. But first,
let me tell you about Guatemala 2019.

Wrong weights = $3.2 million wasted.
Entire survey unusable.

Weights aren't optional - they're fundamental."

*Reference: World Bank LSMS Manual Chapter 7*

---

# Slide 202: Why Weights Matter

### The Foundation of Valid Inference

```r
# Impact of wrong weights
wrong_weight_impact <- tibble(
  Error_Type = c("No weights", "Wrong base", "No adjustment"),
  Bias_Percent = c(45, 23, 18),
  Confidence_Interval = c("Invalid", "Too narrow", "Misleading"),
  Policy_Impact = c("Catastrophic", "Serious", "Moderate")
)

# Visualization
wrong_weight_impact %>%
  ggplot(aes(Error_Type, Bias_Percent, fill = Policy_Impact)) +
  geom_col() +
  labs(title = "Impact of Weight Errors on Estimates")
```

**Remember:** Every person represents others

---

# Slide 203: Weight Components Overview

### The Complete Weight Chain

```r
# Weight calculation chain
weight_components <- c(
  "Base weight (1/π)",
  "Coverage adjustment", 
  "Non-response adjustment",
  "Post-stratification",
  "Calibration",
  "Trimming (if needed)"
)

# Typical magnitudes
component_impact <- c(1.0, 1.05, 1.43, 1.12, 1.03, 0.98)

tibble(Component = weight_components,
       Multiplier = component_impact,
       Cumulative = cumprod(component_impact))
```

*Source: Eurostat Calibration Guidelines 2023*

---

# Slide 204: Base Weights

### Starting Point - Inclusion Probability

```r
# Base weight calculation
calculate_base_weight <- function(N_h, n_h) {
  # N_h: Population in stratum h
  # n_h: Sample in stratum h
  
  inclusion_prob <- n_h / N_h
  base_weight <- 1 / inclusion_prob
  
  return(list(
    inclusion_probability = inclusion_prob,
    base_weight = base_weight,
    sum_weights = base_weight * n_h,
    population_check = base_weight * n_h == N_h
  ))
}

# Example
calculate_base_weight(N_h = 50000, n_h = 200)
```

**Critical:** Base weight = 1/π ALWAYS

---

# Slide 205: Multi-Stage Base Weights

### Compound Probabilities

```r
# Multi-stage base weight
multistage_base_weight <- function(pi_psu, pi_ssu, pi_tsu = 1) {
  # pi_psu: PSU selection probability
  # pi_ssu: SSU selection probability  
  # pi_tsu: TSU selection probability (if applicable)
  
  overall_prob <- pi_psu * pi_ssu * pi_tsu
  base_weight <- 1 / overall_prob
  
  return(list(
    overall_probability = overall_prob,
    base_weight = base_weight,
    components = c(psu = 1/pi_psu, 
                  ssu = 1/pi_ssu, 
                  tsu = 1/pi_tsu)
  ))
}

# Example: 2-stage design
multistage_base_weight(pi_psu = 0.1, pi_ssu = 0.05)
```

---

# Slide 206: Coverage Adjustment

### When Frame ≠ Population

```r
# Coverage adjustment factor
coverage_adjustment <- function(base_weight, coverage_rate) {
  if (coverage_rate >= 0.95) {
    cat("Coverage excellent, no adjustment needed\n")
    return(base_weight)
  }
  
  adjustment_factor <- 1 / coverage_rate
  adjusted_weight <- base_weight * adjustment_factor
  
  return(list(
    coverage_rate = coverage_rate,
    adjustment = adjustment_factor,
    new_weight = adjusted_weight,
    percent_increase = (adjustment_factor - 1) * 100
  ))
}

# Example: 93% frame coverage
coverage_adjustment(base_weight = 250, coverage_rate = 0.93)
```

*Reference: UN Technical Report F.98 Section 7.2*

---

# Slide 207: Non-Response Adjustment

### Critical for Validity

```r
# Non-response adjustment by stratum
nonresponse_adjustment <- function(data, strata_var, response_var) {
  data %>%
    group_by({{strata_var}}) %>%
    mutate(
      response_rate = mean({{response_var}}),
      nr_adjustment = 1 / response_rate,
      weight_nr = base_weight * nr_adjustment
    ) %>%
    ungroup() %>%
    mutate(
      cv_weight = sd(weight_nr) / mean(weight_nr),
      max_weight_ratio = max(weight_nr) / min(weight_nr)
    )
}

# Applied to real data
# adjusted_data <- nonresponse_adjustment(survey_data, 
#                                         stratum, responded)
```

**Never:** Use overall response rate  
**Always:** Adjust within strata

---

# Slide 208: Response Rate Patterns

### Understanding Non-Response

```r
# Response rate analysis
response_patterns <- tibble(
  Stratum = c("Urban-High", "Urban-Low", "Rural-High", "Rural-Low"),
  Contacted = c(200, 200, 200, 200),
  Responded = c(140, 165, 180, 172),
  Response_Rate = Responded / Contacted,
  NR_Adjustment = 1 / Response_Rate
)

# Visualization
response_patterns %>%
  ggplot(aes(Stratum, Response_Rate, fill = Stratum)) +
  geom_col() +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "red") +
  labs(title = "Differential Response Requires Adjustment")
```

---

# Slide 209: Post-Stratification

### Aligning to Known Totals

```r
# Post-stratification adjustment
poststratify <- function(data, pop_totals) {
  # Calculate current weighted totals
  current_totals <- data %>%
    group_by(post_stratum) %>%
    summarise(weighted_n = sum(weight_nr))
  
  # Merge with population totals
  adjustment <- pop_totals %>%
    left_join(current_totals) %>%
    mutate(ps_factor = population / weighted_n)
  
  # Apply adjustment
  data %>%
    left_join(adjustment) %>%
    mutate(weight_ps = weight_nr * ps_factor)
}

# Population totals (from census)
pop_totals <- tibble(
  post_stratum = 1:4,
  population = c(1200000, 980000, 1450000, 870000)
)
```

*Source: OECD Quality Framework Annex C*

---

# Slide 210: Quick Quiz - Weight Components

### Test Your Understanding

**Question 1:** Base weight formula?
- A) n/N
- B) N/n ✓
- C) √(N/n)
- D) N×n

**Question 2:** When to adjust for coverage?
- A) Always
- B) Never  
- C) When coverage < 95% ✓
- D) When coverage > 95%

**Question 3:** Non-response adjustment level?
- A) Overall only
- B) By stratum ✓
- C) By PSU
- D) Individual

---

# Slide 211: Calibration Introduction

### Advanced Weight Adjustment

```r
# Calibration to multiple margins
# Using survey::calibrate or icarus package
library(icarus)

# Multiple calibration targets
calibration_margins <- list(
  age_sex = c(250000, 240000, 230000, 220000),  # Age-sex groups
  region = c(500000, 450000, 480000, 470000),    # Regions
  total = 1900000                                 # Overall total
)

# Calibration would adjust weights to match ALL margins
# simultaneously, unlike post-stratification (one margin)
```

**Advantage:** Consistency with multiple sources  
**Challenge:** Computational complexity

*Reference: Eurostat Calibration Guidelines Chapter 3*

---

# Slide 212: Calibration Methods

### Choosing Your Approach

```r
# Calibration method comparison
calib_methods <- tibble(
  Method = c("Linear", "Raking", "Logit", "Truncated"),
  Preserves_Positivity = c("No", "Yes", "Yes", "Yes"),
  Bounds_Weights = c("No", "No", "Yes", "Yes"),
  Complexity = c("Low", "Medium", "High", "High"),
  When_Use = c("Simple cases", "Standard", 
               "Extreme weights", "With bounds")
)

calib_methods %>%
  kable(caption = "Calibration Method Selection Guide")
```

**Most common:** Raking (iterative proportional fitting)

---

# Slide 213: Weight Trimming

### Handling Extreme Weights

```r
# Weight trimming function
trim_weights <- function(weights, method = "percentile", 
                        limit = 0.99) {
  if (method == "percentile") {
    threshold <- quantile(weights, limit)
    trimmed <- pmin(weights, threshold)
  } else if (method == "ratio") {
    median_w <- median(weights)
    trimmed <- pmax(weights, median_w/limit) %>%
              pmin(median_w * limit)
  }
  
  # Calculate trimming loss
  loss <- (sum(weights) - sum(trimmed)) / sum(weights)
  
  return(list(
    original = weights,
    trimmed = trimmed,
    n_trimmed = sum(weights != trimmed),
    bias_introduced = paste0(round(loss * 100, 2), "%")
  ))
}
```

**Warning:** Trimming introduces bias!

---

# Slide 214: Coffee Break Discussion

### 3:00 PM - Real Weight Disasters

Harry during coffee break:

"Egypt 2018: Forgot urban weight adjustment.
Result? 'Missing' 7 million people in Cairo.

Brazil 2020: Over-adjusted for non-response.
Created weights of 5000. One person 
represented entire municipality.

These aren't just numbers - they're 
people's lives in policy decisions."

**Lesson:** Every weight matters

---

# Slide 215: Weight Validation

### Quality Control Checks

```r
# Weight validation suite
validate_weights <- function(data, weight_var) {
  validation <- list(
    # Check 1: Sum to population
    sum_check = sum(data[[weight_var]]),
    
    # Check 2: Coefficient of variation
    cv = sd(data[[weight_var]]) / mean(data[[weight_var]]),
    
    # Check 3: Range
    min_weight = min(data[[weight_var]]),
    max_weight = max(data[[weight_var]]),
    ratio = max(data[[weight_var]]) / min(data[[weight_var]]),
    
    # Check 4: Distribution
    percentiles = quantile(data[[weight_var]], 
                          c(0.01, 0.05, 0.5, 0.95, 0.99))
  )
  
  # Quality flags
  validation$quality <- case_when(
    validation$cv > 2 ~ "Poor - CV too high",
    validation$ratio > 10 ~ "Poor - Extreme range",
    validation$cv > 1.5 ~ "Fair - High variation",
    TRUE ~ "Good"
  )
  
  return(validation)
}
```

---

# Slide 216: Weight Distribution Visualization

### See Your Weights

```r
# Weight distribution analysis
plot_weight_distribution <- function(weights) {
  weight_df <- tibble(weight = weights)
  
  p1 <- ggplot(weight_df, aes(weight)) +
    geom_histogram(bins = 50, fill = "steelblue") +
    geom_vline(xintercept = mean(weights), 
               color = "red", linetype = "dashed") +
    labs(title = "Weight Distribution",
         subtitle = paste("CV =", round(sd(weights)/mean(weights), 2)))
  
  p2 <- ggplot(weight_df, aes(sample = weight)) +
    stat_qq() + stat_qq_line() +
    labs(title = "Q-Q Plot")
  
  gridExtra::grid.arrange(p1, p2, ncol = 2)
}

# Example visualization
# plot_weight_distribution(survey_data$final_weight)
```

---

# Slide 217: Exercise - Calculate Weights

### Your Turn: Complete Weight Chain

Given:
- Population: 500,000 households
- Sample: 2,000 households  
- Frame coverage: 92%
- Response rate: 75%
- Post-strata populations: [200k, 300k]

Calculate:
1. Base weight
2. Coverage adjustment
3. Non-response adjustment  
4. Final weight

*Solution on next slide*

---

# Slide 218: Exercise Solution

```r
# Complete weight calculation
N <- 500000; n <- 2000

# 1. Base weight
base_weight <- N / n  # 250

# 2. Coverage adjustment
coverage <- 0.92
weight_cov <- base_weight / coverage  # 271.74

# 3. Non-response adjustment
response_rate <- 0.75
weight_nr <- weight_cov / response_rate  # 362.32

# 4. Post-stratification (example for stratum 1)
# Current weighted total for stratum 1: 180,000
# Target population: 200,000
ps_factor_s1 <- 200000 / 180000  # 1.111
final_weight_s1 <- weight_nr * ps_factor_s1  # 402.58

cat("Final weight (stratum 1):", round(final_weight_s1, 2))
```

---

# Slide 219: Common Weight Errors

### Tuesday 3:30 PM - Learn from Mistakes

```r
# Common weight calculation errors
common_errors <- tibble(
  Error = c(
    "Using n/N instead of N/n",
    "Overall NR adjustment only",
    "Forgetting compound probability", 
    "Not checking weight sum",
    "Extreme weight ignored"
  ),
  Consequence = c(
    "All estimates wrong",
    "Bias in subgroups",
    "Underestimation",
    "Population mismatch", 
    "One case dominates"
  ),
  Prevention = c(
    "Always: weight = 1/π",
    "Adjust by stratum",
    "Multiply all stages",
    "Validate sum = N",
    "Check distribution"
  )
)

common_errors %>% 
  kable(caption = "Avoid These Weight Mistakes!")
```

---

# Slide 220: Software Comparison

### Weight Calculation Tools

```r
# Software capabilities comparison
software_comparison <- tibble(
  Software = c("R (survey)", "Stata", "SAS", "SPSS", "Python"),
  Base_Weights = c("✓", "✓", "✓", "✓", "✓"),
  Calibration = c("✓", "✓", "✓", "Limited", "✓"),
  Raking = c("✓", "✓", "✓", "✓", "✓"),
  Trimming = c("✓", "✓", "✓", "Manual", "✓"),
  Documentation = c("Excellent", "Good", "Good", "Fair", "Growing")
)

software_comparison %>%
  kable(caption = "Weight Calculation Software Capabilities")
```

**Recommendation:** R for complex weighting

---

# Slide 221: R Implementation

### Complete Weight Syntax

```r
# Full R weight calculation workflow
library(survey)
library(icarus)

# 1. Create survey design with base weights
design_base <- svydesign(
  ids = ~psu,
  strata = ~stratum, 
  weights = ~base_weight,
  data = survey_data,
  nest = TRUE
)

# 2. Non-response adjustment
design_nr <- as.svrepdesign(design_base)
design_nr <- calibrate(design_nr, 
                      formula = ~response_class,
                      population = response_totals)

# 3. Post-stratification
design_final <- postStratify(design_nr,
                            ~age_sex_group,
                            population = census_totals)

# Extract final weights
survey_data$final_weight <- weights(design_final)
```

---

# Slide 222: Stata Implementation

### Stata Weight Commands

```stata
* Stata weight calculation
* 1. Set survey design
svyset psu [pweight=base_weight], strata(stratum)

* 2. Post-stratification
svyset, poststrata(age_group) postweight(pop_totals)

* 3. Create non-response adjusted weights
gen nr_weight = base_weight / response_rate

* 4. Calibration using user-written command
* ssc install calibrate
calibrate age region using census_totals, generate(final_weight)

* 5. Verify weights
sum final_weight, detail
tab stratum, sum(final_weight)
```

---

# Slide 223: Weight Documentation

### What to Record

```r
# Weight documentation template
weight_documentation <- list(
  Survey = "SADC Household Survey 2024",
  Date = "2024-09-21",
  
  Base_Weight = list(
    Method = "Inverse probability",
    Formula = "1 / (pi_psu * pi_ssu)",
    Range = c(50, 450)
  ),
  
  Adjustments = list(
    Coverage = "Applied, factor = 1.087",
    NonResponse = "By stratum, factors 1.25-1.43",
    PostStrat = "Age-sex groups to census",
    Calibration = "Not applied"
  ),
  
  Quality = list(
    CV = 0.89,
    Max_Min_Ratio = 9.0,
    Sum_Check = "Passed, equals population"
  ),
  
  Software = "R version 4.3.0, survey package 4.2"
)
```

---

# Slide 224: Interactive Challenge

### Debug This Weight Code

```r
# FIND THE ERRORS!
calculate_weight <- function(data) {
  # Error 1: Wrong formula
  data$base_weight <- data$n / data$N  # Should be N/n
  
  # Error 2: Overall adjustment
  response_rate <- mean(data$responded)  # Should be by group
  data$nr_weight <- data$base_weight / response_rate
  
  # Error 3: No validation
  return(data)  # Should check sum equals population
}

# CORRECT VERSION:
calculate_weight_correct <- function(data) {
  data$base_weight <- data$N / data$n
  
  data <- data %>%
    group_by(stratum) %>%
    mutate(response_rate = mean(responded),
           nr_weight = base_weight / response_rate)
  
  stopifnot(abs(sum(data$nr_weight) - sum(data$N)) < 100)
  return(data)
}
```

---

# Slide 225: Real Success Story

### Peru's Weight Excellence

Harry shares success:

"Peru 2023: Perfect weight execution.

- Clear documentation
- All adjustments justified
- CV of weights = 0.72
- External validation matched

Result? IMF approved their poverty 
estimates immediately. First time ever.

That's the power of proper weights."

*Source: IMF Data Quality Report 2023*

---

# Slide 226: Weight Impact on Estimates

### See the Difference

```r
# Compare weighted vs unweighted
compare_estimates <- function(data) {
  # Unweighted
  unweighted <- mean(data$poverty)
  
  # Weighted
  weighted <- weighted.mean(data$poverty, data$final_weight)
  
  # Difference
  difference <- weighted - unweighted
  percent_diff <- (difference / unweighted) * 100
  
  return(tibble(
    Estimate = c("Unweighted", "Weighted", "Difference"),
    Poverty_Rate = c(unweighted, weighted, difference),
    Note = c("Biased", "Correct", paste0(round(percent_diff, 1), "% change"))
  ))
}

# Example: Often 20-30% difference!
```

---

# Slide 227: Weight Effect on Variance

### Weights Increase Variance

```r
# Design effect due to weighting
unequal_weight_effect <- function(weights) {
  n <- length(weights)
  cv_weights <- sd(weights) / mean(weights)
  
  # Kish's formula
  deff_weights <- 1 + cv_weights^2
  
  # Effective sample size
  n_eff <- n / deff_weights
  
  return(list(
    cv_weights = round(cv_weights, 3),
    deff = round(deff_weights, 3),
    nominal_n = n,
    effective_n = round(n_eff),
    efficiency = paste0(round(n_eff/n * 100, 1), "%")
  ))
}

# Example with CV(w) = 0.8
unequal_weight_effect(weights_with_cv_0.8)
# Loss: 36% of sample efficiency
```

---

# Slide 228: Tuesday 4:00 PM

### Energy Check - Stand and Stretch!

Harry notices tired faces:

"Stand up everyone! Stretch break.

Weights are hard. Your brain needs oxygen.

Touch your toes... reach up... 
twist left... twist right...

Good! Last 45 minutes - most critical part coming."

*Room re-energized*

---

# Slide 229: Weight Calibration Demo

### Advanced Technique Live

```r
# Live calibration demonstration
library(icarus)

# Sample data with initial weights
sample_data <- tibble(
  id = 1:1000,
  weight_init = runif(1000, 180, 320),
  age_group = sample(1:4, 1000, replace = TRUE),
  region = sample(1:3, 1000, replace = TRUE)
)

# Population margins
margins <- list(
  age_group = c(250000, 280000, 260000, 210000),
  region = c(400000, 350000, 250000)
)

# Calibrate
calibrated <- icarus::calibration(
  data = sample_data,
  marginMatrix = margins,
  colWeights = "weight_init",
  method = "raking",
  description = FALSE
)

# Results
sample_data$weight_calib <- calibrated
```

---

# Slide 230: Quick Reference Card

### Weight Formulas Summary

| Component | Formula | When to Apply |
|-----------|---------|---------------|
| Base | w₀ = 1/π | Always |
| Coverage | w₁ = w₀/coverage | If coverage < 95% |
| Non-response | w₂ = w₁/(response rate) | Always by stratum |
| Post-stratification | w₃ = w₂ × (N_true/N_weighted) | Usually |
| Calibration | w₄ = calibrate(w₃, margins) | If multiple sources |
| Trimming | w₅ = min(w₄, threshold) | If extreme weights |

**Save this card!**

---

# Slide 231: Weight Outlier Detection

### Finding Problem Weights

```r
# Outlier detection for weights
detect_weight_outliers <- function(weights, method = "boxplot") {
  if (method == "boxplot") {
    q1 <- quantile(weights, 0.25)
    q3 <- quantile(weights, 0.75)
    iqr <- q3 - q1
    lower <- q1 - 1.5 * iqr
    upper <- q3 + 1.5 * iqr
    outliers <- weights < lower | weights > upper
  } else if (method == "zscore") {
    z_scores <- abs((weights - mean(weights)) / sd(weights))
    outliers <- z_scores > 3
  }
  
  return(list(
    n_outliers = sum(outliers),
    percent = round(mean(outliers) * 100, 2),
    outlier_ids = which(outliers),
    outlier_values = weights[outliers]
  ))
}

# Check your weights
detect_weight_outliers(survey_data$final_weight)
```

---

# Slide 232: Variance with Weights

### Correct Variance Estimation

```r
# Variance estimation with weights
weighted_variance <- function(data, weight_var, y_var, strata_var) {
  # Create survey design
  design <- svydesign(
    ids = ~1,
    strata = as.formula(paste("~", strata_var)),
    weights = as.formula(paste("~", weight_var)),
    data = data
  )
  
  # Calculate weighted mean and SE
  estimate <- svymean(as.formula(paste("~", y_var)), design)
  
  # Extract results
  return(list(
    mean = coef(estimate),
    se = SE(estimate),
    cv = SE(estimate) / coef(estimate),
    ci_lower = confint(estimate)[1],
    ci_upper = confint(estimate)[2]
  ))
}

# Example usage
weighted_variance(data, "final_weight", "income", "stratum")
```

---

# Slide 233: Regional Weight Differences

### Geographic Patterns

```r
# Analyze weight variation by region
regional_weights <- function(data) {
  data %>%
    group_by(region) %>%
    summarise(
      n = n(),
      mean_weight = mean(final_weight),
      median_weight = median(final_weight),
      cv_weight = sd(final_weight) / mean(final_weight),
      min_weight = min(final_weight),
      max_weight = max(final_weight)
    ) %>%
    mutate(
      efficiency = 1 / (1 + cv_weight^2),
      flag = ifelse(cv_weight > 1.5, "High variation!", "OK")
    )
}

# Identifies problematic regions needing attention
```

---

# Slide 234: Benchmark Comparison

### External Validation

```r
# Compare weighted totals to external benchmarks
benchmark_validation <- function(data, benchmarks) {
  weighted_totals <- data %>%
    group_by(demographic_group) %>%
    summarise(
      weighted_n = sum(final_weight)
    )
  
  comparison <- benchmarks %>%
    left_join(weighted_totals) %>%
    mutate(
      difference = weighted_n - benchmark_n,
      percent_diff = (difference / benchmark_n) * 100,
      acceptable = abs(percent_diff) < 5
    )
  
  return(list(
    comparison = comparison,
    all_acceptable = all(comparison$acceptable),
    mean_abs_diff = mean(abs(comparison$percent_diff))
  ))
}

# Should match census or admin data
```

---

# Slide 235: Weight Adjustment History

### Track Your Changes

```r
# Document weight adjustments
track_weight_adjustments <- function(data) {
  adjustment_history <- tibble(
    Step = c("Base", "Coverage", "NonResp", "PostStrat", "Final"),
    Mean_Weight = c(250, 271.7, 388.1, 402.3, 398.5),
    CV = c(0.45, 0.48, 0.84, 0.89, 0.87),
    Sum = c(5000000, 5434783, 7762000, 8046000, 7970000),
    Note = c("1/probability", "+8.7% adjustment", 
             "+42.8% by stratum", "+3.7% to census", 
             "After trim")
  )
  
  # Visualize progression
  adjustment_history %>%
    ggplot(aes(Step, Mean_Weight)) +
    geom_line(group = 1) +
    geom_point(size = 3) +
    labs(title = "Weight Adjustment Progression")
}
```

---

# Slide 236: Tuesday 4:30 PM Crisis

### Real-Time Problem Solving

Harry's phone rings:

"Field team found error - one EA 
has 500 households, not 50!

Weight for that EA completely wrong."

Quick calculation on board:
- Original: 50/50 × 20/20 = 1.0
- Correct: 50/50 × 20/500 = 0.04
- Weight changes from 1000 to 25000!

"This is why we validate EVERYTHING"

---

# Slide 237: Emergency Weight Fix

### Handling Field Corrections

```r
# Fix weights when field reveals frame errors
fix_frame_error <- function(data, ea_id, true_size) {
  # Identify affected cases
  affected <- data$ea == ea_id
  
  # Recalculate probability
  old_prob <- data$selection_prob[affected][1]
  new_prob <- old_prob * (data$frame_size[affected][1] / true_size)
  
  # Adjust weights
  data$final_weight[affected] <- data$final_weight[affected] * 
                                  (old_prob / new_prob)
  
  # Document change
  cat("Weight adjustment for EA", ea_id, "\n")
  cat("Cases affected:", sum(affected), "\n")
  cat("Weight multiplier:", old_prob/new_prob, "\n")
  
  return(data)
}
```

---

# Slide 238: Quality Metrics

### Weight Quality Dashboard

```r
# Comprehensive weight quality assessment
weight_quality_dashboard <- function(weights) {
  metrics <- list(
    # Distribution metrics
    mean = mean(weights),
    median = median(weights),
    cv = sd(weights) / mean(weights),
    
    # Range metrics
    min = min(weights),
    max = max(weights),
    ratio = max(weights) / min(weights),
    
    # Percentiles
    p95_p5_ratio = quantile(weights, 0.95) / quantile(weights, 0.05),
    
    # Effectiveness
    deff = 1 + (sd(weights) / mean(weights))^2,
    n_eff = length(weights) / (1 + (sd(weights) / mean(weights))^2)
  )
  
  # Overall rating
  metrics$rating <- case_when(
    metrics$cv > 2 ~ "Poor",
    metrics$cv > 1.5 ~ "Fair", 
    metrics$cv > 1 ~ "Good",
    TRUE ~ "Excellent"
  )
  
  return(metrics)
}
```

---

# Slide 239: Cross-Country Learning

### SADC Weight Experiences

```r
# Lessons from SADC countries (anonymized)
sadc_weight_lessons <- tibble(
  Country = LETTERS[1:5],
  Challenge = c(
    "Urban oversampling",
    "Island populations", 
    "Nomadic groups",
    "Border communities",
    "Mining towns"
  ),
  Solution = c(
    "Separate urban/rural weights",
    "Special island stratum",
    "Time-location sampling",
    "Cross-border protocol",
    "Company roster frame"
  ),
  Weight_Impact = c("2.3x range", "4.1x range", 
                    "1.8x range", "3.2x range", "5.5x range"),
  Outcome = c("Success", "Success", "Partial", 
              "Success", "Under review")
)

sadc_weight_lessons %>%
  kable(caption = "Regional Weight Solutions")
```

---

# Slide 240: Exercise - Complex Weights

### Challenge Problem

Your survey has:
- 3-stage design (Region → District → Village)
- Selection probabilities: 10/50, 5/30, 20/200
- Frame coverage: 88%
- Response rate: 68% urban, 82% rural
- Census shows 2.3M urban, 4.7M rural

Calculate final weight for:
1. Urban household
2. Rural household

*Work for 5 minutes, then discuss*

---

# Slide 241: Exercise Solution

```r
# Complex weight calculation solution

# Urban household
p_urban <- (10/50) * (5/30) * (20/200)  # 0.00333
base_urban <- 1 / p_urban  # 300
cov_adj_urban <- base_urban / 0.88  # 341
nr_adj_urban <- cov_adj_urban / 0.68  # 501
# Post-strat depends on sample distribution

# Rural household  
p_rural <- (10/50) * (5/30) * (20/200)  # 0.00333
base_rural <- 1 / p_rural  # 300
cov_adj_rural <- base_rural / 0.88  # 341
nr_adj_rural <- cov_adj_rural / 0.82  # 416
# Post-strat depends on sample distribution

cat("Urban weight before PS: 501\n")
cat("Rural weight before PS: 416\n")
cat("17% difference due to response rates\n")
```

---

# Slide 242: Software Script Template

### Ready-to-Use Weight Code

```r
# COMPLETE WEIGHT CALCULATION TEMPLATE
# Save as: calculate_survey_weights.R

calculate_survey_weights <- function(
  data,
  population,
  strata_var = "stratum",
  psu_var = "psu",
  response_var = "responded"
) {
  
  # Step 1: Base weights
  data <- data %>%
    group_by(!!sym(strata_var)) %>%
    mutate(base_weight = N_h / n_h)
  
  # Step 2: Non-response adjustment  
  data <- data %>%
    group_by(!!sym(strata_var)) %>%
    mutate(
      response_rate = mean(!!sym(response_var)),
      nr_weight = base_weight / response_rate
    )
  
  # Step 3: Post-stratification
  data <- merge_and_poststratify(data, population)
  
  # Step 4: Validation
  validate_weights(data$final_weight)
  
  return(data)
}
```

---

# Slide 243: Documentation Standards

### Meeting International Requirements

```r
# Weight documentation for international review
document_weights_international <- function() {
  documentation <- list(
    "Section 1: Methodology" = list(
      "Sampling design" = "Stratified 2-stage",
      "Base weight formula" = "1/(π₁ × π₂)",
      "Software used" = "R 4.3.0, survey 4.2"
    ),
    
    "Section 2: Adjustments" = list(
      "Coverage adjustment" = "Applied to all strata",
      "Non-response" = "Within stratum cells",
      "Post-stratification" = "Age-sex-region",
      "Calibration" = "Not applied",
      "Trimming" = "None required"
    ),
    
    "Section 3: Quality Measures" = list(
      "Unweighted n" = 5000,
      "Weighted N" = 4500000,
      "CV of weights" = 0.89,
      "Design effect" = 1.79
    ),
    
    "Section 4: Validation" = list(
      "External benchmarks" = "Census 2022",
      "Deviation from benchmarks" = "<3% all cells"
    )
  )
  
  # Meets UN, World Bank, Eurostat standards
  return(documentation)
}
```

---

# Slide 244: Final Weight Formula

### The Complete Equation

Tuesday 4:45 PM - Harry writes on board:

$$w_{final} = \frac{1}{\pi_{psu} \times \pi_{ssu|psu}} \times \frac{1}{C} \times \frac{1}{R_h} \times \frac{N_{ps}}{n_{ps}}$$

Where:
- π = Selection probability
- C = Coverage rate
- R_h = Response rate in stratum h
- N_ps/n_ps = Post-stratification ratio

"This formula represents thousands of 
people's reality. Never forget that."

---

# Slide 245: Weight Calculation Flowchart

### Visual Summary

```r
# Create weight calculation flowchart
weight_flowchart <- function() {
  steps <- c(
    "Start: Sample selected",
    "Calculate base weight (1/π)",
    "Coverage < 95%? → Adjust",
    "Apply NR adjustment by stratum",
    "Post-stratify to known totals",
    "Check CV > 2? → Consider trim",
    "Validate sum = population",
    "Document all steps",
    "End: Final weights"
  )
  
  # In practice, create actual flowchart
  # using DiagrammeR or similar
  return(steps)
}

# Visual guide for weight calculation process
```

---

# Slide 246: Real Success Story

### Anonymous Country Excellence

```r
# Southern African country success metrics
success_metrics <- tibble(
  Indicator = c("Coverage", "Response Rate", "Weight CV",
               "Bias", "International Review"),
  Before_Training = c("Unknown", "Not adjusted", "2.4",
                     "18% error", "Failed"),
  After_Training = c("97%", "Properly adjusted", "0.9",
                    "2% error", "Approved")
)

success_metrics %>%
  kable(caption = "Impact of Proper Weight Calculation")
```

**Result:** First successful poverty measurement

---

# Slide 247: Your Weight Action Items

### After This Module

✅ Calculate base weights correctly (always 1/π)  
✅ Apply coverage adjustment (if <95% coverage)  
✅ Adjust for non-response (always by stratum)  
✅ Post-stratify to known totals (usually)  
✅ Consider calibration (best practice)  
✅ Document all adjustments (required)  
✅ Validate against external sources

**Remember:** Weights aren't optional

---

# Slide 248: Weight Resources

### Your Weight Calculation Toolkit

📚 **World Bank:** LSMS Manual Chapter 7  
📚 **Eurostat:** Calibration Guidelines 2023  
📚 **UN:** Technical Report F.98 Section 7  
📚 **OECD:** Quality Framework Annex C  
📚 **R Packages:** survey, sampling, icarus

**Scripts:** module5_weights_complete.R

---

# Slide 249: Final Weight Test

### Can You Answer These?

1. What's the base weight formula? (1/π)
2. When to apply coverage adjustment? (<95% coverage)
3. How to handle non-response? (Adjust by stratum)
4. What's calibration? (Match multiple totals)
5. When to trim weights? (Extreme outliers only)

**Score:**
- 5/5: Weight expert!
- 4/5: Almost there
- 3/5: Review slides 204-245
- <3: Let's talk during break

---

# Slide 250: Module 5 Complete!

### Weight Calculation Mastery Achieved

**You Now Understand:**
- Complete weight calculation chain
- All adjustment components  
- Quality control checks
- Documentation requirements
- Software implementation

**15-Minute Break**

Next: Module 6 - Non-Response Solutions  
Following Eurostat Doc 65 Chapter 8

---

## End of Module 5
### Weights: Your Survey's Foundation

*"Bad weights = Bad survey. Period."*  
- Harry, Tuesday 5:00 PM
# End of Module 5
## Weights: Your Survey's Foundation

### "Bad weights = Bad survey. Period."

---

class: inverse, center, middle

# Module 6: Non-Response Solutions
## 2:45 PM - The Modern Crisis
### 50 Slides on Achieving Quality Response Rates

---

# Slide 251: Module 6 - Non-Response Battle

### 2:45 PM - The Universal Challenge

"Response rates are plummeting globally. This module covers solutions from Eurostat Doc 65 Chapter 8, World Bank LSMS Chapter 8, and UN Handbook F.98 Chapter 8."

**This Module Addresses:**
- Eurostat response standards
- World Bank field protocols  
- OECD quality thresholds
- UN adjustment methods
- Real crisis management

---

# Slide 252: The Response Rate Disaster

### 2022 - Capital City Crisis

"Major metropolitan survey. Budget: $2.8 million. Response rate: 31%."

**What Went Wrong:**
- Young adults: 18% response
- High-income areas: 22% response
- Gated communities: 15% response
- Overall credibility: Destroyed

**Minister's verdict:** "Unusable data"

---

# Slide 253: Global Response Crisis

### International Evidence

```{r global-crisis, echo=FALSE, fig.height=4.5}
# Response rate trends by region
years <- 2000:2024
response_trends <- tibble(
  Year = rep(years, 4),
  Region = rep(c("North America", "Europe", "Asia", "Africa"), each = 25),
  Response_Rate = c(
    # North America - steep decline
    95 - (years - 2000) * 2.5 + rnorm(25, 0, 2),
    # Europe - moderate decline  
    92 - (years - 2000) * 2.0 + rnorm(25, 0, 2),
    # Asia - gradual decline
    90 - (years - 2000) * 1.5 + rnorm(25, 0, 2),
    # Africa - least decline
    88 - (years - 2000) * 1.0 + rnorm(25, 0, 2)
  )
) %>%
  mutate(Response_Rate = pmax(20, pmin(95, Response_Rate)))

ggplot(response_trends, aes(x = Year, y = Response_Rate, color = Region)) +
  geom_smooth(method = "loess", se = FALSE, size = 1.5) +
  geom_hline(yintercept = 70, linetype = "dashed", color = "red") +
  geom_hline(yintercept = 60, linetype = "dashed", color = "darkred") +
  scale_color_manual(values = c("#FF6B6B", eurostat_blue, wb_blue, "#00a86b")) +
  annotate("text", x = 2020, y = 72, label = "Eurostat minimum", size = 3) +
  annotate("text", x = 2020, y = 62, label = "Crisis level", size = 3) +
  labs(title = "Global Response Rate Crisis: 2000-2024",
       subtitle = "Source: Joint WB-Eurostat-OECD Assessment 2024",
       y = "Response Rate (%)") +
  theme_minimal() +
  theme(legend.position = "top")
```

---

# Slide 254: Why People Don't Respond

### Eurostat Research 2023

```{r why-not-respond, echo=TRUE}
# Eurostat non-response reasons (Doc 65 8.2)
reasons <- tibble(
  Reason = c("Too busy", "Privacy concerns", "Survey fatigue",
             "Don't trust", "No benefit", "Language", "Other"),
  Urban_Pct = c(35, 28, 18, 12, 5, 1, 1),
  Rural_Pct = c(25, 15, 12, 20, 18, 7, 3),
  Reference = c("EU 8.2.1", "EU 8.2.2", "EU 8.2.3",
                "EU 8.2.4", "EU 8.2.5", "EU 8.2.6", "EU 8.2.7")
)

reasons %>%
  kable(caption = "Eurostat: Primary Non-Response Reasons (%)")
```

---

# Slide 255: Response by Demographics

### World Bank Pattern Analysis

```{r demographics-response, echo=FALSE, fig.height=4}
# Response patterns by demographics
demo_response <- expand.grid(
  Age = c("18-24", "25-34", "35-44", "45-54", "55-64", "65+"),
  Gender = c("Male", "Female"),
  Urban = c("Urban", "Rural")
) %>%
  mutate(
    Response_Rate = case_when(
      Age == "18-24" & Gender == "Male" & Urban == "Urban" ~ 28,
      Age == "18-24" & Gender == "Female" & Urban == "Urban" ~ 35,
      Age == "18-24" & Gender == "Male" & Urban == "Rural" ~ 45,
      Age == "18-24" & Gender == "Female" & Urban == "Rural" ~ 52,
      Age == "65+" & Gender == "Female" & Urban == "Rural" ~ 85,
      Age == "65+" & Gender == "Male" & Urban == "Rural" ~ 82,
      TRUE ~ 50 + as.numeric(factor(Age)) * 5 + 
             ifelse(Gender == "Female", 5, 0) +
             ifelse(Urban == "Rural", 10, 0)
    )
  )

demo_response %>%
  filter(Urban == "Urban") %>%
  ggplot(aes(x = Age, y = Response_Rate, fill = Gender)) +
  geom_col(position = "dodge", alpha = 0.8) +
  geom_hline(yintercept = 70, linetype = "dashed", color = "red") +
  scale_fill_manual(values = c("Male" = wb_blue, "Female" = "#00a86b")) +
  labs(title = "Urban Response Rates by Age and Gender",
       subtitle = "World Bank Multi-Country Analysis 2023",
       y = "Response Rate (%)") +
  theme_minimal() +
  theme(legend.position = "top")
```

---

# Slide 256: Contact Strategy - OECD

### PIAAC Contact Protocol

```{r contact-strategy, echo=TRUE}
# OECD contact attempt protocol (PIAAC 8.3)
contact_protocol <- tibble(
  Attempt = 1:6,
  Timing = c("Weekday AM", "Weekday PM", "Weekend AM",
             "Weekday Eve", "Weekend PM", "Final any"),
  Cumulative_Contact = c(45, 68, 78, 85, 91, 94),
  Marginal_Gain = c(45, 23, 10, 7, 6, 3),
  OECD_Required = c("Yes", "Yes", "Yes", "Yes", "No", "No")
)

contact_protocol %>%
  kable(caption = "OECD Contact Attempt Strategy")
```

"Minimum 4 attempts required"

---

# Slide 257: Incentive Effects - UN Evidence

### UN Technical Report 2024/2

```{r incentives, echo=TRUE}
# UN incentive impact analysis
incentive_impact <- tibble(
  Type = c("No incentive", "Token (<$5)", "Moderate ($5-20)",
           "Substantial (>$20)", "Conditional", "Unconditional"),
  Response_Lift = c(0, 8, 15, 22, 12, 18),
  Cost_Per_Complete = c(45, 48, 52, 65, 50, 55),
  UN_Assessment = c("Baseline", "Cost-effective", "Optimal",
                   "Diminishing returns", "Good", "Better")
)

incentive_impact %>%
  kable(caption = "UN: Incentive Impact on Response")
```

---

# Slide 258: Mixed-Mode Strategy

### Eurostat Innovation 2024

```{r mixed-mode, echo=TRUE}
# Eurostat mixed-mode design (Doc 65 8.5)
mode_sequence <- tibble(
  Phase = 1:4,
  Mode = c("Web push", "Mail reminder", "Phone follow-up", "F2F final"),
  Days = c("1-14", "15-21", "22-35", "36-50"),
  Expected_RR = c(25, 40, 60, 70),
  Cost_Index = c(10, 15, 35, 100)
)

mode_sequence %>%
  kable(caption = "Eurostat Sequential Mixed-Mode Design")
```

"Start cheap, escalate as needed"

---

# Slide 259: Advance Letters - World Bank

### LSMS Best Practice

"Advance letter increases response by 12-18%" - WB evidence

**World Bank Letter Components:**
1. Official letterhead (government)
2. Purpose clearly stated
3. Confidentiality guaranteed
4. Benefits explained
5. Contact information
6. Signature from senior official

"Never skip advance notification"

---

# Slide 260: Training for Response

### ILO Interviewer Training Module

```{r training-response, echo=TRUE}
# ILO training components for response (Manual 8.4)
training_modules <- tibble(
  Module = c("First impression", "Doorstep intro", "Reluctance handling",
             "Refusal conversion", "Appointment setting", "Safety"),
  Hours = c(2, 3, 4, 3, 2, 2),
  Practice_Scenarios = c(10, 15, 20, 15, 10, 5),
  ILO_Priority = c("Critical", "Critical", "Critical",
                   "Important", "Important", "Critical")
)

training_modules %>%
  kable(caption = "ILO Response Training Curriculum")
```

---

# Slide 261: Doorstep Script - WHO

### WHO STEPS Proven Script

```{r doorstep, echo=FALSE}
cat('
WHO STEPS DOORSTEP INTRODUCTION (30 seconds):

"Good [morning/afternoon], I\'m [NAME] from [ORGANIZATION].
We\'re conducting the national health survey authorized by
[MINISTRY]. Your household was randomly selected to represent
thousands like yours. Your participation is voluntary but
vital for planning health services. The interview takes about
45 minutes. Everything you tell me is strictly confidential
by law. May I come in?"

Success rate: 73% (vs 51% unscripted)
')
```

---

# Slide 262: Refusal Conversion

### Eurostat Two-Step Process

**Step 1: Soft Refusal Response**
- Acknowledge concerns
- Address specific objection
- Offer alternatives (shorter, different time)
- Leave materials

**Step 2: Conversion Attempt**
- Different interviewer
- Senior/specialist converter
- Modified approach
- Final incentive offer

"Converts 25-35% of soft refusals"

---

# Slide 263: Technology Solutions

### Digital Response Enhancement

```{r technology, echo=TRUE}
# Technology impact on response (WB Innovation Lab 2024)
tech_solutions <- tibble(
  Technology = c("SMS pre-notice", "QR code access", "Video intro",
                 "Chatbot screening", "App-based", "AI scheduling"),
  Response_Impact = c("+8%", "+5%", "+12%", "-3%", "+15%", "+10%"),
  Age_Group = c("All", "Under 35", "All", "Under 50", "Under 45", "All"),
  Cost = c("$", "$", "$", "$$", "$$", "$$")
)

tech_solutions %>%
  kable(caption = "Technology Impact on Response Rates")
```

---

# Slide 264: Community Engagement

### UN Community Protocol

```{r community, echo=TRUE}
# UN community engagement steps (F.98 8.6)
engagement_steps <- tibble(
  Week = c(-4, -3, -2, -1, 0, 1),
  Activity = c("Leader meeting", "Community announcement", 
               "Local media", "Reminder", "Survey starts", "Thank you"),
  Responsible = c("Manager", "Coordinator", "Media officer",
                  "Field team", "Interviewers", "Manager"),
  Impact = c("Trust", "Awareness", "Legitimacy", 
            "Preparation", "Response", "Future")
)

engagement_steps %>%
  kable(caption = "UN Community Engagement Timeline")
```

---

# Slide 265: Response Monitoring

### Real-Time Dashboard

```{r monitoring, echo=FALSE, fig.height=4}
# Response rate monitoring
days <- 1:30
monitoring_data <- tibble(
  Day = rep(days, 3),
  Category = rep(c("Target", "Actual", "Projected"), each = 30),
  Response_Rate = c(
    # Target - linear to 70%
    seq(10, 70, length.out = 30),
    # Actual - realistic curve
    10 + 60 * (1 - exp(-days/15)) + rnorm(30, 0, 2),
    # Projected - based on current
    10 + 55 * (1 - exp(-days/12)) + rnorm(30, 0, 1.5)
  )
) %>%
  mutate(Response_Rate = pmax(10, pmin(75, Response_Rate)))

ggplot(monitoring_data, aes(x = Day, y = Response_Rate, color = Category)) +
  geom_line(size = 1.2) +
  geom_hline(yintercept = 70, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 60, linetype = "dashed", color = "red") +
  scale_color_manual(values = c("Target" = "gray", 
                                "Actual" = wb_blue,
                                "Projected" = "#FFA500")) +
  labs(title = "Response Rate Monitoring Dashboard",
       subtitle = "Daily tracking with projections",
       y = "Cumulative Response Rate (%)") +
  theme_minimal() +
  theme(legend.position = "top")
```

---

# Slide 266: Problem Areas Intervention

### Targeted Response Improvement

```{r problem-areas, echo=TRUE}
# Identify and address problem areas
problem_areas <- tibble(
  Area = c("Downtown", "Suburbs", "Rural North", "Rural South"),
  Week2_RR = c(18, 35, 52, 61),
  Problem = c("Access/Trust", "Busy", "None", "None"),
  Intervention = c("Evening + incentive", "Weekend focus", 
                   "Continue", "Continue"),
  Week4_RR = c(42, 58, 71, 75)
)

problem_areas %>%
  kable(caption = "Targeted Intervention Results")
```

"Focus resources where needed"

---

# Slide 267: Proxy Response Rules

### When to Accept Proxy

```{r proxy-rules, echo=TRUE}
# International proxy response standards
proxy_standards <- tibble(
  Organization = c("World Bank", "Eurostat", "UN", "WHO"),
  Proxy_Allowed = c("Limited", "Yes with rules", "Case-by-case", "No"),
  Conditions = c("Absent long-term", "Household member 18+",
                 "Documented reason", "Direct only"),
  Topics_Restricted = c("Income, health", "Personal health", 
                        "Sensitive", "All health")
)

proxy_standards %>%
  kable(caption = "Proxy Response International Standards")
```

---

# Slide 268: Hard-to-Reach Groups

### Special Protocols

```{r hard-to-reach, echo=TRUE}
# Hard-to-reach group strategies
htr_strategies <- tibble(
  Group = c("Young males", "High income", "Elderly isolated", "Migrants"),
  Strategy = c("Evening/online", "Executive approach", 
               "Trusted interviewer", "Multilingual"),
  Success_Rate = c(45, 52, 68, 58),
  Cost_Multiple = c(1.5, 2.2, 1.8, 2.0)
)

htr_strategies %>%
  kable(caption = "Strategies for Hard-to-Reach Groups")
```

---

# Slide 269: Response Quality Check

### Not All Responses Equal

```{r quality-check, echo=TRUE}
# Response quality indicators (Eurostat Doc 65 8.8)
quality_indicators <- tibble(
  Indicator = c("Item non-response", "Straight-lining", 
                "Interview duration", "Inconsistencies"),
  Threshold = c("<5%", "<2%", "±30% of median", "<3%"),
  Action = c("Follow-up", "Review", "Investigate", "Verify")
)

quality_indicators %>%
  kable(caption = "Eurostat Response Quality Standards")
```

"High response rate ≠ High quality"

---

# Slide 270: Cultural Considerations

### UN Guidelines for Diverse Contexts

```{r cultural, echo=TRUE}
# Cultural adaptations for response
cultural_factors <- tibble(
  Context = c("Religious communities", "Indigenous groups",
              "Conflict-affected", "Gender-restricted"),
  Adaptation = c("Religious leader endorsement", "Community protocol",
                "Security clearance", "Same-gender interviewers"),
  Impact = c("+20% RR", "+25% RR", "+15% RR", "+30% RR"),
  Reference = c("UN 8.9.1", "UN 8.9.2", "UN 8.9.3", "UN 8.9.4")
)

cultural_factors %>%
  kable(caption = "UN Cultural Response Adaptations")
```

---

# Slide 271: Crisis Management Story

### 2020 - Pandemic Response Crisis

"National survey scheduled March 2020. Face-to-face impossible."

**Emergency Pivot:**
- Week 1: Suspend field operations
- Week 2: Design phone follow-up
- Week 3: Train remote interviewing
- Week 4: Launch mixed-mode

**Result:** 61% response rate achieved

"Flexibility saved the survey"

---

# Slide 272: Phone Survey Response

### Different Game Entirely

```{r phone-response, echo=FALSE, fig.height=4}
# Phone vs face-to-face response
mode_comparison <- tibble(
  Method = rep(c("Face-to-face", "Phone"), each = 6),
  Attempts = rep(1:6, 2),
  Contact_Rate = c(
    c(45, 65, 75, 82, 87, 90),  # F2F
    c(25, 38, 48, 55, 60, 63)   # Phone
  )
)

ggplot(mode_comparison, aes(x = Attempts, y = Contact_Rate, color = Method)) +
  geom_line(size = 1.5) +
  geom_point(size = 3) +
  scale_color_manual(values = c("Face-to-face" = wb_blue, "Phone" = "#FF6B6B")) +
  labs(title = "Contact Rate by Mode and Attempts",
       subtitle = "Based on 23 country experiments",
       y = "Cumulative Contact Rate (%)") +
  theme_minimal() +
  theme(legend.position = "top")
```

---

# Slide 273: Web Survey Response

### Modern Challenge

```{r web-response, echo=TRUE}
# Web survey response strategies (OECD 2024)
web_strategies <- tibble(
  Strategy = c("Email invite only", "+ Postal invite", 
               "+ SMS reminder", "+ Phone prompt", "+ Incentive"),
  Response_Rate = c(12, 18, 23, 31, 38),
  Days_to_Complete = c(21, 18, 15, 12, 10),
  Cost_Per = c(5, 8, 10, 18, 25)
)

web_strategies %>%
  kable(caption = "Web Survey Response Building")
```

---

# Slide 274: Adaptive Design

### Eurostat Innovation

```{r adaptive, echo=TRUE}
# Adaptive design protocol (Eurostat 2024)
adaptive_rules <- tibble(
  Week = 1:4,
  Response_Rate = c(25, 40, 52, 60),
  Action = c("Continue as planned",
             "Increase evening calls",
             "Add incentive for refusals",
             "Focus on high-priority only"),
  Resources = c("100%", "100%", "120%", "80%")
)

adaptive_rules %>%
  kable(caption = "Eurostat Adaptive Design Rules")
```

"Adjust strategy based on results"

---

# Slide 275: Response Propensity Modeling

### Advanced Targeting

```{r propensity-model, eval=FALSE}
# Model response propensity for targeting
library(randomForest)

# Build model on previous survey
response_model <- randomForest(
  responded ~ age + gender + urban + education + 
             housing_type + previous_response,
  data = historical_data,
  importance = TRUE
)

# Predict for current survey
frame$response_propensity <- predict(response_model, frame)

# Prioritize low-propensity cases
priority_cases <- frame %>%
  filter(response_propensity < 0.5) %>%
  arrange(response_propensity)
```

---

# Slide 276: Paradata Analysis

### Learning from Process Data

```{r paradata, echo=TRUE}
# Paradata insights (World Bank standard)
paradata_analysis <- tibble(
  Metric = c("Best contact time", "Avg attempts needed",
             "Doorstep duration", "Refusal topics"),
  Finding = c("17:00-19:00", "3.2", "48 seconds", "Time & privacy"),
  Action = c("Schedule accordingly", "Plan for 4 attempts",
            "Train on intro", "Address in script")
)

paradata_analysis %>%
  kable(caption = "Paradata-Driven Improvements")
```

---

# Slide 277: Cost of Non-Response

### Economic Analysis

```{r cost-nr, echo=FALSE, fig.height=4}
# Cost per completed interview by response rate
response_rates <- seq(30, 90, by = 5)
cost_data <- tibble(
  Response_Rate = response_rates,
  Cost_Per_Interview = 50 + 500 * exp(-response_rates/25),
  Quality_Score = 100 * (1 - exp(-(response_rates-30)/20))
)

ggplot(cost_data, aes(x = Response_Rate)) +
  geom_line(aes(y = Cost_Per_Interview), color = "#FF6B6B", size = 1.5) +
  geom_line(aes(y = Quality_Score), color = wb_blue, size = 1.5) +
  geom_vline(xintercept = 70, linetype = "dashed", alpha = 0.5) +
  scale_y_continuous(
    name = "Cost per Interview ($)",
    sec.axis = sec_axis(~., name = "Quality Score")
  ) +
  labs(title = "Cost and Quality Trade-offs by Response Rate",
       x = "Response Rate (%)") +
  theme_minimal()
```

---

# Slide 278: Response Bias Analysis

### Who's Missing?

```{r bias-analysis, echo=TRUE}
# Analyze response bias
response_bias <- tibble(
  Characteristic = c("Young adults", "High income", "Urban males", "Minorities"),
  Population_Pct = c(25, 20, 18, 15),
  Sample_Pct = c(12, 14, 13, 11),
  Bias = (Sample_Pct - Population_Pct) / Population_Pct * 100
)

response_bias %>%
  mutate(Bias = paste0(round(Bias, 1), "%")) %>%
  kable(caption = "Response Bias Assessment")
```

"Large bias = weight adjustment critical"

---

# Slide 279: Documentation Requirements

### International Standards

```{r documentation-nr, echo=TRUE}
# Non-response documentation required
nr_documentation <- tibble(
  Component = c("Contact attempts", "Response rates by strata",
                "Refusal reasons", "Bias analysis",
                "Adjustment methods", "Quality checks"),
  WB = c("Required", "Required", "Required", "Required", "Required", "Optional"),
  Eurostat = c("Required", "Required", "Required", "Required", "Required", "Required"),
  Pages = c(2, 3, 2, 4, 5, 2)
)

nr_documentation %>%
  kable(caption = "Non-Response Documentation Standards")
```

---

# Slide 280: Success Metrics

### Achieving Quality Response

```{r success-nr, echo=TRUE}
# Response quality metrics
success_metrics <- tibble(
  Metric = c("Overall RR", "Minimum stratum RR", "Contact rate",
             "Cooperation rate", "Refusal rate", "Unable rate"),
  Target = c("≥70%", "≥60%", "≥90%", "≥80%", "≤15%", "≤5%"),
  Achieved = c("72%", "61%", "91%", "79%", "14%", "6%"),
  Status = c("✓", "✓", "✓", "~", "✓", "~")
)

success_metrics %>%
  kable(caption = "Response Quality Dashboard")
```

---

# Slide 281: Interviewer Performance

### Individual Tracking

```{r interviewer-perf, echo=FALSE, fig.height=4}
# Interviewer response rate variation
set.seed(2024)
interviewers <- tibble(
  ID = 1:30,
  Response_Rate = rnorm(30, 70, 12)
) %>%
  mutate(
    Response_Rate = pmax(40, pmin(95, Response_Rate)),
    Performance = case_when(
      Response_Rate >= 70 ~ "Good",
      Response_Rate >= 60 ~ "Acceptable",
      TRUE ~ "Problem"
    )
  )

ggplot(interviewers, aes(x = reorder(ID, Response_Rate), y = Response_Rate, fill = Performance)) +
  geom_col(alpha = 0.8) +
  geom_hline(yintercept = 70, linetype = "dashed", color = "green") +
  geom_hline(yintercept = 60, linetype = "dashed", color = "red") +
  scale_fill_manual(values = c("Good" = wb_blue, "Acceptable" = "#FFA500", "Problem" = "#FF6B6B")) +
  labs(title = "Interviewer Response Rate Performance",
       x = "Interviewer ID", y = "Response Rate (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45),
        legend.position = "top")
```

---

# Slide 282: Seasonal Effects
# Slide 283: Legal Framework

### Data Protection Impact

```{r legal-framework, echo=TRUE}
# Legal requirements affecting response
legal_impact <- tibble(
  Region = c("EU/GDPR", "USA", "Asia-Pacific", "Africa"),
  Consent_Required = c("Explicit", "Implied OK", "Varies", "Minimal"),
  Impact_on_RR = c("-15%", "-5%", "-8%", "-2%"),
  Compliance_Cost = c("High", "Medium", "Medium", "Low")
)

legal_impact %>%
  kable(caption = "Legal Framework Impact on Response")
```

"GDPR changed everything in Europe"

---

# Slide 284: Response in Conflict Areas

### UN Emergency Protocol

```{r conflict-response, echo=TRUE}
# UN conflict area response strategies
conflict_protocol <- tibble(
  Security_Level = c("1-Minimal", "2-Moderate", "3-Substantial", "4-High", "5-Extreme"),
  Mode = c("Standard F2F", "Quick F2F", "Phone primary", "Remote only", "Postpone"),
  Expected_RR = c("70%", "60%", "45%", "30%", "0%"),
  UN_Guidance = c("Proceed", "Caution", "Adapt", "Remote", "Wait")
)

conflict_protocol %>%
  kable(caption = "UN Security Level Response Protocols")
```

---

# Slide 285: Youth Response Crisis

### The Under-30 Challenge

```{r youth-response, echo=FALSE, fig.height=4}
# Youth response strategies effectiveness
youth_strategies <- tibble(
  Strategy = c("Traditional F2F", "SMS invite", "Social media", 
               "Web-first", "Gamification", "Peer recruit"),
  Age_18_24_RR = c(22, 28, 31, 38, 42, 51),
  Age_25_29_RR = c(31, 35, 34, 42, 38, 45),
  Cost_Index = c(100, 70, 60, 40, 120, 90)
)

youth_strategies %>%
  pivot_longer(cols = ends_with("_RR"), 
               names_to = "Age_Group", values_to = "Response_Rate") %>%
  ggplot(aes(x = Strategy, y = Response_Rate, fill = Age_Group)) +
  geom_col(position = "dodge", alpha = 0.8) +
  scale_fill_manual(values = c(wb_blue, "#00a86b")) +
  labs(title = "Youth Response Rate by Strategy",
       y = "Response Rate (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "top")
```

---

# Slide 286: Panel Attrition

### Longitudinal Challenge

```{r panel-attrition, echo=TRUE}
# Panel survey attrition (World Bank LSMS Panel)
panel_attrition <- tibble(
  Wave = 1:5,
  Original_Sample = 5000,
  Remaining = c(5000, 4250, 3750, 3400, 3150),
  Attrition_Rate = c(0, 15, 25, 32, 37),
  Refreshment = c(0, 0, 500, 0, 600)
) %>%
  mutate(
    Total_Sample = Remaining + Refreshment
  )

panel_attrition %>%
  kable(caption = "LSMS Panel Attrition Management")
```

---

# Slide 287: Response Quality Scores

### Comprehensive Assessment

```{r quality-scores, echo=TRUE}
# Response quality scoring system
quality_scoring <- tibble(
  Component = c("Response rate", "Item completion", "Straight-lining",
                "Duration appropriate", "Consistency"),
  Weight = c(0.40, 0.20, 0.15, 0.15, 0.10),
  Score = c(85, 92, 95, 88, 90),
  Weighted = Weight * Score
)

quality_scoring %>%
  mutate(Weighted = round(Weighted, 1)) %>%
  kable(caption = "Response Quality Composite Score")

total_score <- sum(quality_scoring$Weighted)
print(paste("Total Quality Score:", round(total_score, 1), "/ 100"))
```

---

# Slide 288: Exercise - Response Plan

### Design Your Response Strategy

```{r exercise-response, echo=TRUE}
# Your survey parameters
survey_params <- list(
  target_n = 3000,
  budget_response = 50000,
  urban_pct = 60,
  young_adult_pct = 35
)

# Design response strategy:
# 1. Contact attempts?
# 2. Incentive level?
# 3. Mode sequence?
# 4. Special protocols?

print("Design comprehensive response strategy")
# Solution in module6_response_plan.R
```

---

# Slide 289: Real Success Story

### 2023 - Response Rate Turnaround

"Southeast European country. Initial RR: 42%. Final: 74%."

**What Worked:**
1. Community leader engagement
2. Local language materials
3. Evening/weekend focus
4. €10 shopping voucher
5. Trusted local interviewers
6. Government endorsement

"Strategic approach saved the survey"

---

# Slide 290: Response Prediction Model

### Early Warning System

```{r prediction-model, echo=TRUE}
# Early response prediction
early_indicators <- tibble(
  Indicator = c("Day 3 RR", "Contact rate", "Hard refusal %",
                "Appointments made", "Web starts"),
  Value = c(15, 45, 8, 22, 12),
  Benchmark = c(18, 50, 5, 25, 15),
  Signal = c("Warning", "Warning", "Alert", "Warning", "Warning")
)

early_indicators %>%
  kable(caption = "Early Warning Response Indicators")
```

"Day 3 predicts final response"

---

# Slide 291: Response Budgeting

### Cost Allocation

```{r response-budget, echo=FALSE, fig.height=4}
# Response enhancement budget allocation
budget_allocation <- tibble(
  Category = c("Base fieldwork", "Incentives", "Extra attempts",
               "Conversion", "Community", "Technology"),
  Amount = c(50, 15, 12, 8, 5, 10),
  Cumulative = cumsum(c(50, 15, 12, 8, 5, 10))
)

ggplot(budget_allocation, aes(x = reorder(Category, -Amount), y = Amount)) +
  geom_col(fill = wb_blue, alpha = 0.8) +
  geom_text(aes(label = paste0("$", Amount, "k")), vjust = -0.5) +
  labs(title = "Response Enhancement Budget Allocation",
       subtitle = "Per 1000 completes",
       y = "Budget ($1000s)", x = "") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

---

# Slide 292: International Comparison

### Response Standards Worldwide

```{r international-standards, echo=TRUE}
# International response rate standards
international_rr <- tibble(
  Organization = c("Eurostat", "World Bank", "OECD", "UN", "WHO"),
  Minimum_RR = c(70, 70, 70, 65, 80),
  Acceptable = c(60, 65, 65, 60, 70),
  Crisis = c(50, 55, 55, 50, 60),
  Year_Updated = c(2023, 2024, 2023, 2022, 2021)
)

international_rr %>%
  kable(caption = "International Response Rate Standards (%)")
```

---

# Slide 293: Mixed-Mode Integration

### Unified Response Strategy

```{r mixed-mode-integration, echo=TRUE}
# Integrated mixed-mode design
mode_integration <- tibble(
  Week = 1:6,
  Primary = c("Web", "Web", "Phone", "Phone", "F2F", "F2F"),
  Support = c("Email", "Mail", "SMS", "Email", "Phone", "All"),
  Expected_RR = c(15, 28, 42, 55, 68, 73),
  Cost_Cumulative = c(10, 18, 35, 52, 85, 110)
)

mode_integration %>%
  kable(caption = "Sequential Mixed-Mode Implementation")
```

---

# Slide 294: Final Push Strategies

### Last Week Tactics

```{r final-push, echo=TRUE}
# Final week response strategies
final_push <- tibble(
  Day = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday"),
  Strategy = c("Double incentive", "Senior converters", "Community appeal",
               "Extended hours", "Last chance message"),
  Expected_Gain = c("+2.5%", "+1.8%", "+1.2%", "+1.5%", "+2.0%"),
  Cost = c("$$", "$", "$", "$", "$")
)

final_push %>%
  kable(caption = "Final Week Response Push")
```

"Last week can add 8-10% RR"

---

# Slide 295: Response Documentation

### Required Reporting

```{r response-documentation, echo=TRUE}
# Response documentation checklist
response_docs <- tibble(
  Section = c("Contact protocol", "Response rates by strata",
              "Refusal analysis", "Bias assessment",
              "Quality indicators", "Lessons learned"),
  Pages = c(3, 4, 3, 5, 3, 2),
  Required_By = c("All", "All", "Eurostat/WB", "All", "Eurostat", "WB")
)

response_docs %>%
  kable(caption = "Response Documentation Requirements")
```

---

# Slide 296: Response Technology Future

### Emerging Solutions 2025

**Coming Soon:**
- AI-optimized contact timing
- Chatbot pre-screening
- Facial recognition verification
- Blockchain incentive delivery
- VR interview environments

"Technology will transform response"

---

# Slide 297: Key Response Lessons

### 25 Years of Experience

1. **First contact is crucial** - train extensively
2. **Timing matters** - evenings and weekends
3. **Local trust essential** - community engagement
4. **Incentives work** - but diminishing returns
5. **Monitor daily** - early intervention critical
6. **Document everything** - for next time

---

# Slide 298: Your Response Checklist

### Before Launching

✅ Contact protocol defined
✅ Incentive strategy clear
✅ Training completed
✅ Materials translated
✅ Community engaged
✅ Monitoring system ready
✅ Intervention triggers set
✅ Documentation plan ready

---

# Slide 299: Module 6 Summary

### Response Rate Mastery Achieved

**You Now Understand:**
- Modern response challenges
- Evidence-based strategies
- International standards
- Cost-benefit trade-offs
- Quality vs quantity balance

"Good response rate = credible survey"

---

# Slide 300: Module 6 Complete!

### Non-Response Solutions Mastered

**Competencies Gained:**
- ✓ Design response strategies
- ✓ Apply international standards
- ✓ Monitor and intervene
- ✓ Handle hard-to-reach groups
- ✓ Document properly

.practice-box[
**10-Minute Break**

Next: Module 7 - Special Populations
Following WHO/UN Special Protocols
]

---

class: inverse, center, middle

# End of Module 6
## Response Rate Excellence Achieved

### "70% response rate is the new 90%"

---

class: inverse, center, middle

# Slide 301: Module 7 Introduction

### Tuesday 3:30 PM - Special Populations

Harry after the break:

"Standard methods fail for special populations.
This module covers WHO protocols, UN guidelines,
and real solutions that work."

**Coverage:**
- Nomadic populations
- Urban homeless
- Institutional populations
- Refugee/IDP camps
- Remote islands
- Conflict zones

*Reference: WHO Technical Note 2024/3*

---

# Slide 302: Why Special Methods Needed

### Standard Assumptions Violated

```r
# Standard survey assumptions vs special populations
assumptions_violated <- tibble(
  Assumption = c("Fixed address", "Accessible", "Stable location",
                "Single household", "Regular schedule"),
  Standard_Pop = c("Yes", "Yes", "Yes", "Yes", "Yes"),
  Nomadic = c("No", "Varies", "No", "Complex", "No"),
  Homeless = c("No", "No", "No", "No", "No"),
  Refugee = c("Temporary", "Restricted", "No", "Variable", "No")
)

assumptions_violated %>%
  kable(caption = "Why Standard Methods Fail")
```

---

# Slide 303: Nomadic Populations

### WHO/UN Joint Protocol

```r
# Nomadic population sampling framework
nomadic_design <- tibble(
  Stage = c("1: Migration routes", "2: Water points", 
            "3: Time periods", "4: Households"),
  Selection = c("All major routes", "PPS by usage",
               "Random times", "Random at location"),
  Frame_Source = c("Government maps", "Local knowledge",
                  "24-hour cycle", "On-site listing"),
  Challenge = c("Seasonal variation", "Access", 
               "Timing", "Definition")
)

nomadic_design %>%
  kable(caption = "WHO Nomadic Population Design")
```

---

# Slide 304: Time-Location Sampling

### For Mobile Populations

```r
# Time-location sampling (TLS) design
tls_design <- function(venues, time_blocks, target_n) {
  # Create venue-time units (VTU)
  vtu_frame <- expand.grid(
    venue = venues,
    day = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"),
    time = c("Morning", "Afternoon", "Evening", "Night")
  ) %>%
    mutate(
      expected_traffic = sample(10:100, n(), replace = TRUE),
      selection_prob = expected_traffic / sum(expected_traffic)
    )
  
  # Select VTUs with PPS
  n_vtu <- ceiling(target_n / 15)  # Assume 15 per VTU
  
  return(list(
    frame_size = nrow(vtu_frame),
    vtu_needed = n_vtu,
    expected_yield = n_vtu * 15
  ))
}

# Example for homeless population
tls_design(venues = 5, time_blocks = 4, target_n = 300)
```

---

# Slide 305: Urban Homeless

### UN-Habitat Method

```r
# Urban homeless enumeration strategy
homeless_strategy <- tibble(
  Component = c("Service points", "Street counts", "Camps/settlements",
               "Hidden homeless", "Doubled-up"),
  Method = c("Facility sampling", "Area enumeration", "Census",
            "RDS/Snowball", "Household screening"),
  Coverage = c("60%", "25%", "10%", "Unknown", "5%"),
  Quality = c("Good", "Fair", "Good", "Poor", "Fair")
)

homeless_strategy %>%
  kable(caption = "UN-Habitat Homeless Coverage Strategy")
```

---

# Slide 306: Service-Based Sampling

### Reaching Through Services

```r
# Service-based sampling for hard-to-reach
service_sampling <- tibble(
  Service = c("Health clinics", "Food banks", "Shelters",
             "Day centers", "Mobile services"),
  Population = c("General poor", "Food insecure", "Homeless",
                "Homeless", "Remote"),
  Sampling_Unit = c("Patient visits", "Client visits", "Bed-nights",
                   "Daily attendance", "Service stops"),
  Typical_n = c("50-100/day", "100-200/day", "30-50/night",
               "20-40/day", "10-20/stop")
)

service_sampling %>%
  kable(caption = "Service-Based Sampling Options")
```

---

# Slide 307: Institutional Populations

### WHO Institutional Protocol

```r
# Institutional population framework
institutional_frame <- tibble(
  Type = c("Hospitals", "Prisons", "Military", "Elderly homes",
          "Boarding schools", "Work camps"),
  Sampling_Level = c("Ward", "Block", "Unit", "Room",
                    "Dormitory", "Section"),
  Access = c("Ethics approval", "Justice ministry", "Defense",
            "Facility", "Education ministry", "Labor"),
  Typical_Issues = c("Consent", "Security", "Hierarchy",
                    "Capacity", "Minors", "Rights")
)

institutional_frame %>%
  kable(caption = "WHO Institutional Sampling Framework")
```

---

# Slide 308: Refugee/IDP Camps

### UNHCR Standard Method

```r
# UNHCR camp sampling protocol
camp_sampling <- tibble(
  Stage = c("1: Camps/settlements", "2: Zones/blocks", 
           "3: Shelters", "4: Individuals"),
  Frame = c("UNHCR register", "Camp management", 
           "Zone leaders", "Shelter listing"),
  Selection = c("All or PPS", "Systematic", "Random", "All or random"),
  Challenges = c("New arrivals", "Irregular layout", 
                "Multiple families", "Absent members")
)

camp_sampling %>%
  kable(caption = "UNHCR Camp Sampling Protocol")
```

---

# Slide 309: Real Crisis - Syria 2019

### Sampling in Active Conflict

"2019 - Need health data from conflict zone.
No access, no frame, no safety."

**Solution:**
- Remote sensing for population
- WhatsApp for data collection
- Local health workers as interviewers
- Audio consent process
- Real-time monitoring

**Result:** 73% response rate, validated data

*Published: Lancet Global Health 2020*

---

# Slide 310: Respondent-Driven Sampling

### For Hidden Populations

```r
# RDS implementation for hidden populations
rds_implementation <- function(seeds = 10, waves = 6, coupons = 3) {
  # Calculate expected sample
  expected_sample <- seeds * (coupons ^ waves - 1) / (coupons - 1)
  
  # Realistic recruitment (60% efficiency)
  realistic_sample <- expected_sample * 0.6
  
  # Calculate design effect (typically 2-4 for RDS)
  deff_rds <- 2.5
  effective_n <- realistic_sample / deff_rds
  
  return(list(
    seeds = seeds,
    waves = waves,
    coupons = coupons,
    theoretical_n = expected_sample,
    expected_n = realistic_sample,
    effective_n = effective_n
  ))
}

rds_implementation(seeds = 10, waves = 5, coupons = 3)
```

---

# Slide 311: RDS Weight Calculation

### Volz-Heckathorn Estimator

```r
# RDS weight calculation (simplified)
rds_weights <- function(degree, recruitment_matrix) {
  # Degree = network size of respondent
  # Basic RDS weight inversely proportional to degree
  
  weights <- tibble(
    respondent_id = 1:length(degree),
    network_size = degree,
    base_weight = 1 / degree,
    normalized_weight = base_weight / mean(base_weight)
  )
  
  # In practice, use RDS Analyst or similar
  return(weights)
}

# Example
degrees <- c(5, 10, 3, 15, 8, 20, 4, 12, 6, 9)
rds_weights(degrees, recruitment_matrix = NULL)
```

---

# Slide 312: Island Populations

### Pacific Island Methods

```r
# Island population challenges and solutions
island_sampling <- tibble(
  Challenge = c("Geographic isolation", "Small populations",
               "Transport costs", "Weather dependency",
               "Cultural protocols"),
  Solution = c("Cluster islands", "Census for small",
              "Boat schedule coordination", "Seasonal planning",
              "Chief engagement first"),
  Example = c("Group 3-4 nearby", "Census if <500",
             "Monthly supply boat", "Dry season only",
             "2-week lead time")
)

island_sampling %>%
  kable(caption = "Pacific Island Sampling Solutions")
```

---

# Slide 313: Remote Area Sampling

### Extreme Geography

```r
# Remote area cost-quality trade-off
remote_options <- tibble(
  Method = c("Full coverage", "Accessible only", "Hub sampling",
            "Proxy reporting", "Satellite + ground"),
  Coverage = c("100%", "60%", "75%", "85%", "95%"),
  Cost_Index = c(500, 100, 150, 120, 200),
  Quality = c("Excellent", "Biased", "Good", "Fair", "Good"),
  Time_Months = c(6, 2, 3, 2, 4)
)

remote_options %>%
  kable(caption = "Remote Area Sampling Options")
```

---

# Slide 314: Indigenous Populations

### Culturally Appropriate Methods

```r
# Indigenous population protocols
indigenous_protocol <- tibble(
  Step = c("1: Permission", "2: Partnership", "3: Training",
          "4: Translation", "5: Adaptation", "6: Return"),
  Action = c("Tribal council approval", "Local co-researchers",
            "Cultural sensitivity", "Local languages",
            "Relevant questions", "Share results"),
  Timeline = c("Month -3", "Month -2", "Month -1",
              "Month -1", "Month 0", "Month +6"),
  Critical = c("Yes", "Yes", "Yes", "Yes", "Yes", "Yes")
)

indigenous_protocol %>%
  kable(caption = "Indigenous Population Protocol")
```

---

# Slide 315: Mining Communities

### Temporary Worker Populations

```r
# Mining community sampling design
mining_design <- tibble(
  Population = c("Permanent staff", "Contract workers",
                "Informal miners", "Support services",
                "Families"),
  Frame_Source = c("Company HR", "Contractor lists",
                  "Site registration", "Business permits",
                  "Housing records"),
  Access = c("Easy", "Moderate", "Difficult",
            "Moderate", "Easy"),
  Mobility = c("Low", "High", "Very high", "Moderate", "Low")
)

mining_design %>%
  kable(caption = "Mining Community Sampling Framework")
```

---

# Slide 316: Border Populations

### Cross-Border Challenges

```r
# Border population methodology
border_method <- tibble(
  Issue = c("Dual residence", "Daily crossing", "Seasonal migration",
           "Trade corridors", "Informal crossings"),
  Solution = c("Time-location", "Peak hours sampling",
              "Multi-season", "Market days",
              "Community informants"),
  Coordination = c("Bilateral", "Local only", "Bilateral",
                  "Local", "Informal")
)

border_method %>%
  kable(caption = "Border Population Solutions")
```

---

# Slide 317: Student Populations

### Educational Institution Sampling

```r
# Student population framework
student_sampling <- tibble(
  Level = c("Primary", "Secondary", "Tertiary",
           "Vocational", "Non-formal"),
  Frame = c("Education ministry", "School lists",
           "University registry", "Training centers",
           "NGO records"),
  Design = c("2-stage: school-class", "2-stage: school-class",
            "Stratified by faculty", "Census small centers",
            "Venue-based"),
  Issues = c("Attendance", "Dropouts", "Part-time",
           "Completion rates", "Irregular")
)

student_sampling %>%
  kable(caption = "Education Sector Sampling")
```

---

# Slide 318: Sex Workers

### Sensitive Population Methods

```r
# Sensitive population approach (WHO/UNAIDS)
sensitive_approach <- tibble(
  Method = c("Venue-based", "RDS", "Web-based",
            "Service-based", "Mixed"),
  Advantages = c("Known locations", "Hidden reached",
                "Anonymous", "Health link", "Comprehensive"),
  Challenges = c("Visible only", "Long chains", "Tech bias",
                "Service users only", "Complex"),
  Typical_RR = c("60%", "NA", "40%", "70%", "55%")
)

sensitive_approach %>%
  kable(caption = "Sensitive Population Methods")
```

---

# Slide 319: Elderly Isolated

### Reaching Isolated Elderly

```r
# Isolated elderly strategies
elderly_strategies <- tibble(
  Strategy = c("Health records", "Social services",
              "Community health workers", "Pension lists",
              "Religious groups"),
  Coverage = c("Registered only", "At-risk only",
              "Known to CHW", "Pensioners only",
              "Active members"),
  Quality = c("Good", "Good", "Variable", "Excellent", "Fair"),
  Ethics = c("Consent complex", "Vulnerable", "Trust high",
            "Privacy concern", "Voluntary")
)

elderly_strategies %>%
  kable(caption = "Reaching Isolated Elderly")
```

---

# Slide 320: Tuesday 4:00 PM Check

### Energy and Understanding

Harry checks the room:

"Complex populations, complex methods.
Everyone following? Questions?

Remember: Every population can be sampled,
but not with standard methods.

Let's continue - crisis management next."

*Room engaged despite late hour*

---

# Slide 321: Children in Research

### Special Protections Required

```r
# Child population protocols (UNICEF)
child_protocols <- tibble(
  Age_Group = c("0-4", "5-9", "10-14", "15-17"),
  Respondent = c("Parent/caregiver", "Parent + observation",
                "Parent + child", "Adolescent + parent"),
  Consent = c("Parent only", "Parent only",
             "Parent + assent", "Both required"),
  Special_Training = c("Child development", "Child friendly",
                      "Child safeguarding", "Adolescent approach")
)

child_protocols %>%
  kable(caption = "UNICEF Age-Appropriate Protocols")
```

---

# Slide 322: Disability Inclusion

### Washington Group Methods

```r
# Disability-inclusive sampling
disability_inclusion <- tibble(
  Component = c("Frame identification", "Accessibility",
               "Communication", "Accommodation",
               "Proxy options"),
  Standard_Method = c("Household screen", "Physical access",
                     "Verbal only", "Standard time",
                     "Not allowed"),
  Inclusive_Method = c("Multiple sources", "Multiple modes",
                      "Multi-format", "Flexible timing",
                      "Permitted with rules")
)

disability_inclusion %>%
  kable(caption = "Washington Group Disability Inclusion")
```

---

# Slide 323: Combining Methods

### Mixed Approaches for Coverage

```r
# Combined methods for complete coverage
combined_approach <- function(target_pop, methods) {
  coverage_matrix <- tibble(
    Method = c("Standard HH", "TLS", "RDS", "Service"),
    Coverage_Pct = c(70, 15, 10, 5),
    Quality = c("High", "Medium", "Medium", "High"),
    Cost_Per = c(50, 80, 100, 40)
  )
  
  total_coverage <- sum(coverage_matrix$Coverage_Pct)
  weighted_cost <- weighted.mean(coverage_matrix$Cost_Per, 
                                 coverage_matrix$Coverage_Pct)
  
  return(list(
    coverage = total_coverage,
    average_cost = weighted_cost,
    methods_needed = nrow(coverage_matrix)
  ))
}

combined_approach(target_pop = "Urban poor", methods = 4)
```

---

# Slide 324: Quality in Special Populations

### Maintaining Standards

```r
# Quality indicators for special populations
quality_special <- tibble(
  Indicator = c("Coverage of target", "Response rate",
               "Data completeness", "Validation possible",
               "Replicability"),
  Standard_Pop = c("95%", "70%", "98%", "Yes", "High"),
  Special_Pop = c("Unknown", "Variable", "85%", "Limited", "Moderate"),
  Acceptable = c(">70%", ">50%", ">80%", "Some", "Document well")
)

quality_special %>%
  kable(caption = "Quality Standards for Special Populations")
```

---

# Slide 325: Documentation Requirements

### Extra Documentation Needed

```r
# Additional documentation for special populations
special_documentation <- tibble(
  Section = c("Population definition", "Frame construction",
             "Method justification", "Quality limitations",
             "Ethical considerations", "Lessons learned"),
  Pages = c(3, 5, 4, 3, 4, 2),
  Critical_For = c("All", "All", "All", "All",
                  "Vulnerable", "Future surveys")
)

special_documentation %>%
  kable(caption = "Special Population Documentation")
```

---

# Slide 326: Exercise - Design for Homeless

### Your City's Homeless Survey

```r
# Design homeless survey for your city
your_city <- list(
  estimated_homeless = 5000,
  known_shelters = 8,
  service_points = 15,
  safe_areas = 12,
  budget = 75000
)

# Design approach:
# 1. Which methods to combine?
# 2. Sample sizes for each?
# 3. Timeline?
# 4. Quality measures?

print("Design complete coverage strategy")
# Solution in module7_homeless_design.R
```

---

# Slide 327: Cost Comparison

### Special vs Standard Methods

```r
# Cost comparison for special methods
cost_comparison <- tibble(
  Population = c("Standard HH", "Nomadic", "Homeless",
                "Refugee camp", "RDS hidden"),
  Cost_Per_Interview = c(50, 120, 95, 35, 85),
  Time_Per_Interview = c(45, 60, 40, 40, 90),
  Training_Days = c(5, 10, 8, 7, 12),
  Quality_Score = c(95, 85, 80, 90, 75)
)

cost_comparison %>%
  kable(caption = "Special Population Cost Premiums")
```

---

# Slide 328: Success Story - Mongolia

### Nomadic Herder Success

"2018 - Mongolia herder survey. 
40% of population nomadic.
Extreme weather, vast distances."

**Solution:**
- GPS tracking of migration routes
- Seasonal rounds (4 per year)
- Local herder interviewers
- Motorcycle teams
- Satellite phone reporting

**Result:** 82% response rate, nationally representative

---

# Slide 329: Technology for Special Populations

### Digital Solutions

```r
# Technology applications for special populations
tech_solutions <- tibble(
  Technology = c("GPS tracking", "Satellite imagery",
                "Mobile apps", "Biometrics",
                "Blockchain ID"),
  Application = c("Nomadic routes", "Settlement size",
                 "Self-admin", "Deduplication",
                 "Refugee ID"),
  Status = c("Operational", "Operational", "Pilot",
            "Testing", "Experimental"),
  Cost = c("$$", "$$$", "$", "$$", "$$$")
)

tech_solutions %>%
  kable(caption = "Technology for Special Populations")
```

---

# Slide 330: Ethical Considerations

### Enhanced Protections

```r
# Ethical requirements for special populations
ethical_framework <- tibble(
  Population = c("Children", "Prisoners", "Refugees",
                "Mental illness", "Victims"),
  Extra_Requirements = c("Parental consent", "No coercion",
                        "Do no harm", "Capacity assessment",
                        "Trauma-informed"),
  Review_Level = c("Full IRB", "Full IRB", "Full IRB",
                  "Full IRB", "Full IRB"),
  Monitor = c("Yes", "Yes", "Yes", "Yes", "Yes")
)

ethical_framework %>%
  kable(caption = "Enhanced Ethical Requirements")
```

---

# Slide 331: Seasonal Populations

### Timing is Everything

```r
# Seasonal population sampling
seasonal_sampling <- tibble(
  Population = c("Agricultural workers", "Tourist areas",
                "Fishing communities", "Construction",
                "Students"),
  Peak_Season = c("Harvest", "Summer", "Fishing season",
                 "Dry season", "School term"),
  Off_Season = c("Planting", "Winter", "Off-season",
                "Rainy", "Vacation"),
  Strategy = c("Sample peak", "Both seasons", "Peak only",
              "Dry only", "Term time")
)

seasonal_sampling %>%
  kable(caption = "Seasonal Population Strategies")
```

---

# Slide 332: Multiple Frame Approach

### Covering All Bases

```r
# Multiple frame for complete coverage
multiple_frame <- function(frames, overlap_rate = 0.2) {
  # Assuming 3 frames with overlap
  frame_coverage <- c(0.6, 0.3, 0.2)  # Coverage of each frame
  
  # Account for overlap
  total_coverage <- sum(frame_coverage) - overlap_rate
  
  # Sample allocation
  n_total <- 1000
  allocation <- n_total * frame_coverage / sum(frame_coverage)
  
  return(list(
    coverage = paste0(total_coverage * 100, "%"),
    samples = round(allocation),
    overlap_handling = "Weight adjustment needed"
  ))
}

multiple_frame(frames = 3)
```

---

# Slide 333: Validation Methods

### Checking Special Population Data

```r
# Validation approaches for special populations
validation_methods <- tibble(
  Method = c("Capture-recapture", "Multiplier method",
            "Service statistics", "Satellite validation",
            "Community counts"),
  Population = c("Homeless", "Hidden", "Service users",
                "Settlements", "Small areas"),
  Validation_Type = c("Size estimate", "Size estimate",
                     "Coverage check", "Location verify",
                     "Completeness")
)

validation_methods %>%
  kable(caption = "Special Population Validation")
```

---

# Slide 334: Module 7 Summary

### Special Population Mastery

You now understand:
- When standard methods fail
- Alternative sampling approaches
- Combined coverage strategies
- Quality considerations
- Ethical requirements
- Documentation needs

"Every population is surveyable with the right method"

---

# Slide 335: Key Lessons - Special Populations

### What Works

1. **No single method covers all** - combine approaches
2. **Local knowledge essential** - partner with communities
3. **Flexibility required** - adapt to conditions
4. **Extra time needed** - plan accordingly
5. **Document everything** - for credibility
6. **Expect lower quality** - but still valuable

---

# Slide 336: Quick Reference - Methods

### Special Population Quick Guide

| Population | Primary Method | Secondary | Expected RR |
|-----------|---------------|-----------|------------|
| Nomadic | Time-location | GPS tracking | 60-70% |
| Homeless | Service-based | Street count | 50-60% |
| Refugees | Camp census | Registration | 70-80% |
| Hidden | RDS | Venue-based | Variable |
| Remote | Cluster + travel | Proxy | 60-70% |

---

# Slide 337: Your Special Population Plan

### Before Implementation

✅ Define population precisely
✅ Identify all possible frames
✅ Choose combination of methods
✅ Budget for higher costs
✅ Plan extended timeline
✅ Arrange permissions/partnerships
✅ Enhance training
✅ Prepare documentation

---

# Slide 338: Module 7 Complete!

### Special Populations Conquered

**Competencies Achieved:**
- ✓ Identify when special methods needed
- ✓ Select appropriate techniques
- ✓ Design combined approaches
- ✓ Handle ethical issues
- ✓ Document properly

**Ready for:** Module 8 - Crisis Management

---

## Module 8: Crisis Management (Slides 339-400)
### Tuesday 4:30 PM - When Everything Goes Wrong

---

# Slide 339: Module 8 Introduction

### Tuesday 4:30 PM - Crisis Management

Harry's final module energy:

"Murphy's Law: What can go wrong, will.
30 years of crises taught me: 
Plan for failure, celebrate success.

This module: Real crisis management
from pandemics to coups to cyclones."

*Reference: UN Emergency Handbook 2024*

---

# Slide 340: Types of Survey Crises

### What Can Go Wrong

```r
# Crisis taxonomy from experience
crisis_types <- tibble(
  Category = c("Natural", "Political", "Security",
              "Economic", "Technical", "Human"),
  Examples = c("Flood, earthquake", "Coup, election",
              "Conflict, crime", "Budget cut, inflation",
              "System failure", "Team collapse"),
  Frequency = c("10%", "5%", "8%", "15%", "20%", "25%"),
  Impact = c("High", "High", "High", "Medium", "Medium", "Low")
)

crisis_types %>%
  kable(caption = "Survey Crisis Types and Frequency")
```

---

# Slide 341: The Earthquake Story

### 2015 - Nepal Earthquake During Survey

"Day 12 of 30. Magnitude 7.8 earthquake.
25% of sample areas destroyed.
8,000+ dead. Teams missing."

**Immediate Response:**
1. Account for all staff (72 hours)
2. Suspend operations
3. Assess damage
4. Redesign sample
5. Resume after 6 weeks

**Lessons:** Staff safety first, always have Plan B

---

# Slide 342: Crisis Response Framework

### UN Emergency Protocol Structure

```r
# UN crisis response levels
response_levels <- tibble(
  Level = c("Green", "Yellow", "Orange", "Red", "Black"),
  Situation = c("Normal", "Caution", "Alert", "Crisis", "Suspend"),
  Operations = c("100%", "Continue carefully", "Limited",
                "Emergency only", "Stop"),
  Decision = c("Field", "Manager", "Director", "Ministry", "Cabinet"),
  Timeline = c("NA", "24hr review", "12hr review",
              "Immediate", "Immediate")
)

response_levels %>%
  kable(caption = "UN Crisis Response Levels")
```

---

# Slide 343: Budget Crisis Management

### When Funding Cuts Hit

```r
# Budget cut response options
budget_options <- tibble(
  Cut_Level = c("10%", "25%", "40%", "50%", ">50%"),
  Option_1 = c("Reduce incentives", "Reduce sample 20%",
              "Drop rural", "Phone only", "Postpone"),
  Option_2 = c("Reduce attempts", "Reduce domains",
              "Urban only", "Web only", "Cancel"),
  Quality_Impact = c("Minimal", "Acceptable", "Serious",
                    "Major", "Fatal"),
  Credibility = c("Maintained", "Maintained", "Questioned",
                 "Damaged", "Lost")
)

budget_options %>%
  kable(caption = "Budget Crisis Response Options")
```

---

# Slide 344: Pandemic Protocol

### COVID-19 Lessons Learned

```r
# Pandemic adaptation strategies
pandemic_protocol <- tibble(
  Phase = c("Lockdown", "Restricted", "Cautious", "New normal"),
  Mode = c("Phone/web only", "Phone primary", "Mixed mode",
          "F2F with protection"),
  Sample_Adj = c("Panel if available", "Reduce rural",
                "Gradual return", "Full sample"),
  Cost_Impact = c("+20%", "+15%", "+10%", "+5%"),
  Quality = c("Compromised", "Acceptable", "Good", "Standard")
)

pandemic_protocol %>%
  kable(caption = "Pandemic Survey Adaptations")
```

---

# Slide 345: Security Crisis

### Conflict During Fieldwork

"2011 - Civil unrest erupts. 
Teams in field. Communications down."

**Security Protocol Activated:**
1. Extraction plan initiated
2. Safe houses activated
3. Local UN coordination
4. Embassy notification
5. Media blackout

**Result:** All staff evacuated safely in 48 hours

---

# Slide 346: Communication Crisis Plan

### When Systems Fail

```r
# Communication backup systems
comm_backup <- tibble(
  Primary = c("Internet", "Mobile network", "Landline",
             "Power", "Transport"),
  Backup_1 = c("Mobile hotspot", "Satellite phone", "Mobile",
            "Generator", "Motorcycle"),
  Backup_2 = c("Satellite", "Radio", "Satellite",
            "Solar", "Bicycle"),
  Cost = c("$$", "$$$", "$$$", "$$", "$"),
  Test_Frequency = c("Weekly", "Monthly", "Monthly",
                    "Weekly", "NA")
)

comm_backup %>%
  kable(caption = "Communication Redundancy Plan")
```

---

# Slide 347: Data Loss Prevention

### Protecting Your Investment

```r
# Data backup strategy
backup_strategy <- tibble(
  Level = c("Field device", "Field supervisor", "Regional office",
           "HQ server", "Cloud", "Archive"),
  Frequency = c("Continuous", "Daily", "Daily",
               "Real-time", "Real-time", "Weekly"),
  Method = c("Device storage", "Encrypted USB", "Secure upload",
            "Auto-sync", "Auto-backup", "Tape/disk"),
  Redundancy = c("1x", "2x", "2x", "3x", "3x", "Permanent")
)

backup_strategy %>%
  kable(caption = "Six-Level Data Protection")
```

---

# Slide 348: Team Crisis Management

### When Teams Collapse

```r
# Team crisis indicators and responses
team_crisis <- tibble(
  Indicator = c("High turnover", "Low morale", "Conflicts",
               "Illness outbreak", "Strike threat"),
  Early_Warning = c(">15% quit", "Complaints up", "Reports",
                   "3+ sick", "Rumors"),
  Response = c("Retention bonus", "Team meeting", "Mediation",
              "Health check", "Negotiate"),
  Prevention = c("Fair pay", "Regular feedback", "Clear roles",
                "Insurance", "Union dialogue")
)

team_crisis %>%
  kable(caption = "Team Crisis Management")
```

---

# Slide 349: Weather Crisis Protocol

### Seasonal Disasters

```r
# Weather crisis management
weather_protocol <- tibble(
  Event = c("Cyclone warning", "Flooding", "Extreme heat",
           "Snow/ice", "Drought"),
  Response = c("Evacuate coast", "Relocate ops", "Timing change",
              "Postpone", "Water provision"),
  Sample_Impact = c("Temp replace", "Permanent replace", "None",
                   "Delay", "None"),
  Cost_Impact = c("+30%", "+40%", "+10%", "+20%", "+15%"),
  Timeline = c("+2 weeks", "+4 weeks", "None", "+3 weeks", "None")
)

weather_protocol %>%
  kable(caption = "Weather Crisis Responses")
```

---

# Slide 350: Political Crisis Navigation

### Elections and Coups

"2008 - Coup during fieldwork.
Survey branded 'government propaganda.'
Teams threatened."

**Political Crisis Management:**
- Immediate suspension
- Rebranding as "independent research"
- New partnerships with NGOs
- Resumed after 3 months
- Emphasized neutrality

**Lesson:** Political insurance essential

---

# Slide 351: Technology Failure

### When Systems Crash

```r
# Technology failure recovery
tech_recovery <- tibble(
  Failure = c("Server crash", "Software bug", "Tablets stolen",
             "Internet down", "Power grid failure"),
  Immediate = c("Switch to backup", "Paper backup", "Police report",
               "Offline mode", "Generators"),
  Recovery_Time = c("4 hours", "2 days", "1 week",
                   "Continuous", "Immediate"),
  Data_Loss = c("None", "Minimal", "None if backed up",
               "None", "None"),
  Cost = c("$5k", "$2k", "$30k", "$1k", "$10k")
)

tech_recovery %>%
  kable(caption = "Technology Failure Recovery")
```

---

# Slide 352: Frame Destruction

### When Sampling Frame Disappears

```r
# Frame destruction scenarios
frame_crisis <- tibble(
  Scenario = c("Census building burns", "Flood destroys maps",
              "Cyber attack", "Political deletion",
              "Discovery of major errors"),
  Response = c("Reconstruct from backups", "Satellite imagery",
              "Paper backups", "Alternative sources",
              "Rapid re-listing"),
  Time_Impact = c("+1 month", "+2 months", "+2 weeks",
                 "+6 weeks", "+3 weeks"),
  Quality = c("Maintained", "Reduced", "Maintained",
             "Compromised", "Improved")
)

frame_crisis %>%
  kable(caption = "Frame Destruction Recovery")
```

---

# Slide 353: Stakeholder Crisis

### Managing Expectations

```r
# Stakeholder crisis management
stakeholder_crisis <- tibble(
  Stakeholder = c("Minister", "Donor", "Public", "Media", "Parliament"),
  Crisis = c("Wants different questions", "Threatens withdrawal",
            "Lost trust", "Negative coverage", "Questions validity"),
  Response = c("Document, explain impact", "Emergency meeting",
              "Transparency campaign", "Press conference",
              "Technical briefing"),
  Outcome = c("Compromise", "Negotiated", "Rebuilt slowly",
             "Corrected", "Accepted")
)

stakeholder_crisis %>%
  kable(caption = "Stakeholder Crisis Management")
```

---

# Slide 354: Quality Crisis

### When Quality Fails

```r
# Quality failure recovery
quality_recovery <- tibble(
  Problem = c("Fraud detected", "Translation errors",
             "Wrong sample", "Measurement error",
             "Weight miscalculation"),
  Detection = c("Validation", "Review", "Analysis",
               "External check", "Validation"),
  Response = c("Re-interview 20%", "Retranslate, redo",
              "Acknowledge, adjust", "Recalibrate",
              "Recalculate, document"),
  Impact = c("Major", "Major", "Fatal", "Serious", "Serious")
)

quality_recovery %>%
  kable(caption = "Quality Crisis Recovery")
```

---

# Slide 355: Financial Controls

### Preventing Financial Crisis

```r
# Financial control framework
financial_controls <- tibble(
  Control = c("Dual signature", "Weekly reconciliation",
             "Expense approval", "Audit trail",
             "Reserve fund"),
  Purpose = c("Prevent fraud", "Catch errors", "Control spending",
             "Accountability", "Emergency buffer"),
  Level = c(">$1000", "All accounts", ">$500",
           "All transactions", "10% budget"),
  Frequency = c("Every payment", "Weekly", "Before expense",
                "Real-time", "Maintained")
)

financial_controls %>%
  kable(caption = "Financial Crisis Prevention")
```

---

# Slide 356: Media Crisis Management

### When Media Attacks

"2017 - Headline: 'Government Wastes Millions on Useless Survey'"

**Media Crisis Response:**
1. Don't panic or respond immediately
2. Gather facts
3. Prepare clear response
4. Use data to counter
5. Offer transparency
6. Learn for next time

**Result:** Public support increased after transparency

---

# Slide 357: Legal Crisis Preparation

### Legal Challenges

```r
# Legal crisis preparation
legal_prep <- tibble(
  Issue = c("Privacy violation claim", "Discrimination complaint",
           "Contract dispute", "Injury claim",
           "Data breach"),
  Prevention = c("Clear consent", "EEO training", "Clear contracts",
                "Insurance", "Security protocol"),
  Response = c("Legal counsel", "Investigation", "Mediation",
              "Insurance claim", "Notification"),
  Cost = c("$$", "$", "$$$", "$$", "$$$")
)

legal_prep %>%
  kable(caption = "Legal Crisis Preparation")
```

---

# Slide 358: Recovery Metrics

### Measuring Crisis Recovery

```r
# Recovery success metrics
recovery_metrics <- tibble(
  Metric = c("Operations restored", "Quality recovered",
            "Team retained", "Budget impact",
            "Timeline impact", "Reputation"),
  Target = c("100%", ">90%", ">85%", "<20%", "<4 weeks", "Maintained"),
  Typical = c("95%", "85%", "75%", "25%", "6 weeks", "Damaged"),
  Best_Case = c("100%", "95%", "90%", "10%", "2 weeks", "Enhanced")
)

recovery_metrics %>%
  kable(caption = "Crisis Recovery Success Metrics")
```

---

# Slide 359: Simulation Exercise

### Crisis Response Drill

```r
# Crisis simulation scenarios
simulation <- function() {
  crises <- c("Earthquake", "Budget cut 40%", "Team strike",
             "Data breach", "Political coup", "Pandemic")
  
  selected_crisis <- sample(crises, 1)
  
  response_needed <- list(
    immediate = "Safety and assessment",
    day_1 = "Stakeholder communication",
    week_1 = "Recovery plan",
    implementation = "Execute plan"
  )
  
  return(list(
    crisis = selected_crisis,
    response_checklist = response_needed
  ))
}

# Run simulation
simulation()
```

---

# Slide 360: Tuesday 5:00 PM Reality

### End of Day Crisis

Harry's phone rings at 4:55 PM:

"Donor wants preliminary results tomorrow.
We're only 60% complete.
Minister expecting briefing.
What do we do?"

**Real-time solution:**
- Explain situation honestly
- Provide what's available
- Clear confidence intervals
- Timeline for complete results
- Document everything

---

# Slide 361: Lessons Database

### Learning from Every Crisis

```r
# Crisis lessons database structure
lessons_db <- tibble(
  Year = c(2010, 2015, 2018, 2020, 2023),
  Crisis = c("Flood", "Earthquake", "Budget cut",
            "COVID-19", "Coup"),
  Key_Lesson = c("Need backup sites", "Staff safety first",
                "Multiple funding sources", "Remote capability essential",
                "Political neutrality vital"),
  Change_Made = c("Alternative samples prepared", "Security protocol",
                 "Donor diversity", "Mixed-mode standard",
                 "Independence emphasized")
)

lessons_db %>%
  kable(caption = "Crisis Lessons Database")
```

---

# Slide 362: Crisis Communication

### Clear Messages Under Pressure

```r
# Crisis communication templates
comm_templates <- tibble(
  Audience = c("Staff", "Government", "Donors", "Public", "Media"),
  Key_Message = c("Safety first, instructions follow",
                 "Temporary delay, quality maintained",
                 "Funds secure, may need flexibility",
                 "Your data safe, survey continues",
                 "Technical issue, resolving quickly"),
  Channel = c("WhatsApp + SMS", "Official letter", "Video call",
             "Website + social", "Press release"),
  Timing = c("Immediate", "Within 24hr", "Within 24hr",
            "Within 48hr", "When ready")
)

comm_templates %>%
  kable(caption = "Crisis Communication Framework")
```

---

# Slide 363: Insurance and Risk

### Financial Protection

```r
# Survey insurance coverage
insurance_coverage <- tibble(
  Risk = c("General liability", "Professional indemnity",
          "Equipment", "Data breach", "Political risk"),
  Coverage = c("$2M", "$5M", "Replacement value",
              "$10M", "$1M"),
  Cost_Percent = c("0.5%", "1%", "2%", "1%", "3%"),
  Claim_Success = c("High", "Moderate", "High", "Low", "Low")
)

insurance_coverage %>%
  kable(caption = "Survey Insurance Portfolio")
```

---

# Slide 364: Crisis Leadership

### Leading Through Crisis

**Harry's Crisis Leadership Principles:**

1. **Stay calm** - panic spreads fast
2. **Communicate clearly** - no ambiguity  
3. **Decide quickly** - perfect is enemy of good
4. **Document everything** - CYA essential
5. **Learn always** - every crisis teaches
6. **Protect people** - surveys replaceable, people aren't

"Leadership is tested in crisis"

---

# Slide 365: Contingency Reserves

### Budget Crisis Preparation

```r
# Contingency reserve planning
reserves <- tibble(
  Component = c("General contingency", "Security emergency",
               "Natural disaster", "Technical failure",
               "Inflation buffer"),
  Percent_Budget = c(10, 3, 2, 2, 3),
  Access_Authority = c("PM", "Director", "Director", "PM", "PM"),
  Documentation = c("Simple", "Detailed", "Detailed", "Simple", "Simple")
)

reserves %>%
  mutate(Total = sum(Percent_Budget)) %>%
  kable(caption = "20% Total Contingency Reserve")
```

---

# Slide 366: Partner Network

### Crisis Support Network

```r
# Crisis support partners
support_network <- tibble(
  Partner = c("UN OCHA", "Red Cross", "Military", "Police",
             "Embassy", "Local NGOs"),
  Support_Type = c("Coordination", "Emergency", "Evacuation",
                  "Security", "Diplomatic", "Local knowledge"),
  Contact_Level = c("Director", "Director", "Ministry",
                   "Commissioner", "Ambassador", "Director"),
  MOU_Status = c("Yes", "Yes", "Sometimes", "Sometimes", "Yes", "Yes")
)

support_network %>%
  kable(caption = "Crisis Support Network")
```

---

# Slide 367: Post-Crisis Evaluation

### Learning and Improving

```r
# Post-crisis evaluation framework
evaluation_framework <- tibble(
  Component = c("Response time", "Decision quality",
               "Communication", "Recovery speed",
               "Cost impact", "Lessons captured"),
  Metric = c("Hours to activate", "Outcomes achieved",
            "Stakeholder feedback", "Days to normal",
            "% over budget", "Database updated"),
  Target = c("<24hr", ">80% positive", ">4/5 rating",
            "<30 days", "<20%", "100%")
)

evaluation_framework %>%
  kable(caption = "Post-Crisis Evaluation")
```

---

# Slide 368: Crisis Prevention

### Proactive Risk Management

```r
# Risk prevention measures
prevention <- tibble(
  Risk_Category = c("Natural", "Political", "Technical",
                   "Financial", "Human"),
  Prevention = c("Seasonal planning", "Neutrality maintained",
                "Redundancy built", "Controls strong",
                "Team care"),
  Investment = c("$", "$", "$$$", "$$", "$$"),
  ROI = c("10x", "Invaluable", "5x", "20x", "15x")
)

prevention %>%
  kable(caption = "Crisis Prevention ROI")
```

---

# Slide 369: Global Crisis Examples

### Learning from Others

```r
# Global crisis case studies
global_cases <- tibble(
  Country = c("Haiti 2010", "Syria 2011-", "Philippines 2013",
             "West Africa 2014", "Global 2020"),
  Crisis = c("Earthquake", "Conflict", "Typhoon",
            "Ebola", "COVID-19"),
  Survey_Impact = c("Complete restart", "Remote methods",
                   "Rapid assessment", "No-go zones",
                   "Mode change"),
  Innovation = c("SMS data", "WhatsApp surveys", "Drone mapping",
                "Phone panels", "Web transition")
)

global_cases %>%
  kable(caption = "Global Crisis Innovations")
```

---

# Slide 370: Building Resilience

### Organizational Preparedness

```r
# Resilience building components
resilience <- tibble(
  Component = c("Flexible contracts", "Cross-trained staff",
               "Multiple suppliers", "Diversified funding",
               "Strong partnerships"),
  Normal_Benefit = c("Cost savings", "Efficiency", "Competition",
                    "Stability", "Support"),
  Crisis_Benefit = c("Rapid adjustment", "Coverage maintained",
                    "Alternatives ready", "Buffer available",
                    "Help available"),
  Implementation = c("Standard", "Ongoing", "Policy", "Strategic", "Continuous")
)

resilience %>%
  kable(caption = "Building Survey Resilience")
```

---

# Slide 371: Crisis Decision Tree

### Rapid Decision Framework

```r
cat("
CRISIS DECISION TREE

Is there immediate danger to staff?
├─ YES → Evacuate first, assess later
└─ NO → Continue assessment

Can survey objectives still be met?
├─ YES → Adapt and continue
└─ NO → Consider alternatives
    ├─ Partial completion possible?
    │   ├─ YES → Reduce scope
    │   └─ NO → Suspend/postpone
    └─ Alternative methods available?
        ├─ YES → Redesign
        └─ NO → Document and close
")
```

---

# Slide 372: Reputation Management

### Protecting Credibility

```r
# Reputation protection strategies
reputation <- tibble(
  Threat = c("Quality questions", "Political bias claim",
            "Cost overrun", "Delay", "Data breach"),
  Response = c("Transparency", "Independence proof",
              "Explain value", "Regular updates",
              "Take responsibility"),
  Outcome = c("Trust maintained", "Credibility intact",
             "Understanding", "Patience", "Respect for honesty")
)

reputation %>%
  kable(caption = "Reputation Crisis Management")
```

---

# Slide 373: Staff Welfare Crisis

### Caring for Teams

```r
# Staff welfare in crisis
staff_welfare <- tibble(
  Support = c("Counseling services", "Emergency leave",
             "Salary advance", "Medical care",
             "Family support"),
  When = c("Trauma/stress", "Personal crisis", "Financial crisis",
          "Illness/injury", "Family emergency"),
  Policy = c("EAP contract", "5 days automatic", "1 month available",
            "Full coverage", "Flexible"),
  Usage = c("15% annually", "8% annually", "5% annually",
           "As needed", "3% annually")
)

staff_welfare %>%
  kable(caption = "Staff Crisis Support Systems")
```

---

# Slide 374: Supply Chain Crisis

### When Materials Don't Arrive

```r
# Supply chain crisis management
supply_crisis <- tibble(
  Item = c("Tablets", "Vehicles", "Paper forms",
          "PPE", "Fuel"),
  Alternative = c("Phones/paper", "Motorcycles/walk",
                 "Print locally", "Source locally",
                 "Budget increase"),
  Time_Impact = c("+1 week", "None", "+3 days",
                 "+1 week", "Immediate"),
  Quality_Impact = c("Minimal", "Slower", "None",
                    "None", "None")
)

supply_crisis %>%
  kable(caption = "Supply Chain Alternatives")
```

---

# Slide 375: Exit Strategy

### When to Pull the Plug

```r
# Survey termination criteria
exit_criteria <- tibble(
  Criterion = c("Staff safety", "Quality threshold",
               "Budget overrun", "Political interference",
               "Response rate"),
  Red_Line = c("Any threat", "<60% standard", ">50%",
              "Independence lost", "<40%"),
  Decision = c("Immediate", "Consultation", "Donor discussion",
              "Document and exit", "Attempt recovery"),
  Recovery = c("When safe", "If fixable", "If funded",
              "If resolved", "One attempt")
)

exit_criteria %>%
  kable(caption = "Survey Exit Criteria")
```

---

# Slide 376: Success Despite Crisis

### Tuesday 5:15 PM - Hope

Harry's closing story:

"2019 - Everything went wrong.
Cyclone, coup, budget cut 50%.
Team of 50 became 20.

We adapted, innovated, persevered.
Delivered quality data on time.
Won international recognition.

Crisis reveals character."

---

# Slide 377: Crisis Preparedness Checklist

### Your Emergency Ready Check

✅ Crisis response plan documented
✅ Communication tree established
✅ Backup systems tested
✅ Financial reserves allocated
✅ Insurance coverage adequate
✅ Partnerships documented
✅ Team trained on protocols
✅ Lessons database maintained
✅ Regular drills conducted

---

# Slide 378: 30 Years of Crises

### Harry's Crisis Statistics

```r
# Harry's career crisis summary
career_crises <- tibble(
  Decade = c("1990s", "2000s", "2010s", "2020s"),
  Major_Crises = c(8, 12, 15, 10),
  Surveys_Lost = c(2, 1, 0, 0),
  Key_Learning = c("Preparation", "Flexibility", "Resilience", "Innovation")
)

career_crises %>%
  mutate(Success_Rate = paste0(
    round((Major_Crises - Surveys_Lost) / Major_Crises * 100), "%"
  )) %>%
  kable(caption = "Crisis Survival Rate: 95.6%")
```

---

# Slide 379: Final Crisis Wisdom

### What Harry Knows

**Crisis Management Truth:**

1. **Crises are certain** - not if, but when
2. **Preparation pays off** - 10x return
3. **People matter most** - protect them
4. **Documentation saves you** - always CYA
5. **Learn from everything** - growth opportunity
6. **Stay calm** - others depend on you

"Smooth seas never made skilled sailors"

---

# Slide 380: Module 8 Summary

### Crisis Management Mastery

**You Now Understand:**
- Crisis types and responses
- Prevention and preparation
- Communication strategies
- Recovery planning
- Documentation requirements
- Resilience building

"Every crisis conquered makes you stronger"

---

# Slide 381: Exercise - Crisis Response

### Your Crisis Plan

```r
# Design your crisis response
your_crisis_plan <- list(
  survey = "National Health Survey",
  budget = 2000000,
  timeline = "6 months",
  crisis = "Earthquake destroys 30% of sample"
)

# Develop:
# 1. Immediate response (Day 1)
# 2. Assessment plan (Week 1)
# 3. Recovery strategy (Week 2-4)
# 4. Documentation needs

print("Create comprehensive crisis response")
# Solution in module8_crisis_plan.R
```

---

# Slide 382: Quick Reference - Crisis

### Crisis Response Quick Card

| Crisis Type | First Response | Key Decision | Timeline |
|------------|---------------|--------------|----------|
| Natural | Staff safety | Assess damage | 1-4 weeks |
| Political | Suspend | Neutrality | 2-8 weeks |
| Security | Evacuate | Safety assessment | 1-12 weeks |
| Budget | Options | Scope reduction | Immediate |
| Technical | Backup | Recovery plan | 1-2 weeks |

---

# Slide 383: International Crisis Support

### Global Resources Available

```r
# International crisis support
global_support <- tibble(
  Organization = c("UN OCHA", "World Bank", "WHO", "UNHCR", "IOM"),
  Support = c("Coordination", "Funding", "Health emergency",
             "Refugee crisis", "Migration crisis"),
  Response_Time = c("24 hrs", "1 week", "48 hrs", "48 hrs", "72 hrs"),
  Contact = c("ocha.org", "worldbank.org", "who.int",
             "unhcr.org", "iom.int")
)

global_support %>%
  kable(caption = "International Crisis Support")
```

---

# Slide 384: Module 8 Complete!

### Crisis Management Achieved

**Competencies Mastered:**
- ✓ Identify crisis types
- ✓ Activate response protocols
- ✓ Manage communications
- ✓ Lead through crisis
- ✓ Document everything
- ✓ Build resilience

---

# Slide 385: Tuesday Day Summary

### 8 Modules, 385 Slides, One Day

**What You've Learned:**
1. Complex design foundations
2. Stratification mastery
3. Cluster economics
4. Multi-stage integration
5. Weight calculations
6. Non-response solutions
7. Special populations
8. Crisis management

"From basics to advanced in one intense day"

---

# Slide 386: Key Takeaways

### Tuesday's Top 10 Lessons

1. **Stratify always** - variance reduction
2. **Cluster wisely** - cost efficiency
3. **Weight correctly** - validity
4. **Document everything** - credibility
5. **Plan for 70% response** - reality
6. **Special populations need special methods**
7. **Crises will happen** - prepare
8. **International standards matter**
9. **Software helps but understanding essential**
10. **Experience teaches what books cannot**

---

# Slide 387: Tomorrow Preview

### Wednesday - Advanced Topics

Harry's preview:

"Tomorrow we go deeper:
- Small area estimation
- Machine learning applications
- Real-time monitoring
- Quality frameworks
- Advanced variance
- Future of surveys

Rest well - tomorrow is intense!"

---

# Slide 388: Your Homework

### Before Tomorrow

Review and prepare:
1. Run code examples from today
2. Review modules 5-6 especially
3. Prepare your country case
4. List your challenges
5. Rest your brain!

"See you at 7:45 AM sharp!"

---

# Slide 389: Resources Recap

### Your Toolkit

**Standards Mastered:**
- World Bank LSMS Manual
- Eurostat Doc 65/2023
- UN Handbook F.98
- OECD PIAAC Standards
- WHO STEPS Manual
- ILO Survey Manual

**Software Ready:**
- R survey package
- Stata svy commands
- SPSS Complex Samples

---

# Slide 390: Network Building

### Stay Connected

```r
# Workshop network structure
network <- tibble(
  Platform = c("WhatsApp Group", "GitHub Repo", "Email List",
              "LinkedIn Group", "Monthly Zoom"),
  Purpose = c("Quick help", "Code sharing", "Announcements",
             "Professional", "Deep dives"),
  Active = c("Daily", "Weekly", "Monthly", "Ongoing", "Monthly")
)

network %>%
  kable(caption = "Post-Workshop Network")
```

---

# Slide 391: Personal Reflection

### Tuesday 5:30 PM

Harry's closing reflection:

"30 years ago, I knew nothing.
Today, you know what took me
decades to learn through mistakes.

Use this knowledge wisely.
Help others learn.
Build better surveys.
Generate better evidence.
Improve lives."

---

# Slide 392: Q&A Preparation

### Your Questions Matter

Common end-of-day questions:
- How to convince management?
- Budget for proper design?
- Software recommendations?
- Career development?
- Specific country challenges?

"No question too basic or advanced"

---

# Slide 393: Acknowledgments

### Standing on Shoulders

Harry acknowledges:

"Every lesson comes from:
- Mentors who taught me
- Colleagues who corrected me
- Disasters that educated me
- Successes that motivated me
- Failures that humbled me"

"We build on others' experience"

---

# Slide 394: The Impact Potential

### Why This Matters

```r
# Survey impact calculation
impact <- tibble(
  Decision = c("Poverty programs", "Health services", "Education",
              "Infrastructure", "Emergency response"),
  People_Affected = c("Millions", "Millions", "Millions",
                      "Millions", "Thousands"),
  Budget_Influenced = c("Billions", "Billions", "Billions",
                        "Billions", "Millions"),
  Your_Role = c("Critical", "Critical", "Critical",
               "Critical", "Critical")
)

impact %>%
  kable(caption = "Your Survey Impact")
```

---

# Slide 395: Technical Excellence

### The Standard You Represent

"When you design a survey:
- Ministers depend on you
- Donors trust you
- People count on you
- History judges you
- Future builds on you

Technical excellence is ethical responsibility"

---

# Slide 396: Continuous Learning

### Survey Methods Evolution

```r
# Evolution timeline
evolution <- tibble(
  Era = c("1990s", "2000s", "2010s", "2020s", "2030s"),
  Innovation = c("Computer-assisted", "Web surveys", "Mobile data",
                "AI/ML integration", "?"),
  Challenge = c("Training", "Coverage", "Quality", "Privacy", "Unknown"),
  Opportunity = c("Efficiency", "Speed", "Cost", "Insights", "Unlimited")
)

evolution %>%
  kable(caption = "Survey Evolution Timeline")
```

---

# Slide 397: Your Action Plan

### Next 90 Days

Week 1-2:
- Review all materials
- Setup software
- Practice code

Week 3-4:
- Design pilot
- Test methods
- Document process

Month 2-3:
- Implement improvements
- Train team
- Share learnings

---

# Slide 398: Closing Philosophy

### Harry's Survey Philosophy

"Surveys are not about numbers.
They're about people's lives,
their struggles, hopes, needs.

Every percentage point represents
thousands of human stories.

Never forget the humanity
behind the statistics."

---

# Slide 399: Final Challenge

### Your Survey Mission

"I challenge you:

Design one survey that:
- Follows international standards
- Respects respondents
- Delivers quality data
- Influences positive change
- Makes you proud

That's success."

---

# Slide 400: End of Tuesday

### Day 2 Complete!

**Tuesday Achievement Unlocked:**
- 8 modules mastered
- 400 slides absorbed
- International standards learned
- Real experience shared
- Network built
- Confidence gained

**Harry's farewell:**
"See you tomorrow for Day 3.
Tonight, rest that amazing brain!"

---

## End of Tuesday Workshop
### 400 Slides of Intensity Complete

*"Today you learned 20 years of experience in 10 hours"*

**Tomorrow: Wednesday - Advanced Applications**

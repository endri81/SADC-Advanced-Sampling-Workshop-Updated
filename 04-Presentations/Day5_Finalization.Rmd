---
title: "Advanced Sampling Methods - Lecture 5"
subtitle: "Friday's Finale: From Data to Decisions"
author: "Advanced Household Survey Methods Workshop"
institute: "SADC Statistical Training Centre"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: [default, metropolis, metropolis-fonts, "custom.css"]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      slideNumberFormat: "%current%"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.width = 10,
  fig.height = 5,
  fig.align = 'center',
  cache = FALSE
)

library(tidyverse)
library(survey)
library(knitr)
library(kableExtra)
library(gt)
library(plotly)
library(DT)
library(gtExtras)
# Set theme
theme_set(theme_minimal(base_size = 14))

# SADC colors
sadc_colors <- c("#003f7f", "#0066cc", "#ff6b35", "#00a86b", "#ffb800", "#dc3545")

set.seed(2025)
```

class: inverse, center, middle

# MODULE 1: STRATEGIC SYNTHESIS
## Friday 7:00 AM - The Ministerial Presentation
### Slides 1-50

---

# Slide 1: Friday Morning - The Stakes

## 7:00 AM - Harry's Office

The email that sets the tone:

**From:** Minister of Planning  
**Subject:** RE: Today's Presentation  
**Priority:** URGENT

"Harry,

The cabinet is considering three options:
1. Continue current methodology (save money, questionable quality)
2. Adopt your integrated approach (investment required)
3. Outsource to international firm ($2M USD)

Your presentation at 9:00 AM will determine our path.

Don't let us down."

---

# Slide 2: The Week's Journey - What Harry Learned

```{r week-summary, echo=FALSE, fig.height=4}
week_data <- tibble(
  Day = c("Monday", "Tuesday", "Wednesday", "Thursday"),
  Challenge = c("Foundation gaps", "Frame disasters", 
                "Variance mysteries", "Integration chaos"),
  Solution = c("UNSD/WB standards", "Multiple frames", 
               "Advanced estimation", "Automated pipeline"),
  Impact = c(25, 40, 60, 85)
)

ggplot(week_data, aes(x = Day, y = Impact)) +
  geom_col(fill = sadc_colors[2], alpha = 0.8) +
  geom_text(aes(label = paste0(Impact, "%")), vjust = -0.5, size = 5) +
  labs(title = "Cumulative Capability Building Through the Week",
       subtitle = "Each day built on previous learning",
       y = "Implementation Readiness (%)") +
  theme_minimal(base_size = 14)
```

---

# Slide 3: The Presentation Framework

## Harry's Strategic Approach

```{r framework, echo=FALSE}
framework <- tibble(
  Component = c("Current State", "International Best Practice", 
                "Our Capacity", "Implementation Plan", "Expected Results"),
  Time = c("5 min", "10 min", "10 min", "15 min", "5 min"),
  Key_Message = c("Honest assessment", "What excellence looks like",
                  "What we can achieve", "Concrete steps", "ROI demonstration")
)

framework %>%
  gt() %>%
  tab_header(
    title = "45-Minute Presentation Structure",
    subtitle = "Designed for ministerial decision-making"
  ) %>%
  tab_style(
    style = cell_fill(color = "#e8f4f8"),
    locations = cells_body(columns = everything())
  )
```

---

# Slide 4: Current State Assessment - The Truth

```{r current-state, echo=FALSE}
# Create assessment matrix
assessment <- expand.grid(
  Area = c("Sampling", "Weights", "Variance", "Documentation", "Automation"),
  Score = NA
) %>%
  mutate(
    Score = c(3, 2, 2, 1, 1),
    International_Standard = 5,
    Gap = International_Standard - Score
  )

ggplot(assessment, aes(x = Area, y = Score)) +
  geom_col(fill = sadc_colors[6], alpha = 0.6) +
  geom_col(aes(y = International_Standard), 
           fill = "transparent", color = sadc_colors[2], 
           size = 1.5, linetype = "dashed") +
  geom_text(aes(label = Score), vjust = -0.5, size = 5) +
  labs(title = "Current Statistical Capacity vs International Standards",
       subtitle = "Score: 1 (Poor) to 5 (Excellent)",
       y = "Capacity Score", x = "") +
  coord_flip() +
  theme_minimal(base_size = 14)
```

**Bottom Line:** Operating at 36% of international standard

---

# Slide 5: The Cost of Poor Quality

## What Bad Sampling Really Costs

```{r cost-analysis2, echo=TRUE}
# Calculate real costs of poor sampling
poor_quality_costs <- tibble(
  Category = c("Wrong policy decisions", "Repeated surveys", 
               "Lost donor confidence", "Staff overtime", "Crisis management"),
  Annual_Cost_USD = c(5000000, 800000, 2000000, 150000, 100000)
)

total_cost <- sum(poor_quality_costs$Annual_Cost_USD)

poor_quality_costs %>%
  mutate(Percentage = Annual_Cost_USD / total_cost * 100) %>%
  arrange(desc(Annual_Cost_USD)) %>%
  gt() %>%
  fmt_currency(columns = Annual_Cost_USD, currency = "USD") %>%
  fmt_percent(columns = Percentage, scale_values = FALSE, decimals = 1) %>%
  tab_header(
    title = paste("Annual Cost of Poor Survey Quality: $", 
                  format(total_cost, big.mark = ","), "USD"),
    subtitle = "Hidden costs destroying our credibility"
  )
```

---

# Slide 6: International Best Practice Synthesis

```{r best-practice, echo=FALSE}
practices <- tibble(
  Institution = c("Eurostat", "World Bank", "OECD", "UN Stats"),
  Key_Strength = c("Harmonization", "Field reality", "Innovation", "Standards"),
  Application = c("EU-SILC design", "LSMS framework", "PIAAC methods", "SDG indicators"),
  Our_Gap = c("No harmonization", "Limited field protocols", 
              "No innovation budget", "Partial compliance")
)

practices %>%
  gt() %>%
  tab_header(
    title = "International Excellence Standards",
    subtitle = "What we should be implementing"
  ) %>%
  tab_style(
    style = cell_text(color = "red", weight = "bold"),
    locations = cells_body(columns = Our_Gap)
  )
```

---

# Slide 7: The Integrated Solution

## Harry's Unified Framework

```{r integrated-solution, echo=TRUE}
# The solution architecture
integrated_framework <- list(
  design = list(
    sampling = "Two-stage PPS with stratification",
    frame = "Multiple frame integration with deduplication",
    rotation = "25% panel rotation (EU-SILC model)"
  ),
  
  implementation = list(
    data_collection = "Mixed-mode with propensity adjustment",
    quality_control = "Real-time monitoring dashboard",
    documentation = "Automated metadata generation"
  ),
  
  analysis = list(
    weights = "GREG calibration with trimming",
    variance = "Linearization with replicate validation",
    missing = "Multiple imputation with survey weights"
  ),
  
  dissemination = list(
    outputs = "Automated report generation",
    access = "Public use files with disclosure control",
    reproducibility = "Version-controlled analysis scripts"
  )
)

str(integrated_framework, max.level = 2)
```

---

# Slide 8: Implementation Roadmap

```{r roadmap, echo=FALSE}
roadmap <- tibble(
  Quarter = paste0("Q", 1:8),
  Year = c(rep("Year 1", 4), rep("Year 2", 4)),
  Milestone = c("Framework design", "Pilot testing", "Staff training", "Partial rollout",
                "Full implementation", "First results", "Optimization", "Excellence achieved"),
  Investment = c(50000, 75000, 40000, 60000, 100000, 30000, 25000, 20000),
  Cumulative_Capability = c(15, 30, 45, 60, 75, 85, 92, 98)
)

ggplot(roadmap, aes(x = Quarter, y = Cumulative_Capability, group = 1)) +
  geom_line(color = sadc_colors[2], size = 2) +
  geom_point(aes(size = Investment), color = sadc_colors[4]) +
  geom_text(aes(label = Milestone), angle = 45, hjust = 0, vjust = -1, size = 3) +
  scale_size_continuous(range = c(3, 10), guide = FALSE) +
  labs(title = "24-Month Journey to Statistical Excellence",
       subtitle = "Phased implementation with measured progress",
       y = "Capability (% of International Standard)") +
  theme_minimal(base_size = 14)
```

---

# Slide 9: Quick Win - Immediate Improvements

## What We Can Do Monday Morning

```{r quick-wins, echo=TRUE}
# Immediate improvements with zero budget
quick_wins <- function() {
  improvements <- list(
    "Document random starts" = "5 minutes per survey",
    "Calculate design weights" = "1 hour setup",
    "Check frame coverage" = "2 hours analysis",
    "Create field monitoring sheet" = "30 minutes",
    "Generate quality indicators" = "R script ready"
  )
  
  for(task in names(improvements)) {
    cat(sprintf("âœ“ %s: %s\n", task, improvements[[task]]))
  }
  
  cat("\nTotal time investment: <1 day\n")
  cat("Quality improvement: 15-20%\n")
  cat("Cost: $0\n")
}

quick_wins()
```

---

# Slide 10: Technology Stack Required

```{r tech-stack, echo=FALSE}
tech <- tibble(
  Category = c("Software", "Software", "Hardware", "Hardware", 
               "Training", "Training"),
  Item = c("R + RStudio", "Survey Solutions CAPI", "Tablets (20)", 
           "Server", "R for Survey Analysis", "Sampling Theory"),
  Current = c("Excel only", "Paper", "None", "Desktop PC", 
              "None", "1990s manual"),
  Cost_USD = c(0, 0, 8000, 3000, 2000, 1500),
  Priority = c("Critical", "Critical", "High", "Medium", "Critical", "High")
)

tech %>%
  gt() %>%
  fmt_currency(columns = Cost_USD, currency = "USD") %>%
  tab_header(
    title = "Technology Investment Requirements",
    subtitle = paste("Total investment needed: $", 
                     format(sum(tech$Cost_USD), big.mark = ","))
  ) %>%
  tab_style(
    style = cell_fill(color = "#ffe6e6"),
    locations = cells_body(
      columns = Priority,
      rows = Priority == "Critical"
    )
  )
```

---

# Slide 11: Staff Capacity Building Plan

```{r capacity-building, echo=FALSE}
training_plan <- tibble(
  Month = 1:6,
  Topic = c("Sampling theory", "R basics", "Survey package", 
            "Weight calculation", "Variance estimation", "Report automation"),
  Participants = c(20, 20, 15, 15, 10, 10),
  Instructor = c("Harry", "External", "Harry", "Harry", "External", "Harry"),
  Days = c(3, 5, 3, 2, 3, 2)
)

training_hours <- sum(training_plan$Participants * training_plan$Days * 8)

training_plan %>%
  gt() %>%
  tab_header(
    title = "Six-Month Intensive Training Program",
    subtitle = paste("Total training hours:", format(training_hours, big.mark = ","))
  ) %>%
  tab_style(
    style = cell_fill(color = "#e8f4f8"),
    locations = cells_body(
      columns = Instructor,
      rows = Instructor == "Harry"
    )
  )
```

---

# Slide 12: Risk Assessment and Mitigation

```{r risks, echo=FALSE}
risks <- tibble(
  Risk = c("Staff resistance", "Budget cuts", "Technical failures", 
           "Political pressure", "Timeline delays"),
  Probability = c("High", "Medium", "Low", "Medium", "Medium"),
  Impact = c("Medium", "High", "Medium", "High", "Low"),
  Mitigation = c("Gradual rollout, show wins", "Phased implementation", 
                 "Backup systems, training", "Transparency, documentation",
                 "Buffer time, parallel tracks")
)

# Create risk matrix visualization
risk_matrix <- expand.grid(
  Probability = c("Low", "Medium", "High"),
  Impact = c("Low", "Medium", "High")
) %>%
  mutate(
    Risk_Score = case_when(
      Probability == "High" & Impact == "High" ~ 9,
      Probability == "High" & Impact == "Medium" ~ 6,
      Probability == "Medium" & Impact == "High" ~ 6,
      TRUE ~ 3
    )
  )

risks %>%
  gt() %>%
  tab_header(
    title = "Risk Register with Mitigation Strategies",
    subtitle = "Proactive planning for success"
  ) %>%
  tab_style(
    style = cell_fill(color = "#fff3cd"),
    locations = cells_body(
      columns = everything(),
      rows = Impact == "High"
    )
  )
```

---

# Slide 13: Success Metrics Framework

```{r metrics, echo=TRUE}
# Define measurable success indicators
success_metrics <- function() {
  metrics <- tribble(
    ~Indicator, ~Baseline, ~Year1_Target, ~Year2_Target, ~Measurement,
    "Response Rate", "68%", "75%", "82%", "Monthly tracking",
    "CV of estimates", "0.18", "0.10", "0.05", "Each survey",
    "Weight CV", "None", "<1.0", "<0.5", "Quarterly review",
    "Documentation", "20%", "70%", "100%", "Audit checklist",
    "Cost per interview", "$65", "$50", "$40", "Financial reports",
    "Minister satisfaction", "2/10", "6/10", "8/10", "Annual survey"
  )
  
  metrics %>%
    gt() %>%
    tab_header(
      title = "Measurable Success Indicators",
      subtitle = "Clear targets with regular monitoring"
    )
}

success_metrics()
```

---

# Slide 14: Budget Comparison - Truth to Power

```{r budget-comparison, echo=FALSE}
options <- tibble(
  Option = c("Status Quo", "Harry's Plan", "Outsource"),
  Year1_Cost = c(400000, 625000, 2000000),
  Year2_Cost = c(400000, 450000, 2000000),
  Total = c(800000, 1075000, 4000000),
  Quality = c("Poor", "Excellent", "Good"),
  Control = c("Full", "Full", "None"),
  Capacity_Building = c("None", "Extensive", "Minimal")
)

ggplot(options, aes(x = Option, y = Total/1000)) +
  geom_col(aes(fill = Quality)) +
  scale_fill_manual(values = c("Poor" = sadc_colors[6], 
                               "Good" = sadc_colors[3],
                               "Excellent" = sadc_colors[5])) +
  geom_text(aes(label = paste0("$", Total/1000, "K")), 
            vjust = -0.5, size = 5, fontface = "bold") +
  labs(title = "Two-Year Cost Comparison",
       subtitle = "Investment vs Quality Trade-offs",
       y = "Cost (Thousands USD)", x = "") +
  theme_minimal(base_size = 14)
```

---

# Slide 15: Return on Investment Analysis

```{r roi, echo=TRUE}
# Calculate ROI for Harry's plan
calculate_roi <- function() {
  # Costs
  investment <- 1075000  # Two-year total
  
  # Benefits (per year after implementation)
  benefits <- list(
    avoided_resurveys = 800000,
    policy_accuracy = 2000000,  # Better targeting
    donor_confidence = 1000000,  # Renewed funding
    efficiency_gains = 300000    # Automation savings
  )
  
  annual_benefit <- sum(unlist(benefits))
  roi <- (annual_benefit - investment/2) / (investment/2) * 100
  payback_months <- (investment / annual_benefit) * 12
  
  cat("Investment: $", format(investment, big.mark = ","), "\n")
  cat("Annual Benefits: $", format(annual_benefit, big.mark = ","), "\n")
  cat("ROI: ", round(roi), "%\n")
  cat("Payback Period: ", round(payback_months), " months\n")
  cat("\n5-Year Net Value: $", 
      format(annual_benefit * 5 - investment, big.mark = ","))
}

calculate_roi()
```

---

# Slide 16: The Data Quality Transformation

```{r quality-transformation, echo=FALSE}
before_after <- tibble(
  Aspect = rep(c("Coverage", "Accuracy", "Timeliness", 
                  "Coherence", "Accessibility"), each = 2),
  Status = rep(c("Before", "After"), 5),
  Score = c(3, 9, 2, 8, 4, 9, 2, 8, 1, 7)
)

ggplot(before_after, aes(x = Aspect, y = Score, fill = Status)) +
  geom_col(position = "dodge") +
  scale_fill_manual(values = c("Before" = sadc_colors[6], 
                               "After" = sadc_colors[5])) +
  geom_text(aes(label = Score), position = position_dodge(0.9), 
            vjust = -0.5) +
  labs(title = "Data Quality Transformation Impact",
       subtitle = "Eurostat quality dimensions (1-10 scale)",
       y = "Quality Score") +
  theme_minimal(base_size = 14)
```

---

# Slide 17: Real Survey Redesign - Live Demo

```{r survey-redesign, echo=TRUE}
# Live redesign of current survey
redesign_survey <- function(current_design) {
  # Current problematic design
  cat("CURRENT DESIGN PROBLEMS:\n")
  cat("- No stratification\n")
  cat("- Equal probability throughout\n")
  cat("- No documentation\n\n")
  
  # New design following international standards
  new_design <- list(
    stage1 = list(
      units = "Enumeration Areas",
      stratification = c("Province", "Urban/Rural"),
      selection = "PPS using census population",
      sample_size = 250
    ),
    stage2 = list(
      units = "Households",
      selection = "Systematic random",
      sample_size = 20,
      total = 5000
    )
  )
  
  cat("NEW DESIGN STRUCTURE:\n")
  print(new_design)
  return(new_design)
}

optimal_design <- redesign_survey(NULL)
```

---

# Slide 18: Script Library Overview

## Ready-to-Use Code Arsenal

```{r script-library, echo=TRUE}
# Master script library structure
script_library <- list(
  "01_sampling/" = c("pps_selection.R", "systematic.R", "stratified.R"),
  "02_weights/" = c("base_weights.R", "calibration.R", "trimming.R"),
  "03_variance/" = c("linearization.R", "jackknife.R", "bootstrap.R"),
  "04_quality/" = c("response_rates.R", "design_effects.R", "coverage.R"),
  "05_analysis/" = c("descriptives.R", "regression.R", "small_area.R"),
  "06_reporting/" = c("automated_tables.R", "quality_report.R", "dashboard.R")
)

# Display structure
for(folder in names(script_library)) {
  cat(folder, "\n")
  for(script in script_library[[folder]]) {
    cat("  â””â”€", script, "\n")
  }
}

cat("\nTotal scripts ready: ", sum(lengths(script_library)))
```

---

# Slide 19: The Decision Matrix

```{r decision-matrix, echo=FALSE}
decision <- tibble(
  Criteria = c("Quality", "Cost", "Speed", "Capacity", "Sustainability", "Control"),
  Weight = c(30, 20, 10, 20, 15, 5),
  Status_Quo = c(2, 8, 5, 1, 2, 10),
  Harrys_Plan = c(9, 6, 7, 9, 9, 10),
  Outsource = c(7, 2, 9, 3, 4, 2)
)

decision_scores <- decision %>%
  mutate(
    SQ_Score = Weight * Status_Quo / 10,
    HP_Score = Weight * Harrys_Plan / 10,
    OS_Score = Weight * Outsource / 10
  )

total_scores <- c(
  StatusQuo = sum(decision_scores$SQ_Score),
  HarrysPlan = sum(decision_scores$HP_Score),
  Outsource = sum(decision_scores$OS_Score)
)

# Create visualization
decision %>%
  pivot_longer(cols = c(Status_Quo, Harrys_Plan, Outsource), 
               names_to = "Option", values_to = "Score") %>%
  ggplot(aes(x = Criteria, y = Score, fill = Option)) +
  geom_col(position = "dodge") +
  scale_fill_manual(values = sadc_colors[c(6, 5, 3)]) +
  labs(title = "Multi-Criteria Decision Analysis",
       subtitle = sprintf("Weighted Scores - Status Quo: %.0f, Harry's Plan: %.0f, Outsource: %.0f",
                         total_scores[1], total_scores[2], total_scores[3]),
       y = "Score (0-10)") +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

---

# Slide 20: Global Best Practice Alignment

```{r global-alignment, echo=FALSE}
alignment <- tibble(
  Standard = c("UN Fundamental Principles", "Eurostat Quality Framework", 
               "World Bank LSMS", "OECD Guidelines", "IMF SDDS"),
  Current_Compliance = c(40, 30, 25, 20, 35),
  After_Implementation = c(95, 90, 92, 88, 90)
)

alignment %>%
  pivot_longer(cols = -Standard, names_to = "Period", values_to = "Compliance") %>%
  ggplot(aes(x = Standard, y = Compliance, fill = Period)) +
  geom_col(position = "dodge") +
  scale_fill_manual(values = c("Current_Compliance" = sadc_colors[6],
                               "After_Implementation" = sadc_colors[5])) +
  geom_text(aes(label = paste0(Compliance, "%")), 
            position = position_dodge(0.9), vjust = -0.5, size = 3) +
  labs(title = "International Standards Compliance",
       subtitle = "Achieving global recognition",
       y = "Compliance (%)") +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

---

# Slide 21: Crisis Prevention System

```{r crisis-prevention, echo=TRUE}
# Early warning system for survey quality
crisis_prevention <- function(survey_data) {
  warnings <- list()
  
  # Check 1: Response rates
  if(mean(survey_data$response_rate) < 0.70) {
    warnings$response <- "âš ï¸ Low response rate detected"
  }
  
  # Check 2: Weight variability
  if(sd(survey_data$weights)/mean(survey_data$weights) > 1.5) {
    warnings$weights <- "âš ï¸ Excessive weight variation"
  }
  
  # Check 3: Coverage
  if(survey_data$frame_coverage < 0.95) {
    warnings$coverage <- "âš ï¸ Frame coverage below threshold"
  }
  
  # Check 4: Design effect
  if(survey_data$deff > 2.5) {
    warnings$deff <- "âš ï¸ High design effect reducing precision"
  }
  
  # Alert system
  if(length(warnings) > 0) {
    cat("QUALITY ALERTS TRIGGERED:\n")
    for(w in warnings) cat(w, "\n")
    cat("\nAction required before publication!")
  } else {
    cat("âœ… All quality indicators within acceptable range")
  }
}

# Test with sample data
test_survey <- list(response_rate = 0.65, weights = c(1, 2, 8, 1.5),
                    frame_coverage = 0.92, deff = 2.8)
crisis_prevention(test_survey)
```

---

# Slide 22: Documentation Template System

```{r documentation, echo=FALSE}
doc_structure <- tibble(
  Document = c("Sampling Design", "Field Operations", "Weight Calculation",
               "Quality Report", "User Guide", "Technical Report"),
  Current_Status = c("None", "Outdated", "None", "Partial", "None", "1995 version"),
  Template_Ready = c("âœ…", "âœ…", "âœ…", "âœ…", "âœ…", "âœ…"),
  Auto_Generate = c("Partial", "No", "Yes", "Yes", "Partial", "Yes")
)

doc_structure %>%
  gt() %>%
  tab_header(
    title = "Documentation Transformation",
    subtitle = "From chaos to comprehensive records"
  ) %>%
  tab_style(
    style = cell_fill(color = "#ffe6e6"),
    locations = cells_body(
      columns = Current_Status,
      rows = Current_Status %in% c("None", "Outdated")
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "#e6ffe6"),
    locations = cells_body(
      columns = Template_Ready
    )
  )
```

---

# Slide 23: Simulation Evidence - Why This Works

```{r simulation-evidence, echo=FALSE}
set.seed(2025)
nsim <- 1000

# Simulate both approaches
simulations <- tibble(
  sim = 1:nsim,
  current = rnorm(nsim, mean = 35, sd = 8),  # High variance
  proposed = rnorm(nsim, mean = 34.5, sd = 2)  # Low variance
)

# Calculate MSE
mse_current <- mean((simulations$current - 34.2)^2)
mse_proposed <- mean((simulations$proposed - 34.2)^2)

# Visualization
simulations %>%
  pivot_longer(cols = c(current, proposed), names_to = "Method", values_to = "Estimate") %>%
  ggplot(aes(x = Estimate, fill = Method)) +
  geom_histogram(alpha = 0.6, position = "identity", bins = 50) +
  geom_vline(xintercept = 34.2, linetype = "dashed", size = 1) +
  scale_fill_manual(values = c("current" = sadc_colors[6],
                               "proposed" = sadc_colors[5]),
                    labels = c("Current Design", "Proposed Design")) +
  labs(title = "1000 Simulations: Current vs Proposed Design",
       subtitle = sprintf("MSE Reduction: %.1f%%", 
                         (1 - mse_proposed/mse_current) * 100),
       x = "Poverty Rate Estimate (%)", y = "Frequency") +
  theme_minimal(base_size = 14)
```

---

# Slide 24: Field Team Feedback Integration

```{r field-feedback, echo=FALSE}
feedback <- tibble(
  Issue = c("Travel time", "Unclear instructions", "Data entry errors",
            "Respondent fatigue", "Safety concerns"),
  Frequency = c("Daily", "Weekly", "Daily", "Often", "Sometimes"),
  Current_Solution = c("None", "Phone calls", "Manual check", "None", "Avoid areas"),
  Proposed_Solution = c("Cluster sampling", "Digital manual", "Validation rules",
                       "Shorter modules", "Team protocols"),
  Impact = c("High", "Medium", "High", "Medium", "High")
)

feedback %>%
  gt() %>%
  tab_header(
    title = "Field Team Pain Points Addressed",
    subtitle = "Solutions based on 200+ interviewer feedback sessions"
  ) %>%
  tab_style(
    style = cell_fill(color = "#fff3cd"),
    locations = cells_body(
      columns = Impact,
      rows = Impact == "High"
    )
  )
```

---

# Slide 25: Partner Organization Alignment

```{r partners, echo=FALSE}
partners <- tibble(
  Organization = c("UN Statistics", "World Bank", "Regional Bureau", 
                   "National Planning", "Finance Ministry"),
  Current_View = c("Concerned", "Skeptical", "Supportive", "Neutral", "Cost-focused"),
  After_Presentation = c("Supportive", "Engaged", "Champion", "Supportive", "Convinced"),
  Commitment = c("Technical assistance", "Funding possibility", 
                 "Regional rollout", "Policy support", "Budget approved")
)

partners %>%
  gt() %>%
  tab_header(
    title = "Stakeholder Alignment Strategy",
    subtitle = "Building coalition for success"
  ) %>%
  tab_style(
    style = cell_text(color = sadc_colors[5], weight = "bold"),
    locations = cells_body(columns = After_Presentation)
  )
```

---

# Slide 26: The Innovation Agenda

```{r innovation, echo=TRUE}
# Future innovations to integrate
innovation_pipeline <- function() {
  innovations <- list(
    "2025 Q3" = "Tablet-based CAPI rollout",
    "2025 Q4" = "Real-time quality dashboard",
    "2026 Q1" = "Machine learning for non-response",
    "2026 Q2" = "Automated small area estimation",
    "2026 Q3" = "AI-assisted questionnaire design",
    "2026 Q4" = "Blockchain for data integrity"
  )
  
  cat("INNOVATION ROADMAP:\n")
  cat("==================\n\n")
  
  for(quarter in names(innovations)) {
    cat(sprintf("%s: %s\n", quarter, innovations[[quarter]]))
  }
  
  cat("\nEstimated efficiency gain: 40% by end 2026")
}

innovation_pipeline()
```

---

# Slide 27: Knowledge Transfer Plan

```{r knowledge-transfer, echo=FALSE}
transfer_plan <- tibble(
  Month = 1:12,
  Activity = c("Core team training", "Write SOPs", "Pilot survey", 
               "Lessons learned", "Expand training", "Regional workshop",
               "Documentation", "Train trainers", "Full rollout",
               "Quality audit", "Optimization", "Conference presentation"),
  Participants = c(5, 5, 20, 10, 30, 50, 5, 10, 100, 15, 10, 200),
  Output = c("Skilled core", "Procedures", "Proof of concept", "Improvements",
             "Wider skills", "Regional buy-in", "Full manual", "Multipliers",
             "Implementation", "Quality report", "Refined system", "Recognition")
)

ggplot(transfer_plan, aes(x = Month, y = Participants)) +
  geom_col(fill = sadc_colors[4]) +
  geom_text(aes(label = Activity), angle = 90, hjust = 0, vjust = 0.5, size = 3) +
  labs(title = "12-Month Knowledge Transfer Timeline",
       subtitle = "Building sustainable institutional capacity",
       y = "Number of Participants") +
  theme_minimal(base_size = 14)
```

---

# Slide 28: Quality Assurance Framework

```{r qa-framework, echo=TRUE}
# Comprehensive QA system
quality_assurance <- function() {
  qa_levels <- list(
    design = c("Peer review", "International expert check", "Simulation test"),
    field = c("Supervisor spot checks", "Audio recording", "GPS verification"),
    data = c("Consistency checks", "Outlier detection", "Duplicate removal"),
    weights = c("Sum validation", "Distribution check", "Calibration totals"),
    analysis = c("Replicate variance", "Sensitivity tests", "Benchmark comparison"),
    output = c("Internal review", "External validation", "User feedback")
  )
  
  total_checks <- sum(lengths(qa_levels))
  
  cat("QUALITY ASSURANCE FRAMEWORK\n")
  cat("===========================\n\n")
  
  for(stage in names(qa_levels)) {
    cat(toupper(stage), "STAGE:\n")
    for(check in qa_levels[[stage]]) {
      cat("  âœ“", check, "\n")
    }
    cat("\n")
  }
  
  cat("Total quality checks:", total_checks)
}

quality_assurance()
```

---

# Slide 29: Cost-Benefit by Component

```{r component-costs, echo=FALSE}
components <- tibble(
  Component = c("Sampling design", "Weight system", "Variance estimation",
                "Documentation", "Automation", "Training"),
  Cost = c(50000, 30000, 25000, 15000, 40000, 60000),
  Benefit = c(200000, 150000, 100000, 80000, 180000, 250000),
  ROI = round((Benefit - Cost) / Cost * 100)
)

components %>%
  mutate(Net_Benefit = Benefit - Cost) %>%
  arrange(desc(ROI)) %>%
  gt() %>%
  fmt_currency(columns = c(Cost, Benefit, Net_Benefit), currency = "USD") %>%
  fmt_percent(columns = ROI, scale_values = FALSE, decimals = 0) %>%
  tab_header(
    title = "Component-Level Investment Analysis",
    subtitle = "Every component pays for itself"
  ) %>%
  data_color(
    columns = ROI,
    colors = scales::col_numeric(
      palette = c("#ffe6e6", "#e6ffe6"),
      domain = c(200, 600)
    )
  )
```

---

# Slide 30: Regional Impact Potential

```{r regional-impact, echo=FALSE}
regional <- tibble(
  Country = paste0("Country ", LETTERS[1:8]),
  Current_Quality = sample(2:4, 8, replace = TRUE),
  Potential_Quality = sample(7:9, 8, replace = TRUE),
  Implementation_Cost = sample(80:150, 8) * 1000,
  Annual_Savings = sample(200:400, 8) * 1000
)

regional %>%
  mutate(
    Quality_Gain = Potential_Quality - Current_Quality,
    Payback_Years = round(Implementation_Cost / Annual_Savings, 1)
  ) %>%
  gt() %>%
  fmt_currency(columns = c(Implementation_Cost, Annual_Savings), 
               currency = "USD") %>%
  tab_header(
    title = "Regional Scaling Opportunity",
    subtitle = "8 SADC countries ready for transformation"
  ) %>%
  data_color(
    columns = Quality_Gain,
    colors = scales::col_numeric(
      palette = c("#fff3cd", "#d4edda"),
      domain = c(3, 7)
    )
  )
```

---

# Slide 31: The Ministerial Dashboard Mock-up

```{r dashboard, echo=TRUE}
# Executive dashboard design
create_dashboard <- function() {
  dashboard <- list(
    indicators = list(
      response_rate = list(value = 0.82, target = 0.80, status = "green"),
      cv_estimates = list(value = 0.048, target = 0.05, status = "green"),
      timeliness = list(value = 45, target = 60, status = "green"),
      budget_used = list(value = 0.78, target = 1.00, status = "green")
    ),
    
    alerts = c("None - all systems operational"),
    
    next_milestones = c(
      "Week 2: Complete frame update",
      "Week 3: Begin field operations",
      "Week 6: Preliminary results"
    )
  )
  
  cat("MINISTER'S SURVEY DASHBOARD\n")
  cat("===========================\n\n")
  
  cat("KEY INDICATORS:\n")
  for(ind in names(dashboard$indicators)) {
    item <- dashboard$indicators[[ind]]
    symbol <- ifelse(item$status == "green", "âœ…", "âš ï¸")
    cat(sprintf("%s %s: %.2f (Target: %.2f)\n", 
                symbol, ind, item$value, item$target))
  }
  
  cat("\nSYSTEM STATUS:", dashboard$alerts, "\n")
}

create_dashboard()
```

---

# Slide 32: Peer Review Quotes

## What International Experts Say

```{r peer-quotes, echo=FALSE}
quotes <- tibble(
  Expert = c("Dr. Smith, Eurostat", "Prof. Johnson, World Bank",
             "Dr. Chen, UN Statistics", "Ms. Garcia, OECD"),
  Quote = c("This framework represents best practice implementation",
            "Exactly what developing statistical systems need",
            "Comprehensive approach addressing all critical gaps",
            "Model for regional statistical development"),
  Date = c("Review, January 2025", "Email, December 2024",
           "Workshop feedback, January 2025", "Consultation, January 2025")
)

quotes %>%
  gt() %>%
  tab_header(
    title = "International Expert Validation",
    subtitle = "External endorsement of approach"
  ) %>%
  tab_style(
    style = cell_text(style = "italic"),
    locations = cells_body(columns = Quote)
  )
```

---

# Slide 33: Before/After Visualization

```{r before-after, echo=FALSE}
# Create comprehensive before/after comparison
comparison_data <- expand.grid(
  Dimension = c("Design", "Implementation", "Analysis", "Dissemination"),
  Stage = c("Before", "After"),
  stringsAsFactors = FALSE
) %>%
  mutate(
    Score = c(2, 8, 3, 9, 2, 8, 1, 7)  # Before and after scores
  )

ggplot(comparison_data, aes(x = Dimension, y = Score, fill = Stage)) +
  geom_col(position = "dodge", width = 0.7) +
  scale_fill_manual(values = c("Before" = sadc_colors[6], 
                               "After" = sadc_colors[5])) +
  geom_text(aes(label = Score), position = position_dodge(0.7), 
            vjust = -0.5, size = 5) +
  labs(title = "Statistical System Transformation",
       subtitle = "Comprehensive improvement across all dimensions",
       y = "Capability Score (0-10)") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "top")
```

---

# Slide 34: Change Management Strategy

```{r change-management, echo=FALSE}
change_phases <- tibble(
  Phase = c("Awareness", "Desire", "Knowledge", "Ability", "Reinforcement"),
  Timeline = c("Month 1", "Month 2-3", "Month 4-6", "Month 7-9", "Month 10-12"),
  Activities = c("Presentations, demos", "Show benefits, address concerns",
                 "Training, documentation", "Practice, pilot, refine",
                 "Recognition, institutionalize"),
  Key_Message = c("Change is needed", "Change benefits you", 
                  "You can do this", "You're succeeding", "This is our way"),
  Resistance_Level = c("High", "Medium", "Medium", "Low", "Minimal")
)

change_phases %>%
  gt() %>%
  tab_header(
    title = "ADKAR Change Management Approach",
    subtitle = "Systematic transition to excellence"
  ) %>%
  data_color(
    columns = Resistance_Level,
    colors = scales::col_factor(
      palette = c("High" = "#ffcccc", "Medium" = "#fff3cd", 
                  "Low" = "#d4edda", "Minimal" = "#c3e6cb"),
      domain = c("High", "Medium", "Low", "Minimal")
    )
  )
```

---

# Slide 35: Success Story Preview

```{r success-preview, echo=TRUE}
# What success looks like in 18 months
future_success <- function() {
  achievements <- list(
    quality = "Meeting all international standards",
    efficiency = "40% reduction in survey costs",
    timeliness = "Results delivered in 6 weeks (was 6 months)",
    credibility = "Government policies based on our data",
    recognition = "Invited to present at ISI World Congress",
    sustainability = "Local team fully capable"
  )
  
  cat("ðŸ“… DATE: 18 MONTHS FROM NOW\n")
  cat("================================\n\n")
  
  cat("Dear Minister,\n\n")
  cat("I'm pleased to report our achievements:\n\n")
  
  for(area in names(achievements)) {
    cat(sprintf("â€¢ %s: %s\n", toupper(area), achievements[[area]]))
  }
  
  cat("\nThe investment has paid off multiple times over.\n")
  cat("\nRespectfully,\nHarry")
}

future_success()
```

---

# Slide 36: Technical Architecture

```{r architecture, echo=FALSE}
architecture <- tibble(
  Layer = c("Data Collection", "Processing", "Storage", "Analysis", "Dissemination"),
  Current_Tech = c("Paper", "Excel", "Folders", "SPSS", "PDF reports"),
  Proposed_Tech = c("Survey Solutions", "R + Python", "PostgreSQL", 
                    "R + Survey Package", "Shiny Dashboard"),
  Integration = c("API", "ETL Pipeline", "Automated backup", 
                  "Reproducible scripts", "Real-time updates")
)

architecture %>%
  gt() %>%
  tab_header(
    title = "Technical Stack Transformation",
    subtitle = "From fragmented to integrated"
  ) %>%
  tab_style(
    style = cell_fill(color = "#e8f4f8"),
    locations = cells_body(columns = Proposed_Tech)
  )
```

---

# Slide 37: Capacity Utilization Analysis

```{r capacity, echo=FALSE}
capacity_data <- tibble(
  Resource = c("Statisticians", "Field Staff", "IT Support", 
               "Analysts", "Managers"),
  Current_Utilization = c(45, 60, 20, 35, 70),
  Optimal_Utilization = c(75, 80, 60, 70, 60),
  After_Implementation = c(72, 78, 55, 68, 58)
)

capacity_data %>%
  pivot_longer(cols = -Resource, names_to = "Scenario", values_to = "Utilization") %>%
  ggplot(aes(x = Resource, y = Utilization, fill = Scenario)) +
  geom_col(position = "dodge") +
  scale_fill_manual(values = c("Current_Utilization" = sadc_colors[6],
                               "Optimal_Utilization" = sadc_colors[3],
                               "After_Implementation" = sadc_colors[5])) +
  geom_hline(yintercept = 70, linetype = "dashed", alpha = 0.5) +
  labs(title = "Human Resource Optimization",
       subtitle = "Better allocation of existing staff",
       y = "Utilization (%)") +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

---

# Slide 38: Continuous Improvement Cycle

```{r improvement-cycle, echo=TRUE}
# Implement Deming Cycle for surveys
pdca_cycle <- function() {
  cycle <- list(
    PLAN = c(
      "Review previous survey performance",
      "Identify improvement opportunities",
      "Design enhanced methodology"
    ),
    DO = c(
      "Pilot test improvements",
      "Train field teams",
      "Implement with close monitoring"
    ),
    CHECK = c(
      "Analyze quality indicators",
      "Compare with targets",
      "Gather stakeholder feedback"
    ),
    ACT = c(
      "Standardize successful improvements",
      "Update documentation",
      "Share lessons learned"
    )
  )
  
  cat("CONTINUOUS IMPROVEMENT FRAMEWORK\n")
  cat("================================\n\n")
  
  for(phase in names(cycle)) {
    cat(phase, "Phase:\n")
    for(i in 1:length(cycle[[phase]])) {
      cat(sprintf("  %d. %s\n", i, cycle[[phase]][i]))
    }
    cat("\n")
  }
  
  cat("Cycle repeats every 6 months for continuous enhancement")
}

pdca_cycle()
```

---

# Slide 39: Audit Trail System

```{r audit-trail, echo=FALSE}
audit_system <- tibble(
  Process = c("Sample Selection", "Data Collection", "Editing", 
              "Weight Calculation", "Analysis", "Publication"),
  Documentation = c("Random seeds, selection log", "Paradata, timestamps",
                    "Edit rules, changes log", "Weight components, checks",
                    "Code versioning, outputs", "Review notes, approvals"),
  Responsible = c("Sampling team", "Field supervisors", "Data team",
                  "Methodology unit", "Analysis team", "Management"),
  Retention = c("Permanent", "5 years", "5 years", "Permanent", 
                "Permanent", "10 years")
)

audit_system %>%
  gt() %>%
  tab_header(
    title = "Complete Audit Trail Framework",
    subtitle = "Transparency and reproducibility guaranteed"
  ) %>%
  tab_style(
    style = cell_fill(color = "#e8f4f8"),
    locations = cells_body(
      columns = Retention,
      rows = Retention == "Permanent"
    )
  )
```

---

# Slide 40: Integration with National Statistics

```{r integration, echo=FALSE}
integration_map <- tibble(
  System = c("Census", "Admin Records", "Business Register", 
             "Vital Statistics", "Agricultural Survey"),
  Current_Link = c("None", "Manual", "None", "Occasional", "None"),
  Proposed_Link = c("Frame updates", "Validation", "Employment data",
                    "Demographics", "Rural indicators"),
  Frequency = c("Decennial", "Quarterly", "Annual", "Monthly", "Annual"),
  Value_Add = c("Accurate frame", "Quality checks", "Economic context",
                "Population updates", "Rural coverage")
)

integration_map %>%
  gt() %>%
  tab_header(
    title = "National Statistical System Integration",
    subtitle = "Breaking down silos for better statistics"
  ) %>%
  tab_style(
    style = cell_text(color = "red"),
    locations = cells_body(
      columns = Current_Link,
      rows = Current_Link == "None"
    )
  )
```

---

# Slide 41: Publication Standards Upgrade

```{r publication, echo=TRUE}
# New publication standards
publication_standards <- function() {
  standards <- list(
    metadata = "DDI compliant XML",
    microdata = "Anonymized public use files",
    tables = "Machine-readable CSV with metadata",
    reports = "Interactive HTML with embedded data",
    visualizations = "D3.js interactive charts",
    api = "RESTful API for developers"
  )
  
  cat("MODERN DISSEMINATION STANDARDS\n")
  cat("==============================\n\n")
  
  cat("Old approach: Static PDF reports\n")
  cat("New approach:\n\n")
  
  for(component in names(standards)) {
    cat(sprintf("  â€¢ %s: %s\n", toupper(component), standards[[component]]))
  }
  
  cat("\nResult: 10x increase in data usage")
}

publication_standards()
```

---

# Slide 42: Error Detection Algorithms

```{r error-detection, echo=TRUE}
# Automated error detection system
detect_errors <- function(data) {
  errors <- list()
  
  # Benford's Law for first digit
  first_digits <- substr(abs(data$income[data$income > 0]), 1, 1)
  benford_expected <- log10(1 + 1/(1:9))
  observed <- table(first_digits) / length(first_digits)
  
  chi_sq <- sum((observed - benford_expected)^2 / benford_expected)
  
  if(chi_sq > 15.5) {  # 5% critical value
    errors$benford <- "âš ï¸ Potential data fabrication detected"
  }
  
  # Outlier detection
  outliers <- abs(scale(data$income)) > 3
  if(sum(outliers) > length(outliers) * 0.05) {
    errors$outliers <- "âš ï¸ Excessive outliers found"
  }
  
  # Duplicate detection
  duplicates <- sum(duplicated(data[, c("age", "income", "education")]))
  if(duplicates > 0) {
    errors$duplicates <- sprintf("âš ï¸ %d potential duplicates", duplicates)
  }
  
  return(errors)
}

# Example detection
test_data <- data.frame(
  income = c(rlnorm(100, 10, 1), rep(50000, 5)),  # With duplicates
  age = c(sample(18:65, 100, replace = TRUE), rep(35, 5)),
  education = c(sample(1:5, 100, replace = TRUE), rep(3, 5))
)

errors <- detect_errors(test_data)
for(e in errors) cat(e, "\n")
```

---

# Slide 43: Resource Optimization Model

```{r optimization, echo=FALSE}
resources <- expand.grid(
  Activity = c("Planning", "Field Work", "Processing", "Analysis"),
  Resource = c("Time", "Budget", "Staff")
) %>%
  mutate(
    Current = c(20, 10, 15, 50, 40, 30, 10, 20, 25, 20, 30, 15),
    Optimal = c(15, 8, 10, 35, 35, 25, 20, 17, 20, 30, 40, 30)
  )

resources %>%
  ggplot(aes(x = Activity, y = Current - Optimal, fill = Resource)) +
  geom_col(position = "dodge") +
  scale_fill_manual(values = sadc_colors[c(2, 3, 4)]) +
  labs(title = "Resource Reallocation Opportunities",
       subtitle = "Percentage points that can be shifted to higher-value activities",
       y = "Potential Savings (%)") +
  theme_minimal(base_size = 12)
```

---

# Slide 44: Emergency Response Protocol

```{r emergency, echo=TRUE}
# Crisis management protocol
emergency_protocol <- function(crisis_type) {
  protocols <- list(
    low_response = c(
      "Immediate: Increase callback attempts",
      "Day 2: Deploy senior interviewers",
      "Day 3: Consider incentives",
      "Day 5: Adjust weights for non-response"
    ),
    
    frame_error = c(
      "Immediate: Stop fieldwork",
      "Day 1: Assess extent of error",
      "Day 2: Develop correction strategy",
      "Day 3: Resume with fixes"
    ),
    
    data_breach = c(
      "Immediate: Isolate affected systems",
      "Hour 2: Notify data protection officer",
      "Hour 4: Assess scope",
      "Day 1: Implement fixes and notify if required"
    )
  )
  
  cat(sprintf("EMERGENCY PROTOCOL: %s\n", toupper(crisis_type)))
  cat(strrep("=", 40), "\n\n")
  
  if(crisis_type %in% names(protocols)) {
    for(i in 1:length(protocols[[crisis_type]])) {
      cat(sprintf("%d. %s\n", i, protocols[[crisis_type]][i]))
    }
  }
  
  cat("\nEscalation: Director â†’ Minister within 24 hours")
}

emergency_protocol("low_response")
```

---

# Slide 45: Legislative Compliance

```{r compliance, echo=FALSE}
compliance_matrix <- tibble(
  Requirement = c("Statistics Act", "Data Protection", "UN Principles",
                  "Quality Standards", "Open Data Policy"),
  Current = c("Partial", "Non-compliant", "Partial", "No", "No"),
  After = c("Full", "Full", "Full", "Full", "Full"),
  Actions = c("Update procedures", "Implement controls", "Align methods",
              "Adopt framework", "Develop portal"),
  Timeline = c("Month 3", "Month 1", "Month 6", "Month 9", "Month 12")
)

compliance_matrix %>%
  gt() %>%
  tab_header(
    title = "Legal and Standards Compliance Roadmap",
    subtitle = "Achieving full regulatory alignment"
  ) %>%
  tab_style(
    style = cell_fill(color = "#ffcccc"),
    locations = cells_body(
      columns = Current,
      rows = Current %in% c("Non-compliant", "No")
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "#c3e6cb"),
    locations = cells_body(columns = After)
  )
```

---

# Slide 46: Stakeholder Communication Plan

```{r communication, echo=FALSE}
comm_plan <- tibble(
  Stakeholder = c("Minister", "Senior Management", "Technical Staff",
                  "Field Teams", "Data Users", "Public"),
  Frequency = c("Weekly", "Bi-weekly", "Weekly", "Daily", "Monthly", "Quarterly"),
  Format = c("Dashboard", "Report", "Technical brief", "WhatsApp", "Newsletter", "Website"),
  Key_Messages = c("Progress, risks", "Milestones, issues", "Methods, changes",
                   "Instructions, support", "Improvements, access", "Trust, value")
)

comm_plan %>%
  gt() %>%
  tab_header(
    title = "Structured Communication Framework",
    subtitle = "Keeping everyone informed and engaged"
  ) %>%
  tab_style(
    style = cell_fill(color = "#e8f4f8"),
    locations = cells_body(
      columns = Frequency,
      rows = Frequency %in% c("Weekly", "Daily")
    )
  )
```

---

# Slide 47: Lessons from Failed Attempts

```{r lessons, echo=FALSE}
failures <- tibble(
  Country = paste("Country", c("X", "Y", "Z")),
  Year = c(2018, 2020, 2022),
  Investment = c("$1.2M", "$800K", "$1.5M"),
  Failure_Reason = c("No change management", "Technology without training",
                      "Ignored field reality"),
  Our_Mitigation = c("ADKAR framework", "Training-first approach",
                      "Field team involvement")
)

failures %>%
  gt() %>%
  tab_header(
    title = "Learning from Regional Failures",
    subtitle = "Why others failed and how we'll succeed"
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_body(columns = Our_Mitigation)
  )
```

---

# Slide 48: The Friday Morning Decision

## 8:45 AM - Final Preparation

```{r final-prep, echo=FALSE}
decision_factors <- tibble(
  Factor = c("Technical Merit", "Cost-Effectiveness", "Feasibility",
             "Risk Level", "Sustainability", "Impact"),
  Score = c(9, 8, 8, 3, 9, 10),  # Low risk is good (3/10)
  Weight = c(20, 20, 15, 10, 20, 15)
) %>%
  mutate(
    Weighted_Score = (Score * Weight) / 10
  )

total <- sum(decision_factors$Weighted_Score)

ggplot(decision_factors, aes(x = reorder(Factor, Weighted_Score), 
                             y = Weighted_Score)) +
  geom_col(fill = sadc_colors[5]) +
  geom_text(aes(label = sprintf("%.1f", Weighted_Score)), 
            hjust = -0.2, size = 4) +
  coord_flip() +
  labs(title = sprintf("Decision Score: %.0f/100", total),
       subtitle = "Comprehensive assessment supports investment",
       x = "", y = "Weighted Score") +
  theme_minimal(base_size = 14)
```

---

# Slide 49: The Closing Argument

## Why This, Why Now, Why Us

```{r closing, echo=TRUE}
closing_argument <- function() {
  cat("Distinguished Ministers,\n\n")
  
  cat("WHY THIS APPROACH:\n")
  cat("â€¢ Proven internationally (42 countries)\n")
  cat("â€¢ Addresses all our critical gaps\n")
  cat("â€¢ Builds lasting capacity\n\n")
  
  cat("WHY NOW:\n")
  cat("â€¢ SDG reporting requirements (2025)\n")
  cat("â€¢ Donor confidence at risk\n")
  cat("â€¢ Policy decisions need good data\n\n")
  
  cat("WHY OUR TEAM:\n")
  cat("â€¢ We know our context\n")
  cat("â€¢ We've learned from failures\n")
  cat("â€¢ We're committed to excellence\n\n")
  
  cat("The question isn't whether we can afford to do this.\n")
  cat("It's whether we can afford NOT to.\n\n")
  
  cat("Thank you for your consideration.\n")
  cat("Questions?")
}

closing_argument()
```

---

class: inverse, center, middle

# Module 1 Complete
## Ready for Ministerial Presentation

### âœ… Evidence-based approach
### âœ… Clear ROI demonstration  
### âœ… Implementation roadmap
### âœ… Risk mitigation strategy
### âœ… Stakeholder alignment
# MODULE 2: ADVANCED INTEGRATION TECHNIQUES
## Friday 9:00 AM - The Technical Deep Dive
### Slides 51-100

---

# Slide 51: The Minister's First Question

## 9:00 AM - Presentation Begins

**Minister:** "Harry, before you start - can you prove this actually works?"

**Harry:** "Absolutely, Minister. Let me show you our pilot results..."

```{r pilot-results, echo=FALSE}
pilot_comparison <- tibble(
  Metric = c("Response Rate", "Cost per HH", "Data Quality", "Timeline", "Coverage"),
  Traditional = c(65, 85, 60, 120, 78),
  Integrated_Approach = c(84, 42, 92, 45, 95),
  Improvement = c("+29%", "-51%", "+53%", "-63%", "+22%")
)

pilot_comparison %>%
  gt() %>%
  tab_header(
    title = "Pilot Survey Results: 500 Households",
    subtitle = "January 2025 Comparative Test"
  ) %>%
  tab_style(
    style = cell_fill(color = "#d4edda"),
    locations = cells_body(columns = Improvement)
  )
```

---

# Slide 52: Multi-Frame Integration Architecture

```{r multiframe, echo=TRUE}
# Advanced multi-frame integration system
integrate_frames <- function(census_frame, admin_frame, 
                            satellite_frame, mobile_frame) {
  
  # Step 1: Standardize identifiers
  standardize <- function(frame) {
    frame %>%
      mutate(
        standard_id = paste0(
          substr(province, 1, 2),
          sprintf("%04d", ea_code),
          sprintf("%05d", household_num)
        )
      )
  }
  
  # Step 2: Deduplicate using Fellegi-Sunter
  match_probability <- function(frame1, frame2) {
    # Implement record linkage algorithm
    matches <- recordLinkage(
      frame1, frame2,
      blockfld = c("province", "district"),
      strcmp = c("head_name", "address"),
      strcmpfun = jarowinkler
    )
    return(matches)
  }
  
  # Step 3: Create master frame with quality scores
  master_frame <- list(
    census = list(data = census_frame, quality = 0.7, age_years = 3),
    admin = list(data = admin_frame, quality = 0.9, age_years = 0.5),
    satellite = list(data = satellite_frame, quality = 0.8, age_years = 0),
    mobile = list(data = mobile_frame, quality = 0.6, age_years = 0)
  )
  
  return(master_frame)
}

# Display structure
cat("Multi-Frame Integration Components:\n")
cat("1. Census: Traditional backbone\n")
cat("2. Administrative: Real-time updates\n")
cat("3. Satellite: Coverage verification\n")
cat("4. Mobile: Rapid enumeration\n")
```

---

# Slide 53: Machine Learning for Non-Response

```{r ml-nonresponse, echo=FALSE}
# ML model performance comparison
ml_models <- tibble(
  Model = c("Logistic Regression", "Random Forest", "XGBoost", 
            "Neural Network", "Ensemble"),
  Accuracy = c(0.72, 0.85, 0.88, 0.83, 0.91),
  AUC = c(0.76, 0.89, 0.92, 0.87, 0.94),
  Implementation = c("Simple", "Moderate", "Complex", "Complex", "Very Complex"),
  Training_Time = c("5 min", "20 min", "45 min", "2 hours", "3 hours")
)

ggplot(ml_models, aes(x = Accuracy, y = AUC)) +
  geom_point(size = 5, aes(color = Model)) +
  geom_text(aes(label = Model), vjust = -1, size = 3) +
  geom_vline(xintercept = 0.85, linetype = "dashed", alpha = 0.5) +
  geom_hline(yintercept = 0.90, linetype = "dashed", alpha = 0.5) +
  scale_color_manual(values = sadc_colors) +
  labs(title = "Machine Learning Models for Response Propensity",
       subtitle = "Selecting optimal complexity-performance trade-off",
       x = "Accuracy", y = "Area Under Curve (AUC)") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none")
```

---

# Slide 54: Real-Time Quality Monitoring System

```{r monitoring-system, echo=TRUE}
# Real-time quality monitoring dashboard
monitor_quality <- function(stream_data) {
  
  # Define quality thresholds
  thresholds <- list(
    response_rate = 0.75,
    interview_duration = c(20, 90),  # minutes
    completeness = 0.95,
    consistency = 0.98,
    gps_accuracy = 50  # meters
  )
  
  # Real-time checks
  alerts <- character()
  
  # Check 1: Response rate
  current_rr <- mean(stream_data$completed)
  if(current_rr < thresholds$response_rate) {
    alerts <- c(alerts, sprintf("âš ï¸ Response rate: %.1f%%", current_rr * 100))
  }
  
  # Check 2: Interview duration outliers
  duration_outliers <- stream_data$duration < thresholds$interview_duration[1] |
                       stream_data$duration > thresholds$interview_duration[2]
  if(mean(duration_outliers) > 0.05) {
    alerts <- c(alerts, "âš ï¸ Unusual interview durations detected")
  }
  
  # Check 3: GPS verification
  gps_errors <- stream_data$gps_accuracy > thresholds$gps_accuracy
  if(mean(gps_errors, na.rm = TRUE) > 0.1) {
    alerts <- c(alerts, "âš ï¸ GPS accuracy below threshold")
  }
  
  # Display status
  if(length(alerts) == 0) {
    cat("âœ… All quality indicators normal\n")
  } else {
    cat("QUALITY ALERTS:\n")
    for(alert in alerts) cat(alert, "\n")
  }
  
  return(list(status = length(alerts) == 0, alerts = alerts))
}

# Simulate monitoring
test_stream <- data.frame(
  completed = rbinom(100, 1, 0.72),
  duration = rnorm(100, 45, 20),
  gps_accuracy = rexp(100, 1/30)
)

monitor_quality(test_stream)
```

---

# Slide 55: Adaptive Sampling Algorithm

```{r adaptive-sampling, echo=TRUE}
# Adaptive sampling based on variance estimates
adaptive_sample <- function(initial_data, target_cv = 0.05) {
  
  # Calculate current precision
  current_stats <- initial_data %>%
    group_by(stratum) %>%
    summarise(
      n = n(),
      mean = mean(outcome, na.rm = TRUE),
      sd = sd(outcome, na.rm = TRUE),
      cv = sd / mean
    )
  
  # Neyman allocation for additional sample
  optimal_allocation <- function(stats, additional_n) {
    stats %>%
      mutate(
        nh_optimal = additional_n * (N * sd) / sum(N * sd),
        nh_current = n,
        nh_needed = pmax(0, nh_optimal - nh_current)
      )
  }
  
  # Calculate additional sample needed
  total_additional <- 0
  
  for(i in 1:nrow(current_stats)) {
    if(current_stats$cv[i] > target_cv) {
      # Use formula for required sample size
      n_required <- (1.96 * current_stats$sd[i] / 
                    (target_cv * current_stats$mean[i]))^2
      
      additional <- max(0, n_required - current_stats$n[i])
      total_additional <- total_additional + additional
      
      cat(sprintf("Stratum %d: Add %d units (CV: %.3f -> %.3f)\n",
                  i, round(additional), 
                  current_stats$cv[i], target_cv))
    }
  }
  
  cat(sprintf("\nTotal additional sample needed: %d\n", round(total_additional)))
  
  return(total_additional)
}

# Test with simulated data
test_data <- data.frame(
  stratum = rep(1:4, each = 50),
  outcome = c(rnorm(50, 100, 30), rnorm(50, 80, 25),
             rnorm(50, 120, 40), rnorm(50, 90, 20)),
  N = rep(c(10000, 8000, 12000, 6000), each = 50)
)

adaptive_sample(test_data)
```

---

# Slide 56: Automated Small Area Estimation

```{r sae-automated, echo=FALSE}
# Small area estimation results
sae_results <- expand.grid(
  Province = paste("Province", 1:4),
  District = paste("District", 1:3)
) %>%
  mutate(
    Direct_Estimate = runif(12, 25, 45),
    Direct_CV = runif(12, 0.15, 0.35),
    SAE_Estimate = Direct_Estimate + rnorm(12, 0, 2),
    SAE_CV = Direct_CV * runif(12, 0.3, 0.5),
    Sample_Size = sample(20:100, 12)
  )

sae_results %>%
  mutate(
    Precision_Gain = sprintf("%.0f%%", (1 - SAE_CV/Direct_CV) * 100)
  ) %>%
  select(Province, District, Sample_Size, Direct_CV, SAE_CV, Precision_Gain) %>%
  gt() %>%
  tab_header(
    title = "Small Area Estimation Performance",
    subtitle = "Improving precision for policy-relevant domains"
  ) %>%
  data_color(
    columns = SAE_CV,
    colors = scales::col_numeric(
      palette = c("#d4edda", "#fff3cd", "#ffcccc"),
      domain = c(0.05, 0.20)
    )
  )
```

---

# Slide 57: Blockchain for Data Integrity

```{r blockchain, echo=TRUE}
# Blockchain implementation for survey data integrity
create_blockchain <- function(survey_batch) {
  
  # Create genesis block
  genesis_block <- list(
    index = 0,
    timestamp = Sys.time(),
    data = "Genesis Block",
    previous_hash = "0",
    hash = NULL
  )
  
  # Hash function
  calculate_hash <- function(block) {
    block_string <- paste(
      block$index,
      block$timestamp,
      block$data,
      block$previous_hash,
      collapse = ""
    )
    digest::digest(block_string, algo = "sha256")
  }
  
  genesis_block$hash <- calculate_hash(genesis_block)
  
  # Add survey data blocks
  blockchain <- list(genesis_block)
  
  for(i in 1:nrow(survey_batch)) {
    new_block <- list(
      index = i,
      timestamp = Sys.time(),
      data = list(
        household_id = survey_batch$household_id[i],
        interviewer_id = survey_batch$interviewer_id[i],
        responses_hash = digest::digest(survey_batch[i,], algo = "md5")
      ),
      previous_hash = blockchain[[i]]$hash
    )
    new_block$hash <- calculate_hash(new_block)
    blockchain[[i + 1]] <- new_block
  }
  
  cat(sprintf("Blockchain created with %d blocks\n", length(blockchain)))
  cat("Data integrity guaranteed through cryptographic linking\n")
  cat(sprintf("Chain hash: %s\n", blockchain[[length(blockchain)]]$hash))
  
  return(blockchain)
}

# Test implementation
test_batch <- data.frame(
  household_id = paste0("HH", 1:5),
  interviewer_id = paste0("INT", sample(1:3, 5, replace = TRUE)),
  response = sample(c("Complete", "Partial"), 5, replace = TRUE)
)

chain <- create_blockchain(test_batch)
```

---

# Slide 58: API Development for Data Access

```{r api-design, echo=TRUE}
# RESTful API design for survey data
design_api <- function() {
  
  endpoints <- list(
    # Metadata endpoints
    "/api/v1/surveys" = "GET: List all surveys",
    "/api/v1/surveys/{id}" = "GET: Survey details",
    "/api/v1/surveys/{id}/metadata" = "GET: Full metadata",
    
    # Data endpoints
    "/api/v1/data/aggregate" = "GET: Aggregated statistics",
    "/api/v1/data/microdata" = "GET: Anonymized microdata (auth required)",
    "/api/v1/data/indicators/{indicator}" = "GET: Specific indicator",
    
    # Quality endpoints
    "/api/v1/quality/response-rates" = "GET: Response rate by domain",
    "/api/v1/quality/design-effects" = "GET: Design effects",
    "/api/v1/quality/coverage" = "GET: Frame coverage statistics",
    
    # Real-time endpoints
    "/api/v1/realtime/progress" = "GET: Current field progress",
    "/api/v1/realtime/alerts" = "GET: Active quality alerts"
  )
  
  cat("SURVEY DATA API SPECIFICATION\n")
  cat("============================\n\n")
  
  for(endpoint in names(endpoints)) {
    cat(sprintf("%-40s : %s\n", endpoint, endpoints[[endpoint]]))
  }
  
  cat("\nAuthentication: OAuth 2.0\n")
  cat("Rate limiting: 1000 requests/hour\n")
  cat("Format: JSON (default), CSV, XML\n")
  
  return(endpoints)
}

api_spec <- design_api()
```

---

# Slide 59: Automated Report Generation Pipeline

```{r report-pipeline, echo=FALSE}
pipeline_stages <- tibble(
  Stage = c("Data Collection", "Validation", "Processing", 
            "Analysis", "Visualization", "Report Generation", "Publication"),
  Tool = c("Survey Solutions", "R + Python", "PostgreSQL + R",
           "R Survey Package", "ggplot2 + Plotly", "R Markdown", "Shiny Server"),
  Time = c("Continuous", "Real-time", "Hourly", "Daily", 
           "On-demand", "Weekly", "Monthly"),
  Automation = c("Full", "Full", "Full", "Full", "Partial", "Full", "Full"),
  Manual_Review = c("No", "Exceptions only", "No", "Key findings", 
                    "Yes", "Executive summary", "Final approval")
)

pipeline_stages %>%
  gt() %>%
  tab_header(
    title = "Automated Reporting Pipeline",
    subtitle = "From field to publication in 48 hours"
  ) %>%
  data_color(
    columns = Automation,
    colors = scales::col_factor(
      palette = c("Full" = "#d4edda", "Partial" = "#fff3cd"),
      domain = c("Full", "Partial")
    )
  )
```

---

# Slide 60: Variance Estimation Comparison

```{r variance-comparison, echo=TRUE}
# Compare variance estimation methods
compare_variance_methods <- function(design, statistic) {
  
  methods <- list()
  
  # Method 1: Linearization
  start_time <- Sys.time()
  lin_result <- svymean(as.formula(paste("~", statistic)), 
                        design, deff = TRUE)
  methods$linearization <- list(
    estimate = coef(lin_result),
    se = SE(lin_result),
    time = Sys.time() - start_time,
    deff = deff(lin_result)
  )
  
  # Method 2: Jackknife
  start_time <- Sys.time()
  jk_design <- as.svrepdesign(design, type = "JKn")
  jk_result <- svymean(as.formula(paste("~", statistic)), jk_design)
  methods$jackknife <- list(
    estimate = coef(jk_result),
    se = SE(jk_result),
    time = Sys.time() - start_time
  )
  
  # Method 3: Bootstrap
  start_time <- Sys.time()
  boot_design <- as.svrepdesign(design, type = "bootstrap", replicates = 100)
  boot_result <- svymean(as.formula(paste("~", statistic)), boot_design)
  methods$bootstrap <- list(
    estimate = coef(boot_result),
    se = SE(boot_result),
    time = Sys.time() - start_time
  )
  
  # Compare results
  comparison <- data.frame(
    Method = names(methods),
    Estimate = sapply(methods, function(x) x$estimate),
    SE = sapply(methods, function(x) x$se),
    CV = sapply(methods, function(x) x$se / x$estimate),
    Time = sapply(methods, function(x) x$time)
  )
  
  print(comparison)
  return(methods)
}

# Note: Function structure shown, actual execution requires survey design object
cat("Variance estimation methods ready for comparison\n")
cat("All three methods should give similar results\n")
cat("Choose based on computational resources and requirements\n")
```

---

# Slide 61: Paradata Analysis System

```{r paradata, echo=FALSE}
paradata_metrics <- tibble(
  Interviewer = paste("INT", LETTERS[1:8]),
  Avg_Duration = round(rnorm(8, 45, 10)),
  Response_Rate = round(runif(8, 0.7, 0.95), 2),
  GPS_Compliance = round(runif(8, 0.85, 1.0), 2),
  Time_Between = round(rnorm(8, 120, 30)),  # minutes
  Quality_Score = round(runif(8, 75, 95))
)

# Identify outliers
paradata_metrics <- paradata_metrics %>%
  mutate(
    Flag = case_when(
      Avg_Duration < 30 ~ "âš ï¸ Too fast",
      Avg_Duration > 60 ~ "âš ï¸ Too slow",
      Response_Rate < 0.75 ~ "âš ï¸ Low response",
      GPS_Compliance < 0.90 ~ "âš ï¸ GPS issues",
      TRUE ~ "âœ…"
    )
  )

paradata_metrics %>%
  gt() %>%
  tab_header(
    title = "Interviewer Performance Dashboard",
    subtitle = "Paradata-driven quality monitoring"
  ) %>%
  data_color(
    columns = Quality_Score,
    colors = scales::col_numeric(
      palette = c("#ffcccc", "#fff3cd", "#d4edda"),
      domain = c(70, 95)
    )
  )
```

---

# Slide 62: Disclosure Control Implementation

```{r disclosure-control, echo=TRUE}
# Statistical disclosure control for public use files
apply_disclosure_control <- function(microdata) {
  
  controlled_data <- microdata
  
  # 1. Remove direct identifiers
  direct_identifiers <- c("name", "national_id", "phone", "email", "gps_exact")
  controlled_data <- controlled_data %>%
    select(-any_of(direct_identifiers))
  
  # 2. Top/bottom coding for continuous variables
  top_bottom_code <- function(x, bottom_pct = 0.01, top_pct = 0.99) {
    thresholds <- quantile(x, c(bottom_pct, top_pct), na.rm = TRUE)
    x[x < thresholds[1]] <- thresholds[1]
    x[x > thresholds[2]] <- thresholds[2]
    return(x)
  }
  
  controlled_data$income <- top_bottom_code(controlled_data$income)
  controlled_data$age <- top_bottom_code(controlled_data$age, 0, 0.98)
  
  # 3. Geographic aggregation
  controlled_data <- controlled_data %>%
    mutate(
      district = ifelse(n() < 50, "Grouped", district),
      .by = district
    )
  
  # 4. Rounding for sampling weights
  controlled_data$weight <- round(controlled_data$weight, 1)
  
  # 5. Suppress small cells
  cross_tab <- table(controlled_data$urban_rural, controlled_data$education)
  small_cells <- which(cross_tab < 3 & cross_tab > 0, arr.ind = TRUE)
  
  if(nrow(small_cells) > 0) {
    cat(sprintf("Warning: %d small cells require suppression\n", nrow(small_cells)))
  }
  
  # 6. Add noise to sensitive variables (differential privacy)
  controlled_data$income <- controlled_data$income + 
                            rnorm(nrow(controlled_data), 0, 100)
  
  cat("Disclosure control applied:\n")
  cat("âœ“ Direct identifiers removed\n")
  cat("âœ“ Top/bottom coding applied\n")
  cat("âœ“ Geographic aggregation completed\n")
  cat("âœ“ Weights rounded\n")
  cat("âœ“ Small cells identified\n")
  cat("âœ“ Noise added for differential privacy\n")
  
  return(controlled_data)
}

# Example structure
cat("\nPublic use file ready for distribution\n")
```

---

# Slide 63: Seasonal Adjustment Framework

```{r seasonal-adjustment, echo=FALSE}
# Generate seasonal adjustment demonstration data with proper factor recycling
seasonal_data <- expand.grid(
  Quarter = paste0("Q", 1:4),
  Year = 2022:2024
) %>%
  mutate(
    # Generate raw values with seasonal pattern using trigonometric function
    Raw_Value = 28 + sin(as.numeric(factor(Quarter)) * pi/2) * 5 + 
                rnorm(n(), 0, 2),
    # Properly recycle seasonal factors across all 12 observations
    # rep() ensures the 4-element vector repeats for each year
    Seasonal_Factor = rep(c(1.05, 0.95, 0.98, 1.02), length.out = n()),
    # Calculate seasonally adjusted values through division
    Adjusted_Value = Raw_Value / Seasonal_Factor,
    # Compute linear trend component based on sequential time periods
    Trend = 28 + (seq_len(n()) - 6) * 0.3
  )

# Create visualization comparing raw, adjusted, and trend series
seasonal_data %>%
  pivot_longer(cols = c(Raw_Value, Adjusted_Value, Trend), 
               names_to = "Series", values_to = "Value") %>%
  mutate(
    # Create properly formatted period labels for x-axis
    Period = factor(paste(Year, Quarter), 
                   levels = unique(paste(seasonal_data$Year, 
                                       seasonal_data$Quarter)))
  ) %>%
  ggplot(aes(x = Period, y = Value, 
             color = Series, group = Series)) +
  geom_line(linewidth = 1.2) +  # Note: use linewidth instead of deprecated size
  geom_point(size = 2) +
  scale_color_manual(values = sadc_colors[c(6, 5, 2)],
                     labels = c("Raw Values", "Seasonally Adjusted", 
                               "Trend Component")) +
  labs(title = "Seasonal Adjustment for Quarterly Surveys",
       subtitle = "X-13ARIMA-SEATS methodology applied",
       x = "Period", y = "Indicator Value (%)") +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "bottom",
        legend.title = element_blank())
```

---

# Slide 64: Meta-Analysis Framework

```{r meta-analysis, echo=TRUE}
# Meta-analysis across multiple surveys
conduct_meta_analysis <- function(survey_list) {
  
  # Extract estimates and variances from each survey
  meta_data <- data.frame(
    survey = names(survey_list),
    estimate = sapply(survey_list, function(x) x$estimate),
    variance = sapply(survey_list, function(x) x$se^2),
    n = sapply(survey_list, function(x) x$n)
  )
  
  # Fixed effects meta-analysis
  weights <- 1 / meta_data$variance
  fixed_effect <- sum(meta_data$estimate * weights) / sum(weights)
  fixed_se <- sqrt(1 / sum(weights))
  
  # Random effects (DerSimonian-Laird)
  Q <- sum(weights * (meta_data$estimate - fixed_effect)^2)
  df <- nrow(meta_data) - 1
  tau_squared <- max(0, (Q - df) / (sum(weights) - sum(weights^2)/sum(weights)))
  
  re_weights <- 1 / (meta_data$variance + tau_squared)
  random_effect <- sum(meta_data$estimate * re_weights) / sum(re_weights)
  random_se <- sqrt(1 / sum(re_weights))
  
  # Forest plot data
  forest_data <- meta_data %>%
    mutate(
      lower_ci = estimate - 1.96 * sqrt(variance),
      upper_ci = estimate + 1.96 * sqrt(variance),
      weight_pct = weights / sum(weights) * 100
    )
  
  cat("META-ANALYSIS RESULTS\n")
  cat("====================\n")
  cat(sprintf("Fixed Effect: %.3f (SE: %.3f)\n", fixed_effect, fixed_se))
  cat(sprintf("Random Effect: %.3f (SE: %.3f)\n", random_effect, random_se))
  cat(sprintf("Heterogeneity (IÂ²): %.1f%%\n", 
              max(0, (Q - df) / Q * 100)))
  cat(sprintf("TauÂ²: %.4f\n", tau_squared))
  
  return(list(
    fixed = list(estimate = fixed_effect, se = fixed_se),
    random = list(estimate = random_effect, se = random_se),
    heterogeneity = list(Q = Q, I_squared = max(0, (Q - df) / Q * 100)),
    forest_data = forest_data
  ))
}

# Example with simulated surveys
surveys <- list(
  "Survey_2023" = list(estimate = 0.342, se = 0.015, n = 5000),
  "Survey_2024" = list(estimate = 0.358, se = 0.018, n = 4500),
  "Survey_2025" = list(estimate = 0.351, se = 0.012, n = 6000)
)

meta_results <- conduct_meta_analysis(surveys)
```

---

# Slide 65: Network Sampling for Hidden Populations

```{r network-sampling, echo=TRUE}
# Respondent-driven sampling implementation
implement_rds <- function(seed_sample, network_data, waves = 5) {
  
  # Initialize with seeds
  sample <- seed_sample
  wave_number <- rep(0, nrow(seed_sample))
  
  for(wave in 1:waves) {
    # Get referrals from current wave
    current_wave <- sample[wave_number == wave - 1, ]
    
    referrals <- data.frame()
    for(i in 1:nrow(current_wave)) {
      # Each person refers up to 3 contacts
      n_referrals <- min(3, rpois(1, lambda = 2))
      
      if(n_referrals > 0) {
        new_referrals <- network_data %>%
          filter(referred_by == current_wave$id[i]) %>%
          sample_n(min(n_referrals, n())) %>%
          mutate(wave = wave)
        
        referrals <- bind_rows(referrals, new_referrals)
      }
    }
    
    # Add to sample
    sample <- bind_rows(sample, referrals)
    wave_number <- c(wave_number, rep(wave, nrow(referrals)))
    
    cat(sprintf("Wave %d: %d new respondents\n", wave, nrow(referrals)))
  }
  
  # Calculate RDS weights (Volz-Heckathorn)
  sample <- sample %>%
    mutate(
      degree = sample(3:20, n(), replace = TRUE),  # Network degree
      recruitment_prob = 1 / degree,
      rds_weight = 1 / (recruitment_prob * n())
    )
  
  cat(sprintf("\nTotal sample: %d\n", nrow(sample)))
  cat(sprintf("Effective sample size: %.0f\n", 
              sum(sample$rds_weight)^2 / sum(sample$rds_weight^2)))
  
  return(sample)
}

# Simulate RDS
seeds <- data.frame(id = 1:5, characteristic = "seed")
network <- data.frame(
  id = 6:500,
  referred_by = sample(1:500, 495, replace = TRUE),
  characteristic = sample(c("A", "B", "C"), 495, replace = TRUE)
)

rds_sample <- implement_rds(seeds, network)
```

---

# Slide 66: Calibration Diagnostics Dashboard

```{r calibration-diagnostics, echo=FALSE}
calib_diagnostics <- tibble(
  Variable = c("Age 18-34", "Age 35-54", "Age 55+", 
               "Urban", "Rural", "Male", "Female"),
  Survey_Raw = c(32, 38, 30, 42, 58, 48, 52),
  Population = c(35, 40, 25, 40, 60, 49, 51),
  Survey_Calibrated = c(35, 40, 25, 40, 60, 49, 51),
  Weight_Ratio = c(1.09, 1.05, 0.83, 0.95, 1.03, 1.02, 0.98)
) %>%
  mutate(
    Convergence = ifelse(abs(Survey_Calibrated - Population) < 0.1, "âœ…", "âš ï¸")
  )

calib_diagnostics %>%
  gt() %>%
  tab_header(
    title = "GREG Calibration Convergence Report",
    subtitle = "All marginal totals successfully matched"
  ) %>%
  fmt_number(columns = c(Survey_Raw, Population, Survey_Calibrated),
             decimals = 1) %>%
  fmt_number(columns = Weight_Ratio, decimals = 3) %>%
  data_color(
    columns = Weight_Ratio,
    colors = scales::col_numeric(
      palette = c("#e6f3ff", "#ffffff", "#ffe6e6"),
      domain = c(0.8, 1.2)
    )
  )
```

---

# Slide 67: Cost Optimization Model

```{r cost-optimization, echo=TRUE}
# Optimize survey costs across multiple constraints using linear programming
optimize_survey_costs <- function(budget, requirements) {
  
  library(lpSolve)
  
  # Define cost components as a list for $ operator access
  costs <- list(
    psu_travel = 150,      # Fixed cost per PSU visit
    ssu_interview = 25,    # Cost per secondary sampling unit interview
    f2f_mode = 30,         # Face-to-face interview cost
    phone_mode = 10,       # Telephone interview cost
    web_mode = 5           # Web-based interview cost
  )
  
  # Decision variables represent allocation choices:
  # x1 = number of PSUs to sample
  # x2 = total interviews (implicitly 20 per PSU in this model)
  # x3 = proportion using face-to-face mode
  
  # Objective function coefficients: minimize total survey cost
  obj <- c(costs$psu_travel, 
           costs$ssu_interview, 
           costs$f2f_mode)
  
  # Constraint matrix construction with proper dimensions
  con.mat <- matrix(c(
    costs$psu_travel, costs$ssu_interview * 20, costs$f2f_mode * 20,  # Budget constraint
    0, 20, 0,                                                          # Minimum sample size
    1, 0, 0                                                           # Minimum PSUs
  ), nrow = 3, byrow = TRUE)
  
  # Constraint directions and right-hand side values
  con.dir <- c("<=", ">=", ">=")
  con.rhs <- c(budget, 
                requirements$min_n, 
                requirements$min_psu)
  
  # Solve the linear program with all.int=TRUE for integer solutions
  solution <- lp(direction = "min", 
                 objective.in = obj, 
                 const.mat = con.mat, 
                 const.dir = con.dir, 
                 const.rhs = con.rhs,
                 all.int = TRUE)
  
  # Calculate derived statistics from optimal solution
  n_psu_optimal <- round(solution$solution[1])
  interviews_per_psu <- 20
  total_sample <- n_psu_optimal * interviews_per_psu
  
  # Generate formatted output report with proper number formatting
  cat("OPTIMAL SURVEY DESIGN\n")
  cat("====================\n")
  cat(sprintf("Optimization Status: %s\n", 
              ifelse(solution$status == 0, "Success", "Failed")))
  cat(sprintf("Number of PSUs: %d\n", n_psu_optimal))
  cat(sprintf("Interviews per PSU: %d\n", interviews_per_psu))
  cat(sprintf("Total sample size: %d\n", total_sample))
  
  # Format currency with thousand separators using format()
  cat(sprintf("Total cost: $%s\n", 
              format(solution$objval, big.mark = ",", nsmall = 2, scientific = FALSE)))
  
  # Calculate and format cost per interview
  cost_per_interview <- ifelse(total_sample > 0, solution$objval / total_sample, NA)
  cat(sprintf("Cost per interview: $%.2f\n", cost_per_interview))
  
  # Format budget utilization percentage
  cat(sprintf("Budget utilization: %.1f%%\n", 
              (solution$objval / budget) * 100))
  
  # Return comprehensive results object
  return(list(
    solution = solution,
    design = list(
      n_psu = n_psu_optimal,
      n_total = total_sample,
      cost_total = solution$objval,
      cost_per_unit = cost_per_interview
    ),
    constraints_met = solution$status == 0
  ))
}

# Execute optimization with specified requirements
requirements <- list(min_n = 3000, min_psu = 150)
optimal <- optimize_survey_costs(budget = 100000, requirements = requirements)

# Additional validation: verify constraint satisfaction
if (optimal$constraints_met) {
  cat("\nConstraint Verification:\n")
  cat(sprintf("Sample size requirement (>=%d): %s\n", 
              requirements$min_n, 
              ifelse(optimal$design$n_total >= requirements$min_n, "MET", "FAILED")))
  cat(sprintf("PSU requirement (>=%d): %s\n", 
              requirements$min_psu,
              ifelse(optimal$design$n_psu >= requirements$min_psu, "MET", "FAILED")))
  
  # Display additional optimization metrics with proper formatting
  cat("\nEfficiency Metrics:\n")
  cat(sprintf("Cost efficiency: $%s per PSU\n", 
              format(optimal$design$cost_total / optimal$design$n_psu, 
                     big.mark = ",", nsmall = 2, scientific = FALSE)))
  cat(sprintf("Sample efficiency: %.2f interviews per $1000\n", 
              (optimal$design$n_total / optimal$design$cost_total) * 1000))
}
```

---

# Slide 68: Missing Data Diagnostics

```{r missing-diagnostics, echo=FALSE}
missing_analysis <- tibble(
  Variable = c("Income", "Education", "Health_Status", "Employment",
               "Housing", "Assets", "Social_Grants", "Food_Security"),
  Missing_Pct = c(8.2, 1.3, 3.5, 2.1, 0.8, 5.6, 4.2, 6.8),
  Pattern = c("MAR", "MCAR", "MAR", "MCAR", "MCAR", "MNAR", "MAR", "MAR"),
  Correlation_with_Response = c(0.42, 0.08, 0.31, 0.11, 0.05, 0.58, 0.35, 0.38),
  Imputation_Method = c("PMM", "Mode", "PMM", "Logistic", 
                        "Mode", "Selection", "PMM", "PMM")
)

missing_analysis %>%
  mutate(
    Action = case_when(
      Missing_Pct < 2 ~ "No action needed",
      Missing_Pct < 5 ~ "Standard imputation",
      Missing_Pct < 10 & Pattern != "MNAR" ~ "Multiple imputation",
      TRUE ~ "Sensitivity analysis required"
    )
  ) %>%
  gt() %>%
  tab_header(
    title = "Missing Data Assessment Report",
    subtitle = "Tailored imputation strategy by variable"
  ) %>%
  fmt_number(columns = c(Missing_Pct, Correlation_with_Response),
             decimals = 1) %>%
  data_color(
    columns = Missing_Pct,
    colors = scales::col_numeric(
      palette = c("#d4edda", "#fff3cd", "#ffcccc"),
      domain = c(0, 10)
    )
  )
```

---

# Slide 69: Composite Indicator Construction

```{r composite-indicators, echo=TRUE}
# Build multidimensional poverty index (MPI)
construct_mpi <- function(household_data) {
  
  # Define dimensions and indicators
  dimensions <- list(
    education = list(
      years_schooling = function(x) x$adult_education < 6,
      child_enrollment = function(x) x$children_not_enrolled > 0,
      weight = 1/6
    ),
    health = list(
      nutrition = function(x) x$malnutrition == 1,
      child_mortality = function(x) x$child_death == 1,
      weight = 1/6
    ),
    living_standards = list(
      electricity = function(x) x$has_electricity == 0,
      drinking_water = function(x) x$safe_water == 0,
      sanitation = function(x) x$improved_sanitation == 0,
      flooring = function(x) x$dirt_floor == 1,
      cooking_fuel = function(x) x$solid_fuel == 1,
      assets = function(x) x$asset_count < 2,
      weight = 1/18
    )
  )
  
  # Calculate deprivation score for each household
  household_data <- household_data %>%
    mutate(
      deprivation_score = 0,
      n_deprivations = 0
    )
  
  for(dim in names(dimensions)) {
    for(ind in names(dimensions[[dim]])) {
      if(ind != "weight") {
        indicator_weight <- dimensions[[dim]]$weight
        household_data <- household_data %>%
          mutate(
            deprivation_score = deprivation_score + 
              indicator_weight * dimensions[[dim]][[ind]](.)
          )
      }
    }
  }
  
  # Identify poor (deprivation >= 33.3%)
  household_data <- household_data %>%
    mutate(
      mpi_poor = deprivation_score >= 0.333,
      severely_poor = deprivation_score >= 0.500
    )
  
  # Calculate MPI
  H <- weighted.mean(household_data$mpi_poor, household_data$weight)  # Headcount
  A <- weighted.mean(household_data$deprivation_score[household_data$mpi_poor], 
                    household_data$weight[household_data$mpi_poor])  # Intensity
  
  MPI <- H * A
  
  cat("MULTIDIMENSIONAL POVERTY INDEX\n")
  cat("==============================\n")
  cat(sprintf("MPI Value: %.3f\n", MPI))
  cat(sprintf("Headcount (H): %.1f%%\n", H * 100))
  cat(sprintf("Intensity (A): %.1f%%\n", A * 100))
  cat(sprintf("Severely Poor: %.1f%%\n", 
              weighted.mean(household_data$severely_poor, 
                          household_data$weight) * 100))
  
  return(list(MPI = MPI, H = H, A = A, data = household_data))
}

# Example calculation structure
cat("\nMPI calculation framework ready\n")
cat("Follows Alkire-Foster methodology\n")
```

---

# Slide 70: Geospatial Integration Platform

```{r geospatial, echo=FALSE}
geo_integration <- tibble(
  Data_Layer = c("Census EA Boundaries", "Satellite Imagery", 
                 "Road Network", "Health Facilities", 
                 "Schools", "Markets", "Climate Data"),
  Source = c("NSO", "Sentinel-2", "OpenStreetMap", 
             "Ministry of Health", "Ministry of Education", 
             "Local Government", "Weather Service"),
  Update_Frequency = c("10 years", "Weekly", "Monthly", 
                       "Quarterly", "Annual", "Quarterly", "Daily"),
  Integration_Status = c("Complete", "In Progress", "Complete", 
                         "Pending", "Complete", "Pending", "Testing"),
  Use_Case = c("Sampling frame", "Coverage validation", "Access analysis",
               "Service availability", "Education access", "Economic activity",
               "Seasonal adjustment")
)

geo_integration %>%
  gt() %>%
  tab_header(
    title = "Geospatial Data Integration Platform",
    subtitle = "Enriching surveys with spatial intelligence"
  ) %>%
  data_color(
    columns = Integration_Status,
    colors = scales::col_factor(
      palette = c("Complete" = "#d4edda", 
                  "In Progress" = "#fff3cd",
                  "Pending" = "#ffe6e6",
                  "Testing" = "#e8f4f8"),
      domain = c("Complete", "In Progress", "Pending", "Testing")
    )
  )
```

---

# Slide 71: Time Series Reconciliation

```{r time-series, echo=TRUE}
# Reconcile survey estimates across time
reconcile_time_series <- function(survey_series, benchmark_points) {
  
  # Denton-Cholette benchmarking method
  denton_cholette <- function(series, benchmarks) {
    n <- length(series)
    m <- nrow(benchmarks)
    
    # Create constraint matrix for benchmark quarters
    A <- matrix(0, m, n)
    for(i in 1:m) {
      quarter_months <- ((i-1)*3 + 1):(i*3)
      A[i, quarter_months] <- 1
    }
    
    # Minimize squared differences while preserving movement
    D <- diff(diag(n), differences = 1)
    
    # Quadratic programming solution
    # min (x - series)'W(x - series) + lambda * x'D'Dx
    # subject to Ax = benchmarks
    
    # Simplified solution using proportional adjustment
    adjustment_factors <- benchmarks$value / (A %*% series)
    
    # Distribute adjustment proportionally
    reconciled <- series
    for(i in 1:m) {
      quarter_months <- ((i-1)*3 + 1):(i*3)
      reconciled[quarter_months] <- series[quarter_months] * 
                                   adjustment_factors[i]
    }
    
    return(reconciled)
  }
  
  # Apply reconciliation
  reconciled <- denton_cholette(survey_series$value, benchmark_points)
  
  # Calculate revision statistics
  revisions <- data.frame(
    period = survey_series$period,
    original = survey_series$value,
    reconciled = reconciled,
    revision = reconciled - survey_series$value,
    revision_pct = (reconciled - survey_series$value) / 
                   survey_series$value * 100
  )
  
  cat("TIME SERIES RECONCILIATION\n")
  cat("=========================\n")
  cat(sprintf("Mean revision: %.2f%%\n", mean(abs(revisions$revision_pct))))
  cat(sprintf("Max revision: %.2f%%\n", max(abs(revisions$revision_pct))))
  cat(sprintf("Benchmarks satisfied: %s\n", 
              ifelse(all(abs(A %*% reconciled - benchmark_points$value) < 0.01),
                     "Yes âœ“", "No âœ—")))
  
  return(revisions)
}

# Example structure
survey_monthly <- data.frame(
  period = 1:12,
  value = 25 + sin((1:12) * pi/6) * 3 + rnorm(12, 0, 1)
)

quarterly_benchmarks <- data.frame(
  quarter = 1:4,
  value = c(76, 78, 75, 77)
)

# Note: Actual reconciliation would run here
cat("\nReconciliation framework ready\n")
```

---

# Slide 72: Advanced Weighting Techniques

```{r advanced-weights, echo=FALSE}
weight_methods <- tibble(
  Method = c("Base Design", "Non-response Adjusted", "Raked", 
             "GREG Calibrated", "Trimmed", "Final"),
  Min_Weight = c(12.3, 15.1, 14.8, 14.2, 20.0, 20.0),
  Max_Weight = c(487.2, 612.3, 425.6, 398.4, 300.0, 300.0),
  CV = c(1.82, 2.14, 1.65, 1.43, 1.21, 1.21),
  Effective_n = c(2850, 2420, 3100, 3350, 3580, 3580),
  Loss_Pct = c(0, 0, 0, 0, 2.3, 2.3)
)

weight_methods %>%
  gt() %>%
  tab_header(
    title = "Progressive Weight Refinement",
    subtitle = "Each step improves statistical properties"
  ) %>%
  fmt_number(columns = c(Min_Weight, Max_Weight), decimals = 1) %>%
  fmt_number(columns = CV, decimals = 2) %>%
  fmt_number(columns = Effective_n, decimals = 0) %>%
  fmt_percent(columns = Loss_Pct, scale_values = FALSE, decimals = 1) %>%
  data_color(
    columns = CV,
    colors = scales::col_numeric(
      palette = c("#d4edda", "#fff3cd", "#ffcccc"),
      domain = c(1.0, 2.5),
      reverse = TRUE
    )
  )
```

---

# Slide 73: Documentation Automation System

```{r documentation-auto, echo=TRUE}
# Automated documentation generation
generate_documentation <- function(survey_object) {
  
  doc <- list()
  
  # Section 1: Survey design
  doc$design <- list(
    title = "Survey Design Specification",
    sampling_method = class(survey_object$design)[1],
    stages = ifelse(is.null(survey_object$design$cluster), 1, 2),
    stratification = !is.null(survey_object$design$strata),
    total_strata = length(unique(survey_object$design$strata)),
    sample_size = nrow(survey_object$design$variables),
    population_size = sum(weights(survey_object$design))
  )
  
  # Section 2: Variable dictionary
  doc$variables <- list(
    title = "Variable Dictionary",
    n_variables = ncol(survey_object$design$variables),
    types = table(sapply(survey_object$design$variables, class)),
    missing_summary = colSums(is.na(survey_object$design$variables))
  )
  
  # Section 3: Quality indicators
  doc$quality <- list(
    title = "Quality Indicators",
    response_rate = survey_object$quality$response_rate,
    coverage_rate = survey_object$quality$coverage,
    avg_design_effect = mean(survey_object$deff, na.rm = TRUE),
    weight_cv = sd(weights(survey_object$design)) / 
                mean(weights(survey_object$design))
  )
  
  # Generate markdown report
  cat("# SURVEY DOCUMENTATION\n")
  cat("## Generated:", format(Sys.time()), "\n\n")
  
  for(section in names(doc)) {
    cat("##", doc[[section]]$title, "\n")
    items <- doc[[section]][names(doc[[section]]) != "title"]
    for(item in names(items)) {
      cat("-", item, ":", items[[item]], "\n")
    }
    cat("\n")
  }
  
  # Save to file
  cat("\nDocumentation saved to: survey_documentation.md\n")
  
  return(doc)
}

# Example structure
cat("Documentation automation system configured\n")
cat("Generates complete technical documentation automatically\n")
```

---

# Slide 74: Interviewer Allocation Algorithm

```{r interviewer-allocation, echo=FALSE}
allocation_problem <- tibble(
  Region = paste("Region", LETTERS[1:5]),
  Workload_Hours = c(450, 320, 580, 410, 520),
  Available_Interviewers = c(12, 8, 15, 10, 13),
  Skill_Level = c("High", "Medium", "High", "Low", "Medium"),
  Distance_km = c(50, 120, 30, 200, 80)
) %>%
  mutate(
    Hours_per_Interviewer = round(Workload_Hours / Available_Interviewers),
    Efficiency_Score = case_when(
      Hours_per_Interviewer < 35 ~ "Over-staffed",
      Hours_per_Interviewer > 45 ~ "Under-staffed",
      TRUE ~ "Optimal"
    ),
    Reallocation_Needed = Available_Interviewers - round(Workload_Hours / 40)
  )

allocation_problem %>%
  gt() %>%
  tab_header(
    title = "Interviewer Allocation Optimization",
    subtitle = "Balancing workload across regions"
  ) %>%
  data_color(
    columns = Efficiency_Score,
    colors = scales::col_factor(
      palette = c("Over-staffed" = "#fff3cd",
                  "Optimal" = "#d4edda",
                  "Under-staffed" = "#ffcccc"),
      domain = c("Over-staffed", "Optimal", "Under-staffed")
    )
  )
```

---

# Slide 75: Panel Attrition Analysis

```{r panel-attrition, echo=TRUE}
# Analyze panel attrition patterns
analyze_attrition <- function(panel_data) {
  
  # Track participation across waves
  waves <- paste0("wave_", 1:4)
  
  # Create attrition patterns
  patterns <- panel_data %>%
    mutate(
      pattern = paste0(
        ifelse(wave_1 == 1, "1", "0"),
        ifelse(wave_2 == 1, "1", "0"),
        ifelse(wave_3 == 1, "1", "0"),
        ifelse(wave_4 == 1, "1", "0")
      )
    )
  
  # Classify attrition types
  attrition_types <- patterns %>%
    mutate(
      type = case_when(
        pattern == "1111" ~ "Complete",
        pattern == "1110" ~ "Late attrition",
        pattern == "1100" ~ "Early attrition",
        pattern == "1010" ~ "Intermittent",
        pattern == "1000" ~ "One wave only",
        TRUE ~ "Other pattern"
      )
    )
  
  # Model attrition probability
  attrition_model <- glm(
    dropped_out ~ age + education + urban_rural + income_quintile +
                  interview_quality + distance_to_ea,
    data = panel_data,
    family = binomial()
  )
  
  # Calculate attrition weights
  attrition_prob <- predict(attrition_model, type = "response")
  attrition_weights <- 1 / (1 - attrition_prob)
  
  # Summary statistics
  summary_stats <- list(
    total_baseline = nrow(panel_data),
    complete_panel = sum(attrition_types$type == "Complete"),
    attrition_rate = 1 - sum(attrition_types$type == "Complete") / 
                     nrow(panel_data),
    median_waves = median(rowSums(panel_data[, waves])),
    weight_range = range(attrition_weights, na.rm = TRUE)
  )
  
  cat("PANEL ATTRITION ANALYSIS\n")
  cat("=======================\n")
  cat(sprintf("Baseline sample: %d\n", summary_stats$total_baseline))
  cat(sprintf("Complete panel: %d (%.1f%%)\n", 
              summary_stats$complete_panel,
              summary_stats$complete_panel / summary_stats$total_baseline * 100))
  cat(sprintf("Overall attrition: %.1f%%\n", 
              summary_stats$attrition_rate * 100))
  cat(sprintf("Attrition weight range: %.2f - %.2f\n",
              summary_stats$weight_range[1], 
              summary_stats$weight_range[2]))
  
  return(list(
    patterns = table(attrition_types$type),
    model = attrition_model,
    weights = attrition_weights,
    summary = summary_stats
  ))
}

# Example structure
cat("\nPanel attrition framework configured\n")
cat("Implements inverse probability weighting for attrition\n")
```

---

# Slide 76: Synthetic Data Generation

```{r synthetic-data, echo=TRUE}
# Generate synthetic microdata for training
generate_synthetic_data <- function(real_data_summary, n_synthetic = 5000) {
  
  library(synthpop)
  
  # Method 1: Parametric synthesis
  parametric_synthesis <- function(summary_stats) {
    synthetic <- data.frame(
      # Demographic variables
      age = round(rnorm(n_synthetic, 
                       summary_stats$age_mean, 
                       summary_stats$age_sd)),
      sex = sample(c("M", "F"), n_synthetic, replace = TRUE,
                   prob = c(summary_stats$prop_male, 
                           1 - summary_stats$prop_male)),
      
      # Geographic
      urban_rural = sample(c("Urban", "Rural"), n_synthetic, 
                          replace = TRUE,
                          prob = c(summary_stats$prop_urban,
                                  1 - summary_stats$prop_urban)),
      
      # Socioeconomic (correlated)
      education_years = pmax(0, round(
        rnorm(n_synthetic, 
              summary_stats$education_mean,
              summary_stats$education_sd)
      ))
    )
    
    # Add correlated income
    synthetic$income <- exp(
      8 + 0.1 * synthetic$education_years + 
      0.02 * synthetic$age +
      ifelse(synthetic$urban_rural == "Urban", 0.3, 0) +
      rnorm(n_synthetic, 0, 0.5)
    )
    
    return(synthetic)
  }
  
  # Method 2: CART-based synthesis (if real data available)
  cart_synthesis <- function(real_data) {
    syn_object <- syn(
      real_data,
      method = "cart",
      seed = 2025,
      m = 1  # Single synthetic dataset
    )
    return(syn_object$syn)
  }
  
  # Method 3: Differential privacy synthesis
  dp_synthesis <- function(real_data, epsilon = 1.0) {
    # Add Laplace noise for differential privacy
    synthetic <- real_data
    
    numeric_vars <- sapply(synthetic, is.numeric)
    for(var in names(synthetic)[numeric_vars]) {
      sensitivity <- diff(range(synthetic[[var]], na.rm = TRUE))
      noise <- rlaplace(nrow(synthetic), 0, sensitivity / epsilon)
      synthetic[[var]] <- synthetic[[var]] + noise
    }
    
    return(synthetic)
  }
  
  # Generate synthetic data
  synthetic <- parametric_synthesis(real_data_summary)
  
  cat("SYNTHETIC DATA GENERATION\n")
  cat("========================\n")
  cat(sprintf("Records generated: %d\n", nrow(synthetic)))
  cat(sprintf("Variables: %d\n", ncol(synthetic)))
  cat("\nUtility measures:\n")
  cat("- Univariate similarity: High\n")
  cat("- Bivariate correlations: Preserved\n")
  cat("- Disclosure risk: Minimal\n")
  
  return(synthetic)
}

# Example summary statistics
summary_stats <- list(
  age_mean = 38, age_sd = 15,
  prop_male = 0.49, prop_urban = 0.40,
  education_mean = 8, education_sd = 4
)

synthetic_sample <- generate_synthetic_data(summary_stats, n_synthetic = 100)
cat(sprintf("\nFirst 3 synthetic records generated\n"))
```

---

# Slide 77: Quality Control Algorithms

```{r quality-control-algos, echo=FALSE}
qc_checks <- tibble(
  Check_Type = c("Duplicate Detection", "Logic Consistency", 
                 "Outlier Detection", "Completeness", 
                 "GPS Verification", "Time Stamps", 
                 "Response Patterns", "Interviewer Effects"),
  Algorithm = c("Hash comparison", "Rule engine", 
                "Isolation Forest", "Missing pattern analysis",
                "Geofencing", "Sequential validation",
                "Benford's Law", "Random effects model"),
  Threshold = c("100% match", "Zero violations", "Score > 0.6",
                "< 5% missing", "< 100m deviation", "Logical sequence",
                "p < 0.05", "ICC < 0.1"),
  Current_Status = c("Pass", "2 violations", "12 outliers", "Pass",
                     "Pass", "3 anomalies", "Pass", "ICC = 0.08"),
  Action = c("None", "Review", "Investigate", "None", 
             "None", "Review", "None", "Monitor")
)

qc_checks %>%
  gt() %>%
  tab_header(
    title = "Automated Quality Control Suite",
    subtitle = "Real-time data validation algorithms"
  ) %>%
  data_color(
    columns = Action,
    colors = scales::col_factor(
      palette = c("None" = "#d4edda",
                  "Monitor" = "#e8f4f8",
                  "Review" = "#fff3cd",
                  "Investigate" = "#ffcccc"),
      domain = c("None", "Monitor", "Review", "Investigate")
    )
  )
```

---

# Slide 78: Estimation Domain Optimizer

```{r domain-optimizer, echo=TRUE}
# Optimize estimation domains for precision
optimize_domains <- function(survey_data, target_cv = 0.10) {
  
  # Current domains and their precision
  current_domains <- survey_data %>%
    group_by(province, district) %>%
    summarise(
      n = n(),
      estimate = mean(outcome, na.rm = TRUE),
      se = sd(outcome, na.rm = TRUE) / sqrt(n),
      cv = se / estimate,
      .groups = "drop"
    )
  
  # Identify domains needing aggregation
  problem_domains <- current_domains %>%
    filter(cv > target_cv | n < 30)
  
  # Clustering algorithm for domain aggregation
  if(nrow(problem_domains) > 0) {
    
    # Create similarity matrix based on geography and characteristics
    similarity <- dist(problem_domains[, c("estimate", "n")])
    
    # Hierarchical clustering
    clusters <- hclust(similarity, method = "ward.D2")
    
    # Cut tree to create new domains
    n_clusters <- max(2, nrow(problem_domains) / 2)
    problem_domains$new_domain <- cutree(clusters, k = n_clusters)
    
    # Recalculate precision for new domains
    new_domains <- problem_domains %>%
      group_by(new_domain) %>%
      summarise(
        provinces = paste(province, collapse = "+"),
        combined_n = sum(n),
        combined_cv = sqrt(sum(se^2)) / mean(estimate),
        .groups = "drop"
      )
    
    cat("DOMAIN OPTIMIZATION RESULTS\n")
    cat("==========================\n")
    cat(sprintf("Original domains: %d\n", nrow(current_domains)))
    cat(sprintf("Problem domains: %d (CV > %.2f)\n", 
                nrow(problem_domains), target_cv))
    cat(sprintf("New aggregated domains: %d\n", n_clusters))
    cat(sprintf("Median CV improvement: %.1f%%\n",
                median((problem_domains$cv - new_domains$combined_cv) / 
                      problem_domains$cv * 100)))
    
    return(list(
      original = current_domains,
      problems = problem_domains,
      optimized = new_domains
    ))
  }
  
  cat("All domains meet precision requirements\n")
  return(list(original = current_domains))
}

# Example structure
cat("Domain optimization framework ready\n")
cat("Automatically aggregates domains to achieve target precision\n")
```

---

# Slide 79: Advanced Sampling Frame Validation

```{r frame-validation, echo=FALSE}
frame_validation <- tibble(
  Check = c("Coverage Rate", "Duplication Rate", "Accuracy", 
            "Currency", "Accessibility", "Geo-coding",
            "Classification", "Completeness"),
  Method = c("Census comparison", "Record linkage", "Field verification",
             "Update frequency", "Contact success", "GPS validation",
             "Admin records", "Variable completion"),
  Result = c("92.3%", "3.2%", "94.7%", "8 months", "78.4%", 
             "96.2%", "89.3%", "97.1%"),
  Benchmark = c(">95%", "<2%", ">95%", "<6 months", ">80%", 
                ">95%", ">90%", ">95%"),
  Status = c("âš ï¸", "âš ï¸", "âŒ", "âš ï¸", "âŒ", "âœ…", "âŒ", "âœ…")
) %>%
  mutate(
    Priority = case_when(
      Status == "âŒ" ~ "High",
      Status == "âš ï¸" ~ "Medium",
      TRUE ~ "Low"
    )
  )

frame_validation %>%
  gt() %>%
  tab_header(
    title = "Sampling Frame Quality Assessment",
    subtitle = "Multi-dimensional validation results"
  ) %>%
  data_color(
    columns = Priority,
    colors = scales::col_factor(
      palette = c("High" = "#ffcccc",
                  "Medium" = "#fff3cd",
                  "Low" = "#d4edda"),
      domain = c("High", "Medium", "Low")
    )
  )
```

---

# Slide 80: Predictive Modeling Integration
# Slide 81: Cross-Survey Harmonization

```{r harmonization-framework, echo=TRUE}
# Harmonize variables across different surveys
harmonize_surveys <- function(survey_list) {
  
  # Define harmonization mappings
  harmonization_map <- list(
    income = list(
      survey_a = "monthly_income",
      survey_b = "hh_income_month",
      survey_c = "total_income",
      transform = function(x) x * 12  # Annualize
    ),
    
    education = list(
      survey_a = c("no_edu" = 0, "primary" = 1, "secondary" = 2),
      survey_b = c("illiterate" = 0, "basic" = 1, "high" = 2),
      survey_c = c("none" = 0, "elem" = 1, "hs" = 2)
    )
  )
  
  # Apply harmonization
  harmonized_data <- list()
  
  for(survey in names(survey_list)) {
    data <- survey_list[[survey]]
    
    # Harmonize each variable
    for(var in names(harmonization_map)) {
      old_name <- harmonization_map[[var]][[survey]]
      data[[var]] <- data[[old_name]]
      
      # Apply transformation if needed
      if(!is.null(harmonization_map[[var]]$transform)) {
        data[[var]] <- harmonization_map[[var]]$transform(data[[var]])
      }
    }
    
    harmonized_data[[survey]] <- data
  }
  
  cat("HARMONIZATION COMPLETE\n")
  cat("====================\n")
  cat("Surveys harmonized:", length(survey_list), "\n")
  cat("Variables standardized:", length(harmonization_map), "\n")
  cat("Ready for integrated analysis\n")
  
  return(harmonized_data)
}

# Example execution
cat("Harmonization framework configured\n")
cat("Enables cross-survey comparisons\n")
```

---

# Slide 82: Bayesian Survey Methods

```{r bayesian-methods, echo=FALSE}
bayesian_comparison <- tibble(
  Method = c("Classical", "Bayesian", "Empirical Bayes"),
  Assumptions = c("Fixed parameters", "Prior distributions", "Data-driven priors"),
  Small_Area = c("Unstable", "Stable", "Compromise"),
  Uncertainty = c("Confidence intervals", "Credible intervals", "Hybrid"),
  Software = c("Standard", "STAN, JAGS", "R packages")
)

bayesian_comparison %>%
  gt() %>%
  tab_header(
    title = "Bayesian Methods in Survey Statistics",
    subtitle = "When sample sizes are small"
  ) %>%
  tab_style(
    style = cell_fill(color = "#e8f4f8"),
    locations = cells_body(
      columns = Small_Area,
      rows = Small_Area %in% c("Stable", "Compromise")
    )
  )
```

---

# Slide 83: Non-Probability Sample Integration

```{r nonprob-integration, echo=TRUE}
# Integrate non-probability samples
integrate_nonprob_sample <- function(prob_sample, nonprob_sample) {
  
  # Step 1: Propensity score estimation
  combined <- rbind(
    mutate(prob_sample, source = "probability"),
    mutate(nonprob_sample, source = "non-probability")
  )
  
  # Model participation
  ps_model <- glm(
    source == "non-probability" ~ age + gender + education + region,
    data = combined,
    family = binomial()
  )
  
  # Calculate propensity scores
  propensity_scores <- predict(ps_model, type = "response")
  
  # Step 2: Calculate pseudo-weights for non-prob sample
  nonprob_weights <- (1 - propensity_scores) / propensity_scores
  
  # Step 3: Calibrate to known totals
  # This would use survey::calibrate() in practice
  
  cat("NON-PROBABILITY SAMPLE INTEGRATION\n")
  cat("=================================\n")
  cat("Method: Propensity score weighting\n")
  cat("Weight range:", range(nonprob_weights), "\n")
  cat("Effective sample size reduction: 40%\n")
  cat("\nCaution: Strong assumptions required!\n")
  
  return(list(
    weights = nonprob_weights,
    model = ps_model,
    diagnostics = "Check covariate balance"
  ))
}

# Framework demonstration
cat("Integration framework ready\n")
cat("Use with caution - validity depends on assumptions\n")
```

---

# Slide 84: Rapid Assessment Methods

```{r rapid-assessment, echo=FALSE}
rapid_methods <- tibble(
  Method = c("LQAS", "30x7 Cluster", "SMART", "Mini-MICS", "RDS"),
  Purpose = c("Service coverage", "Immunization", "Nutrition emergency",
              "Child indicators", "Hidden populations"),
  Sample_Size = c("19 per lot", "210 children", "25x10 clusters",
                  "1500 HH", "500-1000"),
  Time_Weeks = c(2, 3, 4, 6, 8),
  Precision = c("Classification", "Â±10%", "Â±5%", "Â±7%", "Unknown")
)

rapid_methods %>%
  gt() %>%
  tab_header(
    title = "Rapid Survey Methods Toolkit",
    subtitle = "When you need answers fast"
  ) %>%
  data_color(
    columns = Time_Weeks,
    colors = scales::col_numeric(
      palette = c("#d4edda", "#fff3cd", "#ffcccc"),
      domain = c(2, 8)
    )
  )
```

---

# Slide 85: Multi-Mode Optimization

```{r multimode-optimize, echo=TRUE}
# Optimize mode allocation
optimize_mode_allocation <- function(budget = 100000, n_target = 5000) {
  
  # Mode characteristics
  modes <- data.frame(
    mode = c("F2F", "Phone", "Web", "SMS"),
    cost = c(50, 15, 5, 2),
    response_rate = c(0.85, 0.60, 0.35, 0.20),
    quality = c(1.0, 0.85, 0.75, 0.50)
  )
  
  # Optimization function (simplified)
  # In practice, use lpSolve or similar
  
  # Heuristic allocation
  allocation <- c(0.40, 0.30, 0.20, 0.10)  # Proportions
  
  # Calculate outcomes
  total_cost <- sum(allocation * n_target * modes$cost)
  avg_response <- sum(allocation * modes$response_rate)
  avg_quality <- sum(allocation * modes$quality)
  
  cat("OPTIMAL MODE ALLOCATION\n")
  cat("=====================\n")
  for(i in 1:nrow(modes)) {
    cat(sprintf("%s: %.0f%% (n=%.0f)\n", 
                modes$mode[i], 
                allocation[i] * 100,
                allocation[i] * n_target))
  }
  cat("\nTotal cost: $", total_cost, "\n")
  cat("Expected response: ", round(avg_response * 100), "%\n")
  cat("Quality index: ", round(avg_quality, 2), "\n")
  
  return(allocation)
}

optimal_mix <- optimize_mode_allocation()
```

---

# Slide 86: Cognitive Testing Integration

```{r cognitive-testing, echo=FALSE}
cognitive_protocol <- tibble(
  Stage = c("Think-aloud", "Probing", "Paraphrasing", 
            "Confidence rating", "Behavior coding"),
  When = c("Development", "Pilot", "Pilot", "Field", "Field"),
  Sample_Size = c("8-12", "20-30", "20-30", "100+", "All"),
  Issues_Found = c("Comprehension", "Interpretation", "Understanding",
                   "Uncertainty", "Interviewer problems"),
  Action = c("Revise wording", "Clarify concepts", "Simplify",
             "Add categories", "Retrain")
)

cognitive_protocol %>%
  gt() %>%
  tab_header(
    title = "Cognitive Testing Protocol",
    subtitle = "Improving questionnaire quality"
  ) %>%
  tab_style(
    style = cell_fill(color = "#fff3cd"),
    locations = cells_body(
      columns = Stage,
      rows = Stage %in% c("Think-aloud", "Probing")
    )
  )
```

---

# Slide 87: Adaptive Survey Design

```{r adaptive-design, echo=TRUE}
# Implement adaptive design
adaptive_survey_design <- function(week, current_stats) {
  
  # Decision rules based on current performance
  decisions <- list()
  
  # Rule 1: Low response rate
  if(current_stats$response_rate < 0.70) {
    decisions$action1 <- "Increase incentive to $20"
    decisions$action2 <- "Deploy best interviewers"
  }
  
  # Rule 2: High cost per complete
  if(current_stats$cost_per_complete > 75) {
    decisions$action3 <- "Shift to phone mode"
    decisions$action4 <- "Stop low-yield areas"
  }
  
  # Rule 3: Representativeness issue
  if(current_stats$youth_deficit > 0.10) {
    decisions$action5 <- "Target youth areas"
    decisions$action6 <- "Use social media recruitment"
  }
  
  cat(sprintf("WEEK %d ADAPTIVE DECISIONS\n", week))
  cat("==========================\n")
  
  if(length(decisions) > 0) {
    for(i in 1:length(decisions)) {
      cat("-", decisions[[i]], "\n")
    }
  } else {
    cat("Continue with current protocol\n")
  }
  
  cat("\nNext review: Week", week + 1, "\n")
  
  return(decisions)
}

# Simulate week 3 decisions
week3_stats <- list(
  response_rate = 0.68,
  cost_per_complete = 82,
  youth_deficit = 0.12
)

decisions <- adaptive_survey_design(3, week3_stats)
```

---

# Slide 88: Total Survey Error Framework

```{r tse-framework, echo=FALSE}
tse_components <- tibble(
  Error_Source = c("Coverage", "Sampling", "Nonresponse", 
                   "Measurement", "Processing"),
  Type = c("Non-sampling", "Sampling", "Non-sampling", 
           "Non-sampling", "Non-sampling"),
  Magnitude = c("Medium", "Low", "High", "Medium", "Low"),
  Mitigation = c("Multiple frames", "Optimal design", "Follow-up protocol",
                 "Cognitive testing", "Validation rules"),
  Cost_to_Fix = c("High", "Medium", "High", "Medium", "Low")
)

tse_components %>%
  ggplot(aes(x = Error_Source, y = 1, fill = Magnitude)) +
  geom_tile(height = 0.8) +
  scale_fill_manual(values = c("Low" = "#d4edda", 
                               "Medium" = "#fff3cd",
                               "High" = "#ffcccc")) +
  coord_flip() +
  labs(title = "Total Survey Error Components",
       subtitle = "Relative importance in household surveys",
       y = "", x = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank(),
        axis.ticks = element_blank())
```

---

# Slide 89: Incentive Optimization

```{r incentive-optimization, echo=TRUE}
# Optimize incentive structure
optimize_incentives <- function(budget_per_hh = 10) {
  
  # Response rate by incentive (from meta-analysis)
  incentive_effect <- data.frame(
    amount = c(0, 5, 10, 20, 50),
    response_rate = c(0.65, 0.72, 0.78, 0.82, 0.84),
    cost_per_complete = c(50, 52, 55, 65, 95)
  )
  
  # Find optimal point
  incentive_effect$efficiency <- 
    incentive_effect$response_rate / incentive_effect$cost_per_complete
  
  optimal <- incentive_effect[which.max(incentive_effect$efficiency), ]
  
  cat("INCENTIVE OPTIMIZATION\n")
  cat("====================\n")
  cat("Optimal incentive: $", optimal$amount, "\n")
  cat("Expected response: ", optimal$response_rate * 100, "%\n")
  cat("Cost per complete: $", optimal$cost_per_complete, "\n")
  cat("\nRecommendation: Use differential incentives by area\n")
  
  return(optimal)
}

optimal_incentive <- optimize_incentives()
```

---

# Slide 90: Matrix Sampling Design

```{r matrix-sampling, echo=FALSE}
matrix_design <- expand.grid(
  Module = LETTERS[1:5],
  Form = 1:3
) %>%
  mutate(
    Included = c("X", "", "X", "X", "", 
                 "", "X", "X", "", "X",
                 "X", "X", "", "X", "")
  ) %>%
  pivot_wider(names_from = Form, values_from = Included,
              names_prefix = "Form_")

matrix_design %>%
  gt() %>%
  tab_header(
    title = "Matrix Sampling Design",
    subtitle = "Reducing respondent burden"
  ) %>%
  tab_footnote(
    footnote = "Each respondent gets 3 of 5 modules",
    locations = cells_title()
  ) %>%
  tab_style(
    style = cell_fill(color = "#e8f4f8"),
    locations = cells_body(
      columns = everything(),
      rows = everything()
    )
  )
```

---

# Slide 91: Paraddata Mining

```{r paradata-mining, echo=TRUE}
# Mine paradata for insights
mine_paradata <- function(paradata) {
  
  insights <- list()
  
  # Pattern 1: Speed indicators
  paradata$speed_flag <- paradata$duration < quantile(paradata$duration, 0.10)
  if(mean(paradata$speed_flag) > 0.05) {
    insights$speed <- "Potential data fabrication detected"
  }
  
  # Pattern 2: Time of day effects
  paradata$evening <- hour(paradata$start_time) >= 18
  evening_quality <- mean(paradata$complete[paradata$evening])
  if(evening_quality > mean(paradata$complete)) {
    insights$timing <- "Evening interviews more successful"
  }
  
  # Pattern 3: Interviewer clustering
  interviewer_icc <- 0.12  # Calculated elsewhere
  if(interviewer_icc > 0.10) {
    insights$interviewer <- "High interviewer effects detected"
  }
  
  cat("PARADATA INSIGHTS\n")
  cat("================\n")
  for(insight in insights) {
    cat("âš ï¸", insight, "\n")
  }
  
  cat("\nActions recommended based on patterns\n")
  
  return(insights)
}

# Demonstration
cat("Paradata mining system configured\n")
cat("Continuous learning from field operations\n")
```

---

# Slide 92: Survey Climate Assessment

```{r survey-climate, echo=FALSE}
climate_factors <- tibble(
  Factor = c("Survey fatigue", "Privacy concerns", "Trust in statistics",
             "Incentive expectations", "Digital divide"),
  Current_Level = c("High", "Very High", "Medium", "Rising", "Significant"),
  Trend = c("â†‘", "â†‘", "â†“", "â†‘", "â†“"),
  Impact_on_Response = c(-15, -20, -10, -5, -12),
  Mitigation = c("Reduce frequency", "Transparency", "Public engagement",
                 "Standardize", "Multi-mode")
)

climate_factors %>%
  gt() %>%
  tab_header(
    title = "Survey Climate Assessment 2025",
    subtitle = "Environmental factors affecting response"
  ) %>%
  data_color(
    columns = Impact_on_Response,
    colors = scales::col_numeric(
      palette = c("#ffcccc", "#fff3cd"),
      domain = c(-20, -5)
    )
  )
```

---

# Slide 93: Emergency Survey Protocols

```{r emergency-protocols, echo=TRUE}
# Emergency survey activation
activate_emergency_survey <- function(crisis_type) {
  
  protocols <- list(
    pandemic = list(
      mode = "Phone only",
      sample = "Previous F2F respondents",
      topics = "Health, income, food security",
      frequency = "Monthly",
      duration = "15 minutes max"
    ),
    
    natural_disaster = list(
      mode = "Mixed (safe areas only)",
      sample = "Affected areas oversample",
      topics = "Damage, needs, displacement",
      frequency = "One-time + follow-up",
      duration = "20 minutes"
    ),
    
    economic_crisis = list(
      mode = "Standard with cost cuts",
      sample = "Panel if available",
      topics = "Employment, coping, expectations",
      frequency = "Quarterly",
      duration = "Standard"
    )
  )
  
  if(crisis_type %in% names(protocols)) {
    p <- protocols[[crisis_type]]
    cat(toupper(crisis_type), "SURVEY PROTOCOL\n")
    cat("========================\n")
    for(element in names(p)) {
      cat(element, ":", p[[element]], "\n")
    }
    cat("\nDeployment time: 72 hours\n")
  }
  
  return(protocols[[crisis_type]])
}

activate_emergency_survey("pandemic")
```

---

# Slide 94: Quality-Cost Trade-offs

```{r quality-cost-tradeoff, echo=FALSE}
tradeoff_points <- tibble(
  Design = c("Basic", "Standard", "Enhanced", "Premium", "Gold"),
  Cost_Index = c(100, 150, 200, 300, 500),
  Quality_Score = c(60, 75, 85, 92, 95),
  CV = c(0.15, 0.10, 0.07, 0.05, 0.03),
  Features = c("Simple random", "+ Stratification", 
               "+ Calibration", "+ Panel component", "+ Real-time adaptive")
)

tradeoff_points %>%
  ggplot(aes(x = Cost_Index, y = Quality_Score)) +
  geom_point(size = 5, color = "darkblue") +
  geom_line(size = 1, color = "darkblue", alpha = 0.5) +
  geom_text(aes(label = Design), vjust = -1) +
  geom_hline(yintercept = 85, linetype = "dashed", color = "red") +
  annotate("text", x = 350, y = 86, label = "Acceptable quality threshold") +
  labs(title = "Survey Quality vs Cost Trade-off",
       subtitle = "Diminishing returns above 'Enhanced' design",
       x = "Cost Index (Basic = 100)",
       y = "Quality Score (0-100)") +
  theme_minimal()
```

---

# Slide 95: Interviewr Performance Analytics

```{r interviewer-analytics, echo=TRUE}
# Analyze interviewer performance
analyze_interviewer_performance <- function(interviewer_data) {
  
  # Calculate key metrics
  performance <- interviewer_data %>%
    group_by(interviewer_id) %>%
    summarise(
      n_interviews = n(),
      response_rate = mean(completed),
      avg_duration = mean(duration),
      quality_score = mean(quality_check),
      cost_per_complete = sum(cost) / sum(completed)
    ) %>%
    mutate(
      efficiency_rank = rank(-response_rate),
      quality_rank = rank(-quality_score),
      overall_rank = (efficiency_rank + quality_rank) / 2
    )
  
  # Identify top and bottom performers
  top_performers <- performance %>%
    filter(overall_rank <= 3) %>%
    pull(interviewer_id)
  
  needs_training <- performance %>%
    filter(quality_score < 0.80 | response_rate < 0.60) %>%
    pull(interviewer_id)
  
  cat("INTERVIEWER PERFORMANCE ANALYSIS\n")
  cat("================================\n")
  cat("Top performers:", paste(top_performers, collapse = ", "), "\n")
  cat("Need training:", paste(needs_training, collapse = ", "), "\n")
  cat("\nRecommendation: Pair weak with strong interviewers\n")
  
  return(performance)
}

# Framework ready
cat("Performance analytics system configured\n")
```

---

# Slide 96: Sampling Frame Maintenance

```{r frame-maintenance, echo=FALSE}
maintenance_schedule <- tibble(
  Activity = c("Coverage check", "Duplicate removal", "Update from admin",
               "Field verification", "Full reconstruction"),
  Frequency = c("Quarterly", "Monthly", "Monthly", "Annual", "10 years"),
  Last_Done = c("Jan 2025", "Sep 2025", "Sep 2025", "Mar 2024", "2022"),
  Status = c("Due", "Current", "Current", "Overdue", "On track"),
  Cost = c(5000, 1000, 2000, 50000, 500000)
)

maintenance_schedule %>%
  gt() %>%
  tab_header(
    title = "Sampling Frame Maintenance Protocol",
    subtitle = "Keeping the foundation strong"
  ) %>%
  fmt_currency(columns = Cost, currency = "USD") %>%
  data_color(
    columns = Status,
    colors = scales::col_factor(
      palette = c("Current" = "#d4edda", "Due" = "#fff3cd",
                  "Overdue" = "#ffcccc", "On track" = "#e8f4f8"),
      domain = c("Current", "Due", "Overdue", "On track")
    )
  )
```

---

# Slide 97: Response Propensity Modeling

```{r response-propensity, echo=TRUE}
# Model response propensity
model_response_propensity <- function(frame_data) {
  
  # Build predictive model
  # In practice, use more sophisticated ML methods
  
  # Logistic regression for demonstration
  formula <- response ~ age + I(age^2) + gender + urban_rural + 
             previous_response + contact_attempts + 
             day_of_week + incentive_amount
  
  # Model would be fitted here
  # model <- glm(formula, data = frame_data, family = binomial())
  
  # Simulated predictions
  propensity_scores <- runif(nrow(frame_data), 0.4, 0.9)
  
  # Create response strata
  frame_data$response_stratum <- cut(
    propensity_scores,
    breaks = quantile(propensity_scores, probs = 0:5/5),
    labels = paste0("S", 1:5)
  )
  
  cat("RESPONSE PROPENSITY MODEL\n")
  cat("========================\n")
  cat("Variables included: 8\n")
  cat("Model AUC: 0.78\n")
  cat("Response strata created: 5\n")
  cat("\nUse for:\n")
  cat("- Adaptive design\n")
  cat("- Nonresponse adjustment\n")
  cat("- Cost optimization\n")
  
  return(frame_data)
}

# Demonstration
cat("Propensity modeling framework ready\n")
```

---

# Slide 98: Survey Integration Platform

```{r integration-platform, echo=FALSE}
platform_components <- tibble(
  Component = c("Design Module", "Field System", "Data Processing",
                "Quality Monitor", "Analysis Engine", "Dissemination"),
  Technology = c("R Shiny", "SurveyCTO", "PostgreSQL + R",
                 "Real-time dashboard", "Survey package", "API + Shiny"),
  Status = c("Operational", "Testing", "Operational",
             "Development", "Operational", "Planning"),
  Integration = c("Full", "API", "Full", "Partial", "Full", "Future"),
  Priority = c("High", "Critical", "High", "High", "Medium", "Medium")
)

platform_components %>%
  gt() %>%
  tab_header(
    title = "Integrated Survey Platform Architecture",
    subtitle = "End-to-end survey ecosystem"
  ) %>%
  data_color(
    columns = Status,
    colors = scales::col_factor(
      palette = c("Operational" = "#d4edda", "Testing" = "#fff3cd",
                  "Development" = "#ffe6e6", "Planning" = "#e8f4f8"),
      domain = c("Operational", "Testing", "Development", "Planning")
    )
  )
```

---

# Slide 99: Harry's Friday Success

## 5:00 PM - Mission Accomplished

```{r friday-success, echo=TRUE}
# Summary of Harry's achievements
friday_summary <- function() {
  achievements <- list(
    "9:00 AM" = "Convinced Minister with evidence",
    "10:00 AM" = "Secured budget approval",
    "11:00 AM" = "Designed panel survey",
    "2:00 PM" = "Trained core team",
    "4:00 PM" = "Implementation plan approved",
    "5:00 PM" = "Celebrated transformation"
  )
  
  cat("HARRY'S FRIDAY ACHIEVEMENTS\n")
  cat("==========================\n\n")
  
  for(time in names(achievements)) {
    cat(time, ":", achievements[[time]], "\n")
  }
  
  cat("\nðŸŽ‰ STATISTICAL SYSTEM TRANSFORMED! ðŸŽ‰\n")
  cat("\nMinister's comment: 'Best investment we've made!'\n")
  cat("Team's response: 'We're ready for any survey!'\n")
  cat("\nHarry's thought: 'This week changed everything.'\n")
}

friday_summary()
```

---

class: inverse, center, middle


# MODULE 3: PANEL SURVEYS & LONGITUDINAL METHODS
## Friday 11:00 AM - Harry's Panel Challenge
### Slides 101-150

---

# Slide 101: The Panel Survey Crisis

## 11:00 AM - Emergency Meeting

**Director bursts in:** "Harry! The Minister wants a panel survey to track poverty dynamics. EU-SILC style, 4-year rotation, starting NOW!"

**The Challenge:**
- Design rotating panel (n=5,000 households)
- 25% annual rotation (Eurostat standard)
- Track income mobility
- Minimize attrition
- Maintain representativeness

**Harry thinks:** "Panel surveys are the PhD of sampling. Time to show what we've learned."

---

# Slide 102: What Makes Panels Special

## Beyond Cross-Sectional Surveys

```{r panel-vs-cross, echo=FALSE}
comparison <- tibble(
  Aspect = c("Measurement", "Sample", "Analysis", "Cost", "Complexity"),
  Cross_Sectional = c("Point in time", "New each wave", "Status", 
                      "Lower", "Simple"),
  Panel = c("Change over time", "Follow same units", "Dynamics", 
            "Higher", "Complex")
)

comparison %>%
  kable(caption = "Panel vs Cross-Sectional Surveys") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

**Harry explains:** "Panels reveal transitions, not just states"

---

# Slide 103: EU-SILC Rotation Design

## The Gold Standard (Eurostat)

```{r eusilc-rotation, echo=FALSE}
rotation <- expand.grid(
  Year = 2025:2028,
  Rotation_Group = 1:4
) %>%
  mutate(
    In_Sample = case_when(
      Rotation_Group == 1 & Year <= 2028 ~ "âœ“",
      Rotation_Group == 2 & Year >= 2025 & Year <= 2028 ~ "âœ“",
      Rotation_Group == 3 & Year >= 2026 ~ "âœ“",
      Rotation_Group == 4 & Year >= 2027 ~ "âœ“",
      TRUE ~ ""
    )
  )

rotation %>%
  pivot_wider(names_from = Year, values_from = In_Sample) %>%
  kable(caption = "4-Year Rotation Pattern (25% refresh annually)") %>%
  kable_styling(bootstrap_options = "bordered")
```

---

# Slide 104: World Bank LSMS Panel Design

## Tracking Welfare Dynamics

**Run Script panel_design.R for full implementation**

Key features (Grosh & Glewwe, 2000):
- 2-3 year panels typical
- Oversample movers
- GPS tracking for mobility
- Split panel option

```{r wb-design-summary, echo=TRUE}
# LSMS panel parameters
lsms_params <- list(
  waves = 3,
  interval_months = 12,
  tracking_rate = 0.90,
  split_panel_pct = 0.50
)
print(lsms_params)
```

---

# Slide 105: OECD Household Panel Guidelines

## International Best Practice

```{r oecd-guidelines, echo=FALSE}
guidelines <- tibble(
  Principle = c("Coverage", "Attrition", "Refreshment", "Weighting"),
  OECD_Standard = c("95% frame coverage", "<15% annual attrition",
                    "Annual evaluation", "Longitudinal + cross-sectional"),
  Implementation = c("Area-based frame", "Incentives + tracking",
                     "Rotating groups", "Complex calibration")
)

guidelines %>%
  gt() %>%
  tab_header(title = "OECD Panel Survey Standards")
```

---

# Slide 106: Sample Size for Panel Studies

## Power Calculations for Change

```{r panel-sample-size, echo=TRUE}
# Calculate sample size for detecting change
panel_sample_size <- function(effect_size = 0.1, 
                              correlation = 0.6,
                              power = 0.8) {
  # Adjustment for repeated measures
  var_factor <- 2 * (1 - correlation)
  
  # Standard sample size
  n_cross <- 1537  # For effect_size = 0.1
  
  # Panel adjustment
  n_panel <- n_cross * var_factor
  
  return(ceiling(n_panel))
}

n_required <- panel_sample_size()
cat("Sample needed:", n_required)
```

---

# Slide 107: Rotation Group Management

## Harry's Implementation Plan

```{r rotation-implementation, echo=FALSE}
groups <- tibble(
  Group = paste0("G", 1:4),
  Start_Year = 2025:2028,
  End_Year = 2028:2031,
  Households = rep(1250, 4),
  Current_Wave = c(4, 3, 2, 1)
)

groups %>%
  ggplot(aes(x = Start_Year, xend = End_Year, 
             y = Group, yend = Group)) +
  geom_segment(size = 8, aes(color = Group)) +
  geom_point(size = 4) +
  geom_point(aes(x = End_Year), size = 4) +
  labs(title = "Panel Rotation Timeline",
       x = "Year", y = "Rotation Group") +
  theme_minimal()
```

---

# Slide 108: Initial Wave Sampling

## Starting the Panel Right

```{r initial-sampling, echo=TRUE}
# Two-stage selection for panel
select_panel_sample <- function(n_psu = 250, n_hh_per_psu = 20) {
  # Stage 1: Select PSUs with PPS
  # Run Script: panel_pps_selection.R
  cat("Stage 1: Select", n_psu, "PSUs using PPS\n")
  
  # Stage 2: Select households
  cat("Stage 2: Select", n_hh_per_psu, "HH per PSU\n")
  
  # Reserve sample for replacement
  reserve_pct <- 0.20
  n_reserve <- ceiling(n_psu * n_hh_per_psu * reserve_pct)
  
  cat("Reserve sample:", n_reserve, "households\n")
  
  return(list(main = n_psu * n_hh_per_psu,
              reserve = n_reserve))
}

sample_sizes <- select_panel_sample()
```

---

# Slide 109: Tracking Rules

## Following Households Over Time

```{r tracking-rules, echo=FALSE}
rules <- tribble(
  ~Situation, ~Action, ~Weight_Impact,
  "Original address", "Interview all", "No change",
  "Moved locally", "Follow and interview", "Adjust for mobility",
  "Moved far", "Telephone/proxy", "Non-response adjustment",
  "Split household", "Follow reference person", "Recalculate",
  "Deceased", "Exit panel", "Attrition weight",
  "Refusal", "Convert attempts", "Non-response weight"
)

rules %>%
  kable(caption = "Eurostat Tracking Protocol") %>%
  kable_styling(bootstrap_options = c("striped", "condensed"))
```

---

# Slide 110: Attrition Patterns

## The Panel Survey Challenge

```{r attrition-patterns, echo=FALSE}
attrition_data <- tibble(
  Wave = 1:4,
  Responding = c(5000, 4250, 3800, 3500),
  Attrition_Rate = c(0, 15, 10, 8),
  Cumulative_Attrition = c(0, 15, 24, 30)
)

attrition_data %>%
  ggplot(aes(x = Wave, y = Responding)) +
  geom_line(size = 2, color = "darkblue") +
  geom_point(size = 4, color = "darkblue") +
  geom_text(aes(label = Responding), vjust = -1) +
  labs(title = "Typical Panel Attrition Pattern",
       subtitle = "World Bank LSMS experience",
       y = "Households Remaining") +
  theme_minimal()
```

---

# Slide 111: Minimizing Attrition

## Best Practices from Three Institutions

```{r minimize-attrition, echo=TRUE}
# Attrition reduction strategies
attrition_strategies <- list(
  eurostat = c("Advance letters", "Flexible scheduling", 
               "Incentives â‚¬20-50"),
  world_bank = c("Community engagement", "Local tracking", 
                 "Mobile money payments"),
  oecd = c("Mixed modes", "Proxy interviews allowed", 
           "Birthday cards")
)

# Expected impact
for(institution in names(attrition_strategies)) {
  cat(toupper(institution), "strategies:\n")
  cat(paste("-", attrition_strategies[[institution]]), sep = "\n")
  cat("\n")
}
```

---

# Slide 112: Wave-on-Wave Tracking

## Maintaining Sample Integrity

**Run Script: wave_tracking.R for full system**

```{r wave-tracking, echo=TRUE}
# Track households across waves
track_households <- function(wave1, wave2) {
  # Match households
  matched <- wave2$hh_id %in% wave1$hh_id
  
  # Calculate rates
  retention_rate <- mean(matched)
  
  # Categories
  stats <- list(
    continuing = sum(matched),
    attrited = sum(!matched),
    rate = retention_rate
  )
  
  return(stats)
}

# Example tracking
cat("Retention rate: 85%\n")
cat("Action: Implement attrition weights")
```

---

# Slide 113: Panel Weights - Initial

## Base Weights for Wave 1

```{r initial-weights, echo=FALSE}
weight_components <- tibble(
  Component = c("Selection probability", "Non-response", 
                "Post-stratification", "Trimming"),
  Formula = c("1/(Ï€_psu Ã— Ï€_hh|psu)", "1/response_rate",
              "Population/Sample", "Bounded [0.3, 3]"),
  Impact = c("Base", "Ã—1.2", "Ã—0.95", "Stabilize")
)

weight_components %>%
  gt() %>%
  tab_header(title = "Initial Weight Construction",
             subtitle = "Following EU-SILC methodology")
```

---

# Slide 114: Longitudinal Weights

## Accounting for Attrition

```{r longitudinal-weights, echo=TRUE}
# Calculate longitudinal weights
calc_longitudinal_weights <- function(base_weight, 
                                     response_prop) {
  # Non-response adjustment
  long_weight <- base_weight / response_prop
  
  # Trimming for stability
  long_weight <- pmin(pmax(long_weight, 
                           quantile(long_weight, 0.01)),
                      quantile(long_weight, 0.99))
  
  return(long_weight)
}

# Example
weights <- calc_longitudinal_weights(100, 0.85)
cat("Adjusted weight:", round(weights, 1))
```

---

# Slide 115: Cross-Sectional Weights in Panels

## Maintaining Representativeness

**Run Script: panel_calibration.R for implementation**

```{r cross-sectional-weights, echo=FALSE}
cs_approach <- tribble(
  ~Wave, ~Method, ~Reference,
  "Wave 1", "Standard calibration", "Census projections",
  "Wave 2", "Include new entrants", "Updated frame",
  "Wave 3", "Composite estimation", "Admin records",
  "Wave 4", "Full recalibration", "Mid-term census"
)

cs_approach %>%
  kable(caption = "Cross-sectional Weight Strategy") %>%
  kable_styling(bootstrap_options = "hover")
```

---

# Slide 116: Refreshment Sample Design

## Bringing in New Blood

```{r refreshment-design, echo=TRUE}
# Design refreshment sample
design_refreshment <- function(year, rotation_pct = 0.25) {
  base_sample <- 5000
  
  # Calculate refreshment needs
  refresh_n <- base_sample * rotation_pct
  
  # Account for expected attrition in new sample
  oversample_factor <- 1.1
  
  target_n <- ceiling(refresh_n * oversample_factor)
  
  cat("Year", year, "refreshment:\n")
  cat("- Target:", refresh_n, "households\n")
  cat("- Select:", target_n, "(includes reserve)\n")
  
  return(target_n)
}

refresh_2026 <- design_refreshment(2026)
```

---

# Slide 117: Composite Estimation

## Combining Waves for Precision

```{r composite-estimation, echo=FALSE}
composite_formula <- tibble(
  Estimator = c("Current wave only", "Equal weighted", 
                "Optimal composite", "AK composite"),
  Weight_Current = c(1.0, 0.5, 0.6, "Adaptive"),
  Weight_Previous = c(0, 0.5, 0.4, "1-K"),
  Efficiency = c("Baseline", "+15%", "+25%", "+30%")
)

composite_formula %>%
  gt() %>%
  tab_header(title = "Composite Estimation Methods",
             subtitle = "As per Statistics Canada guidelines") %>%
  tab_source_note("K determined by autocorrelation")
```

---

# Slide 118: Income Mobility Analysis

## The Power of Panels

```{r mobility-matrix, echo=TRUE}
# Create transition matrix
# Full code in Script: mobility_analysis.R
create_mobility_matrix <- function() {
  matrix(c(0.6, 0.3, 0.1, 0,
           0.2, 0.5, 0.2, 0.1,
           0.05, 0.2, 0.5, 0.25,
           0, 0.05, 0.25, 0.7),
         nrow = 4, byrow = TRUE,
         dimnames = list(
           Wave1 = c("Q1", "Q2", "Q3", "Q4"),
           Wave2 = c("Q1", "Q2", "Q3", "Q4")))
}

mobility <- create_mobility_matrix()
print(mobility)
```

---

# Slide 119: Poverty Dynamics

## What Cross-Sections Miss

```{r poverty-dynamics, echo=FALSE}
dynamics <- tibble(
  Category = c("Always poor", "Escape poverty", 
               "Fall into poverty", "Never poor"),
  Cross_Section = c(20, NA, NA, 80),
  Panel_Reality = c(5, 10, 5, 80)
)

dynamics %>%
  pivot_longer(cols = -Category, names_to = "Method", 
               values_to = "Percentage") %>%
  ggplot(aes(x = Category, y = Percentage, fill = Method)) +
  geom_col(position = "dodge") +
  labs(title = "The Hidden Dynamics of Poverty",
       subtitle = "Why panels matter (World Bank evidence)") +
  theme_minimal() +
  coord_flip()
```

---

# Slide 120: Spell Analysis

## Duration Matters

```{r spell-analysis, echo=TRUE}
# Analyze poverty spells
analyze_spells <- function(panel_data) {
  # Identify spells (simplified)
  spells <- list(
    short_term = "1-2 waves: 45%",
    medium_term = "3-4 waves: 35%",
    chronic = "All waves: 20%"
  )
  
  cat("Poverty spell distribution:\n")
  for(type in names(spells)) {
    cat("-", type, ":", spells[[type]], "\n")
  }
  
  cat("\nPolicy implication: Target chronic poor differently")
}

analyze_spells(NULL)
```

---

# Slide 121: Event Study Design

## Measuring Shock Impacts

**Run Script: event_study.R for implementation**

```{r event-design, echo=FALSE}
event_timeline <- tibble(
  Period = -2:2,
  Label = c("t-2", "t-1", "Shock", "t+1", "t+2"),
  Sample_Size = c(5000, 5000, 5000, 4500, 4200),
  Measurement = c("Baseline", "Pre-trend", "Impact", 
                  "Recovery", "Long-term")
)

event_timeline %>%
  ggplot(aes(x = Period, y = Sample_Size)) +
  geom_line(size = 2) +
  geom_point(size = 4, aes(color = Label)) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Panel Design for Shock Analysis",
       subtitle = "COVID-19 impact study design") +
  theme_minimal()
```

---

# Slide 122: Mixed Mode in Panels

## Maintaining Contact

```{r mixed-mode-panel, echo=TRUE}
# Mode allocation strategy
allocate_modes <- function(wave, cost_f2f = 50, 
                          cost_phone = 10) {
  if(wave == 1) {
    mode_mix <- list(f2f = 1.0, phone = 0, web = 0)
  } else {
    mode_mix <- list(f2f = 0.6, phone = 0.3, web = 0.1)
  }
  
  avg_cost <- sum(mode_mix$f2f * cost_f2f +
                  mode_mix$phone * cost_phone)
  
  cat("Wave", wave, "mode mix:\n")
  cat("Average cost: $", avg_cost, "\n")
  
  return(mode_mix)
}

wave2_modes <- allocate_modes(2)
```

---

# Slide 123: Seam Effects

## The Panel Survey Bias

```{r seam-effects, echo=FALSE}
seam_data <- tibble(
  Month = 1:12,
  Wave = c(rep("Wave 1", 3), rep("Seam", 1), 
           rep("Wave 2", 3), rep("Seam", 1),
           rep("Wave 3", 3), rep("Seam", 1)),
  Transitions = c(5, 4, 6, 18, 5, 4, 5, 20, 6, 5, 4, 19)
)

seam_data %>%
  ggplot(aes(x = Month, y = Transitions, fill = Wave)) +
  geom_col() +
  labs(title = "Seam Effect in Employment Transitions",
       subtitle = "Spurious changes at wave boundaries") +
  theme_minimal()
```

---

# Slide 124: Dependent Interviewing

## Reducing Seam Effects

```{r dependent-interviewing, echo=TRUE}
# Dependent interviewing protocol
dependent_interview <- function(prev_response) {
  # Reference previous wave
  prompt <- paste0(
    "Last time you said you were '", 
    prev_response, 
    "'. Is this still correct?"
  )
  
  # Benefits
  benefits <- c(
    "Reduces spurious change",
    "Improves data quality",
    "Shortens interview"
  )
  
  cat(prompt, "\n\n")
  cat("Benefits:\n")
  cat(paste("-", benefits), sep = "\n")
}

dependent_interview("Employed full-time")
```

---

# Slide 125: Time-in-Sample Bias

## Panel Conditioning Effects

```{r time-in-sample, echo=FALSE}
tis_bias <- tibble(
  Wave = 1:4,
  Reported_Income = c(25000, 26500, 27800, 29000),
  True_Income = c(27000, 27500, 28000, 28500),
  Bias = Reported_Income - True_Income
)

tis_bias %>%
  ggplot(aes(x = Wave)) +
  geom_line(aes(y = Reported_Income), color = "red", size = 2) +
  geom_line(aes(y = True_Income), color = "blue", size = 2) +
  geom_ribbon(aes(ymin = Reported_Income, ymax = True_Income),
              alpha = 0.3) +
  labs(title = "Panel Conditioning: Income Reporting",
       subtitle = "Learning effect over waves") +
  theme_minimal()
```

---

# Slide 126: Imputation in Panels

## Using Temporal Information

**Run Script: panel_imputation.R for methods**

```{r panel-imputation, echo=TRUE}
# Panel imputation strategy
impute_panel <- function(missing_wave = 3) {
  methods <- c(
    "Last observation carried forward",
    "Linear interpolation",
    "Regression with past values",
    "Hot deck within trajectory"
  )
  
  cat("Wave", missing_wave, "imputation options:\n")
  cat(paste(1:4, methods, sep = ". "), sep = "\n")
  
  cat("\nRecommended: Method 3 for income data")
}

impute_panel()
```

---

# Slide 127: Variance Estimation

## Accounting for Correlation

```{r panel-variance, echo=TRUE}
# GEE approach for panel variance
estimate_panel_variance <- function(correlation = 0.6) {
  # Simplified variance inflation
  n_waves <- 4
  
  # Independence assumption
  var_indep <- 1
  
  # Accounting for correlation
  var_factor <- 1 + correlation * (n_waves - 1)
  var_panel <- var_indep * var_factor
  
  cat("Variance inflation factor:", var_factor, "\n")
  cat("SE multiplier:", sqrt(var_factor), "\n")
}

estimate_panel_variance()
```

---

# Slide 128: Balanced vs Unbalanced Panels

## Design Trade-offs

```{r panel-balance, echo=FALSE}
balance_comparison <- tribble(
  ~Aspect, ~Balanced, ~Unbalanced,
  "Sample", "Complete cases only", "All available",
  "Size", "Decreases over time", "Maximized",
  "Analysis", "Simple", "Complex",
  "Bias", "Possible selection", "Reduced",
  "Software", "Standard", "Specialized"
)

balance_comparison %>%
  gt() %>%
  tab_header(title = "Panel Design Choice",
             subtitle = "OECD recommendations")
```

---

# Slide 129: Split Panel Design

## Best of Both Worlds

```{r split-panel, echo=TRUE}
# World Bank split panel approach
design_split_panel <- function(total_n = 5000) {
  # Half indefinite, half rotating
  indefinite <- total_n * 0.5
  rotating <- total_n * 0.5
  
  # Rotation schedule
  rotation_years <- 2
  
  design <- list(
    indefinite_panel = indefinite,
    rotating_panel = rotating,
    rotation_period = rotation_years
  )
  
  cat("Split panel design:\n")
  cat("- Indefinite:", indefinite, "households\n")
  cat("- Rotating:", rotating, "every", rotation_years, "years\n")
  
  return(design)
}

split_design <- design_split_panel()
```

---

# Slide 130: GPS Tracking Innovation

## Finding Mobile Households

```{r gps-tracking, echo=FALSE}
tracking_tech <- tibble(
  Method = c("Address only", "Phone follow-up", 
             "GPS coordinates", "Community informants"),
  Success_Rate = c(60, 75, 92, 85),
  Cost_Index = c(100, 120, 150, 110),
  Speed = c("Slow", "Medium", "Fast", "Medium")
)

tracking_tech %>%
  ggplot(aes(x = Cost_Index, y = Success_Rate)) +
  geom_point(size = 5, aes(color = Method)) +
  geom_text(aes(label = Method), vjust = -1, size = 3) +
  labs(title = "Tracking Technology Comparison",
       subtitle = "GPS delivers best results (LSMS evidence)",
       x = "Cost Index", y = "Success Rate (%)") +
  theme_minimal()
```

---

# Slide 131: Consent and Ethics

## Panel-Specific Considerations

```{r panel-ethics, echo=TRUE}
# Ethics protocol for panels
panel_ethics_checklist <- function() {
  requirements <- list(
    initial = c("Extended consent form",
                "Right to withdraw",
                "Data linking permission"),
    ongoing = c("Annual consent renewal",
                "Update contact preferences",
                "Verify data use"),
    exit = c("Final interview option",
             "Data retention agreement",
             "Thank you letter")
  )
  
  for(phase in names(requirements)) {
    cat(toupper(phase), "requirements:\n")
    cat(paste("-", requirements[[phase]]), sep = "\n")
    cat("\n")
  }
}

panel_ethics_checklist()
```

---

# Slide 132: Quality Control in Panels

## Multi-Wave Validation

**Run Script: panel_quality.R for full system**

```{r panel-quality, echo=FALSE}
quality_checks <- tribble(
  ~Check, ~Frequency, ~Threshold, ~Action,
  "Response consistency", "Each wave", "90% stable", "Flag changes",
  "Interview length", "Monthly", "Â±20% of median", "Review",
  "Attrition patterns", "Quarterly", "Random", "Investigate",
  "Weight distribution", "Each wave", "CV < 2", "Adjust"
)

quality_checks %>%
  kable(caption = "Panel Quality Monitoring") %>%
  kable_styling(bootstrap_options = c("striped", "condensed"))
```

---

# Slide 133: Panel Questionnaire Design

## Minimizing Burden

```{r panel-questionnaire, echo=TRUE}
# Optimize panel questionnaire
optimize_questionnaire <- function(wave) {
  if(wave == 1) {
    modules <- c("Full demographics", "Detailed history", 
                 "Complete inventory")
    time_minutes <- 60
  } else {
    modules <- c("Updates only", "Key indicators", 
                 "New events")
    time_minutes <- 30
  }
  
  cat("Wave", wave, "questionnaire:\n")
  cat("Modules:", paste(modules, collapse = ", "), "\n")
  cat("Expected time:", time_minutes, "minutes\n")
}

optimize_questionnaire(2)
```

---

# Slide 134: International Harmonization

## Making Panels Comparable

```{r harmonization, echo=FALSE}
harmony_standards <- tibble(
  Element = c("Rotation period", "Core variables", 
              "Income reference", "Weights"),
  EU_SILC = c("4 years", "130 variables", "Annual", "Calibrated"),
  LSMS = c("2-3 years", "Flexible", "Monthly", "Post-stratified"),
  OECD = c("Indefinite", "Minimum set", "Annual", "Raked")
)

harmony_standards %>%
  gt() %>%
  tab_header(title = "International Panel Standards") %>%
  tab_style(
    style = cell_fill(color = "lightblue"),
    locations = cells_body(columns = EU_SILC)
  )
```

---

# Slide 135: Cost-Benefit Analysis

## Is It Worth It?

```{r panel-cost-benefit, echo=TRUE}
# Panel survey economics
panel_economics <- function(waves = 4, n = 5000) {
  # Costs
  cost_wave1 <- n * 60  # Full interview
  cost_followup <- n * 0.85 * 35  # Reduced interview
  total_cost <- cost_wave1 + (waves - 1) * cost_followup
  
  # Benefits
  cross_section_cost <- waves * n * 60
  savings <- cross_section_cost - total_cost
  
  cat("Panel saves: $", format(savings, big.mark = ","), "\n")
  cat("Plus: Measures change (invaluable)\n")
  
  return(savings)
}

savings <- panel_economics()
```

---

# Slide 136: Software for Panel Analysis

## Harry's Toolkit

```{r panel-software, echo=FALSE}
software <- tribble(
  ~Software, ~Strength, ~Weakness, ~Cost,
  "R (plm, panelr)", "Flexible, free", "Learning curve", "Free",
  "Stata (xt commands)", "Comprehensive", "Expensive", "$1,800",
  "SAS PROC PANEL", "Enterprise ready", "Complex", "$9,000",
  "Python (linearmodels)", "Modern, ML integration", "Limited", "Free"
)

software %>%
  gt() %>%
  tab_header(title = "Panel Analysis Software Options") %>%
  tab_style(
    style = cell_fill(color = "lightgreen"),
    locations = cells_body(
      columns = Cost,
      rows = Cost == "Free"
    )
  )
```

---

# Slide 137: Fixed Effects Models

## The Panel Advantage

**Run Script: panel_models.R for estimation**

```{r fixed-effects, echo=TRUE}
# Basic fixed effects concept
explain_fixed_effects <- function() {
  cat("Fixed Effects Model:\n")
  cat("Y_it = Î±_i + Î²X_it + Îµ_it\n\n")
  
  cat("Advantages:\n")
  cat("- Controls for time-invariant unobservables\n")
  cat("- Causal inference stronger\n")
  cat("- No omitted variable bias (if time-invariant)\n")
}

explain_fixed_effects()
```

---

# Slide 138: Random Effects Alternative

## When to Use What

```{r random-effects, echo=FALSE}
model_choice <- tibble(
  Criterion = c("Correlation with unobservables", "Between variation",
                "Time-invariant variables", "Sample size"),
  Fixed_Effects = c("Can be correlated", "Not used", 
                    "Cannot estimate", "Large N helpful"),
  Random_Effects = c("Must be uncorrelated", "Uses all", 
                     "Can estimate", "Small N okay")
)

model_choice %>%
  kable(caption = "Fixed vs Random Effects") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

---

# Slide 139: Hausman Test Implementation

## Model Selection

```{r hausman-test, echo=TRUE}
# Hausman test logic
hausman_test <- function(fe_coef, re_coef, var_diff) {
  # Test statistic
  diff <- fe_coef - re_coef
  chi_sq <- (diff^2) / var_diff
  
  # Decision
  if(chi_sq > 3.84) {  # 5% critical value
    decision <- "Use Fixed Effects"
  } else {
    decision <- "Random Effects acceptable"
  }
  
  cat("Hausman test statistic:", round(chi_sq, 2), "\n")
  cat("Decision:", decision, "\n")
}

hausman_test(0.5, 0.45, 0.001)
```

---

# Slide 140: Panel Data Visualization

## Showing Change Over Time

```{r panel-viz, echo=FALSE}
# Spaghetti plot example
panel_viz_data <- expand.grid(
  id = 1:20,
  wave = 1:4
) %>%
  mutate(
    outcome = 25 + id/2 + wave * 2 + rnorm(80, 0, 3),
    group = ifelse(id <= 10, "Treatment", "Control")
  )

panel_viz_data %>%
  ggplot(aes(x = wave, y = outcome, group = id)) +
  geom_line(aes(color = group), alpha = 0.5) +
  geom_smooth(aes(group = group, color = group), 
              method = "loess", se = FALSE, size = 2) +
  labs(title = "Individual Trajectories in Panel Data",
       subtitle = "Spaghetti plot with group trends") +
  theme_minimal()
```

---

# Slide 141: Synthetic Panels

## When True Panels Aren't Possible

**Run Script: synthetic_panel.R for construction**

```{r synthetic-panel, echo=TRUE}
# Create synthetic panel from cross-sections
create_synthetic_panel <- function() {
  # Use birth cohorts as pseudo-panels
  cohorts <- list(
    "1970-1975" = "Track over time",
    "1976-1980" = "Track over time",
    "1981-1985" = "Track over time"
  )
  
  cat("Synthetic panel approach:\n")
  cat("1. Define cohorts (n > 100 per cohort)\n")
  cat("2. Track cohort means over time\n")
  cat("3. Treat as panel of cohorts\n")
  
  cat("\nLimitation: Within-cohort variation lost\n")
}

create_synthetic_panel()
```

---

# Slide 142: Duration Models

## Time to Event Analysis

```{r duration-models, echo=FALSE}
duration_concepts <- tribble(
  ~Concept, ~Definition, ~Example,
  "Spell", "Time in state", "Unemployment duration",
  "Hazard", "Exit probability", "Job finding rate",
  "Censoring", "Incomplete spells", "Still unemployed at survey end",
  "Duration dependence", "Time affects hazard", "Stigma effect"
)

duration_concepts %>%
  gt() %>%
  tab_header(title = "Duration Analysis in Panels",
             subtitle = "Key concepts for poverty dynamics")
```

---

# Slide 143: Machine Learning with Panels

## Modern Methods

```{r ml-panels, echo=TRUE}
# ML applications for panel data
ml_panel_applications <- function() {
  applications <- list(
    prediction = "Forecast attrition probability",
    clustering = "Identify trajectory groups",
    classification = "Detect measurement error",
    imputation = "Smart missing data handling"
  )
  
  cat("ML enhances panel surveys:\n")
  for(app in names(applications)) {
    cat("-", app, ":", applications[[app]], "\n")
  }
  
  cat("\nCaution: Respect temporal structure!")
}

ml_panel_applications()
```

---

# Slide 144: Real-Time Panel Updates

## Digital Age Panels

```{r realtime-panels, echo=FALSE}
digital_timeline <- tibble(
  Method = c("Annual interview", "Quarterly phone", 
             "Monthly web", "Weekly SMS", "Daily app"),
  Frequency = c(1, 4, 12, 52, 365),
  Cost_Per = c(60, 15, 5, 0.5, 0.1),
  Response_Rate = c(85, 70, 50, 40, 25)
)

digital_timeline %>%
  ggplot(aes(x = Frequency, y = Response_Rate)) +
  geom_point(aes(size = Cost_Per), color = "darkblue") +
  geom_text(aes(label = Method), vjust = -1, size = 3) +
  scale_x_log10() +
  labs(title = "Digital Panel Data Collection",
       subtitle = "Frequency vs Response Trade-off",
       x = "Contacts per Year (log scale)",
       y = "Response Rate (%)") +
  theme_minimal()
```

---

# Slide 145: COVID-19 Panel Innovations

## Crisis Response

```{r covid-panels, echo=TRUE}
# Rapid panel deployment
covid_panel_response <- function() {
  innovations <- c(
    "Phone panels from F2F samples",
    "High-frequency (monthly) waves",
    "Short questionnaires (15 min)",
    "Mobile money incentives",
    "Real-time dashboard reporting"
  )
  
  cat("World Bank COVID panel innovations:\n")
  cat(paste("-", innovations), sep = "\n")
  
  cat("\nResult: 100+ countries, <6 weeks deployment")
}

covid_panel_response()
```

---

# Slide 146: Panel Documentation

## Maintaining Metadata

**Run Script: panel_metadata.R for system**

```{r panel-documentation, echo=FALSE}
documentation <- tribble(
  ~Document, ~Update_Frequency, ~Responsible, ~Critical,
  "Sample design", "Once", "Sampling team", "Yes",
  "Tracking log", "Each wave", "Field team", "Yes",
  "Weight calculation", "Each wave", "Estimation team", "Yes",
  "Attrition analysis", "Annual", "Quality team", "Yes",
  "Variable changes", "Each wave", "Data team", "Yes"
)

documentation %>%
  kable(caption = "Panel Documentation Requirements") %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  row_spec(which(documentation$Critical == "Yes"), 
           background = "#ffe6e6")
```

---

# Slide 147: Reporting Panel Results

## Communicating Dynamics

```{r panel-reporting, echo=TRUE}
# Key panel statistics to report
report_panel_stats <- function() {
  stats <- list(
    "Gross change vs net change",
    "Transition matrices",
    "Spell distributions",
    "Individual vs aggregate trends",
    "Confidence intervals accounting for correlation"
  )
  
  cat("Essential panel reporting:\n")
  cat(paste(1:5, stats, sep = ". "), sep = "\n")
  
  cat("\nRemember: Cross-sectional users need education!")
}

report_panel_stats()
```

---

# Slide 148: Future of Panel Surveys

## Harry's Vision

```{r panel-future, echo=FALSE}
future_trends <- tibble(
  Trend = c("Passive data integration", "AI-driven tracking",
            "Blockchain consent", "Continuous measurement",
            "Global panel networks"),
  Timeline = c("Now", "2 years", "3 years", "5 years", "10 years"),
  Impact = c("High", "High", "Medium", "Transformative", "High")
)

future_trends %>%
  gt() %>%
  tab_header(title = "Future of Panel Surveys") %>%
  tab_style(
    style = cell_fill(color = "lightblue"),
    locations = cells_body(
      columns = Impact,
      rows = Impact == "Transformative"
    )
  )
```

---

# Slide 149: Harry's Panel Success

## 4:45 PM - Victory Lap

```{r panel-success, echo=TRUE}
# Final panel design summary
final_panel_design <- function() {
  cat("SADC PANEL SURVEY DESIGN - APPROVED!\n")
  cat("=====================================\n")
  cat("Structure: 4-year rotating panel\n")
  cat("Sample: 5,000 households\n")
  cat("Rotation: 25% annual (EU-SILC standard)\n")
  cat("Tracking: GPS + phone + community\n")
  cat("Attrition: <15% annual (target)\n")
  cat("Weights: Longitudinal + cross-sectional\n")
  cat("Analysis: Fixed effects for causality\n")
  cat("Innovation: SMS between waves\n")
  cat("\nMinister: 'Exactly what we needed!'\n")
}

final_panel_design()
```

---

# Slide 150: Module 3 Summary

## Panel Survey Mastery Achieved

```{r module3-summary, echo=FALSE}
achievements <- tibble(
  Area = c("Design", "Implementation", "Analysis", "Innovation"),
  Competency = c("EU-SILC rotation mastered",
                 "Attrition strategies deployed",
                 "Fixed effects understood",
                 "Digital panels planned"),
  Next_Step = c("Launch pilot", "Train field teams",
                "Develop analysis plan", "Test SMS system")
)

achievements %>%
  gt() %>%
  tab_header(
    title = "Module 3: Panel Survey Competencies",
    subtitle = "Ready for longitudinal data collection"
  ) %>%
  tab_style(
    style = cell_fill(color = "lightgreen"),
    locations = cells_body(columns = everything())
  )
```

**Harry reflects:** "Panels are complex, but they reveal the truth about change. Now we can track poverty dynamics properly!"

---

class: inverse, center, middle

# END OF MODULE 3
## Next: Module 4 - Small Area Estimation

---
# MODULE 6: ADVANCED WEIGHTING TECHNIQUES
## Slides 151-200

---

# Slide 151: Complex Weighting Overview

## Beyond Basic Weights

```{r complex-weights-overview, echo=FALSE}
weight_methods <- tibble(
  Method = c("Base weights", "Non-response adjustment", "Post-stratification", 
             "Raking", "GREG calibration", "Ridge calibration"),
  Complexity = c("Simple", "Moderate", "Moderate", "Complex", "Complex", "Advanced"),
  Bias_Reduction = c("None", "Medium", "Medium", "High", "High", "Highest"),
  Variance_Increase = c("None", "Low", "Low", "Medium", "Medium", "Low")
)

weight_methods %>%
  gt() %>%
  tab_header(
    title = "Advanced Weighting Methods",
    subtitle = "Trade-offs in modern survey weighting"
  )
```

---

# Slide 152: Generalized Regression (GREG) Estimation

```{r greg-estimation, echo=TRUE}
# GREG Calibration Implementation with Error Handling
# =====================================================

greg_calibration <- function(design_weights, X, totals, 
                           method = "linear", bounds = c(0.1, 10)) {
  #' GREG Calibration of Survey Weights
  #' 
  #' @param design_weights Vector of initial design weights
  #' @param X Matrix of auxiliary variables (n x p)
  #' @param totals Vector of known population totals for auxiliary variables
  #' @param method Calibration method: "linear", "raking", or "truncated"
  #' @param bounds Vector of lower and upper bounds for weight ratios
  #' @return Vector of calibrated weights
  
  # Input validation
  n <- length(design_weights)
  if (!is.matrix(X)) X <- as.matrix(X)
  if (nrow(X) != n) stop("X must have same number of rows as length of weights")
  if (length(totals) != ncol(X)) stop("Number of totals must match columns in X")
  
  # Check for singularity issues
  weighted_X <- diag(sqrt(design_weights)) %*% X
  rank_X <- qr(weighted_X)$rank
  
  if (rank_X < ncol(X)) {
    warning("Auxiliary matrix is rank-deficient. Reducing dimensions...")
    # Use QR decomposition to identify linearly independent columns
    qr_decomp <- qr(weighted_X)
    pivot <- qr_decomp$pivot[1:rank_X]
    X <- X[, pivot, drop = FALSE]
    totals <- totals[pivot]
  }
  
  # Calculate calibration factors using different methods
  if (method == "linear") {
    # Linear calibration (standard GREG)
    g <- linear_calibration(design_weights, X, totals)
  } else if (method == "raking") {
    # Raking ratio calibration
    g <- raking_calibration(design_weights, X, totals)
  } else if (method == "truncated") {
    # Truncated linear calibration with bounds
    g <- truncated_calibration(design_weights, X, totals, bounds)
  } else {
    stop("Unknown calibration method")
  }
  
  # Calculate final weights
  calibrated_weights <- design_weights * g
  
  # Output diagnostics
  cat("\nGREG CALIBRATION RESULTS\n")
  cat("========================\n")
  cat("Method:", method, "\n")
  cat("Sample size:", n, "\n")
  cat("Number of constraints:", ncol(X), "\n")
  cat("Initial weight sum:", formatC(sum(design_weights), format = "f", digits = 2), "\n")
  cat("Calibrated weight sum:", formatC(sum(calibrated_weights), format = "f", digits = 2), "\n")
  cat("Weight ratio (g) range:", formatC(min(g), format = "f", digits = 3), 
      "to", formatC(max(g), format = "f", digits = 3), "\n")
  cat("CV of calibrated weights:", formatC(sd(calibrated_weights)/mean(calibrated_weights), 
                                          format = "f", digits = 3), "\n")
  
  # Check calibration constraints
  calibrated_totals <- t(X) %*% calibrated_weights
  constraint_check <- abs(calibrated_totals - totals) / totals
  cat("Max relative constraint error:", formatC(max(constraint_check) * 100, 
                                                format = "f", digits = 4), "%\n")
  
  # Return results as list with additional information
  result <- list(
    weights = calibrated_weights,
    g = g,
    initial_weights = design_weights,
    method = method,
    convergence = max(constraint_check) < 0.001,
    design_effect = sum(calibrated_weights^2) / (sum(calibrated_weights)^2 / n)
  )
  
  return(result)
}

# Linear calibration (standard GREG)
linear_calibration <- function(design_weights, X, totals) {
  n <- length(design_weights)
  
  # Calculate B matrix with regularization for numerical stability
  B <- t(X) %*% diag(design_weights) %*% X
  
  # Add small regularization term if needed
  eigen_vals <- eigen(B, only.values = TRUE)$values
  if (min(eigen_vals) < 1e-10) {
    lambda_reg <- 1e-8
    B <- B + diag(lambda_reg, ncol(B))
    warning("Added regularization to avoid singularity")
  }
  
  # Solve for Lagrange multipliers
  try({
    # Calculate constraint violation
    constraint_violation <- totals - t(X) %*% design_weights
    
    # Solve system
    lambda <- solve(B, constraint_violation)
    
    # Calculate g-weights
    g <- 1 + as.vector(X %*% lambda) / design_weights
    
  }, silent = FALSE)
  
  return(g)
}

# Raking ratio calibration (multiplicative)
raking_calibration <- function(design_weights, X, totals, max_iter = 50, tol = 1e-6) {
  n <- length(design_weights)
  p <- ncol(X)
  
  # Initialize g-weights
  g <- rep(1, n)
  
  # Iterative proportional fitting
  for (iter in 1:max_iter) {
    g_old <- g
    
    # Cycle through each constraint
    for (j in 1:p) {
      current_total <- sum(design_weights * g * X[, j])
      if (current_total > 0) {
        adjustment <- totals[j] / current_total
        g <- g * (1 + (adjustment - 1) * X[, j])
      }
    }
    
    # Check convergence
    if (max(abs(g - g_old)) < tol) {
      cat("Raking converged in", iter, "iterations\n")
      break
    }
  }
  
  if (iter == max_iter) {
    warning("Raking did not converge within maximum iterations")
  }
  
  return(g)
}

# Truncated linear calibration with bounds
truncated_calibration <- function(design_weights, X, totals, bounds = c(0.1, 10)) {
  # Start with linear calibration
  g <- linear_calibration(design_weights, X, totals)
  
  # Apply bounds
  g_truncated <- pmax(bounds[1], pmin(bounds[2], g))
  
  # Check if truncation occurred
  n_truncated <- sum(g != g_truncated)
  if (n_truncated > 0) {
    cat("Truncated", n_truncated, "weights to bounds [", 
        bounds[1], ",", bounds[2], "]\n")
  }
  
  return(g_truncated)
}

# =====================================================
# DEMONSTRATION WITH WORKING EXAMPLE
# =====================================================

# Create a more realistic example dataset
set.seed(123)
n <- 100  # Sample size

# Generate auxiliary variables that avoid singularity
age_group <- sample(1:3, n, replace = TRUE, prob = c(0.3, 0.4, 0.3))
gender <- sample(0:1, n, replace = TRUE)
region <- sample(1:2, n, replace = TRUE, prob = c(0.6, 0.4))

# Create design matrix with intercept
X <- model.matrix(~ factor(age_group) + gender + factor(region) - 1)

# Ensure full rank by checking
if (qr(X)$rank < ncol(X)) {
  # Remove redundant column if needed
  X <- X[, -ncol(X)]
}

# Initial design weights (could be inverse of selection probabilities)
design_weights <- runif(n, 80, 120)

# Known population totals (realistic values)
# These should sum to population size for each category
pop_size <- 10000
totals <- c(
  3000,  # age group 1
  4000,  # age group 2  
  3000,  # age group 3
  5200,  # males
  6000   # region 1
)

# Adjust totals to match the actual auxiliary matrix structure
totals <- totals[1:ncol(X)]

cat("\n========================================\n")
cat("EXAMPLE: GREG Calibration Demonstration\n")
cat("========================================\n\n")

# Run linear GREG calibration
result_linear <- greg_calibration(design_weights, X, totals, method = "linear")

# Run raking calibration
cat("\n")
result_raking <- greg_calibration(design_weights, X, totals, method = "raking")

# Run truncated calibration with bounds
cat("\n")
result_truncated <- greg_calibration(design_weights, X, totals, 
                                    method = "truncated", bounds = c(0.5, 3))

# =====================================================
# VISUALIZATION OF WEIGHT ADJUSTMENTS
# =====================================================

# Create comparison plot
par(mfrow = c(2, 2))

# Plot 1: Initial vs Calibrated Weights
plot(design_weights, result_linear$weights, 
     xlab = "Initial Weights", ylab = "Calibrated Weights",
     main = "Weight Transformation (Linear GREG)",
     pch = 19, col = rgb(0, 0, 1, 0.5))
abline(0, 1, col = "red", lty = 2)

# Plot 2: Distribution of g-weights
hist(result_linear$g, breaks = 20, 
     main = "Distribution of Calibration Factors (g)",
     xlab = "g-weight", col = "lightblue", border = "darkblue")
abline(v = 1, col = "red", lty = 2, lwd = 2)

# Plot 3: Comparison of methods
boxplot(list(Linear = result_linear$g,
             Raking = result_raking$g,
             Truncated = result_truncated$g),
        main = "Calibration Factors by Method",
        ylab = "g-weight", col = c("lightblue", "lightgreen", "lightyellow"))
abline(h = 1, col = "red", lty = 2)

# Plot 4: Weight distribution comparison
plot(density(design_weights), main = "Weight Distributions",
     xlab = "Weight", ylim = c(0, 0.015), lwd = 2)
lines(density(result_linear$weights), col = "blue", lwd = 2)
lines(density(result_raking$weights), col = "green", lwd = 2)
legend("topright", c("Initial", "Linear", "Raking"), 
       col = c("black", "blue", "green"), lwd = 2)

par(mfrow = c(1, 1))

# =====================================================
# PRACTICAL APPLICATION FUNCTION
# =====================================================

apply_greg_weights <- function(data, weight_col, auxiliary_vars, population_totals) {
  #' Apply GREG calibration to survey data
  #' 
  #' @param data Data frame containing survey data
  #' @param weight_col Name of the weight column
  #' @param auxiliary_vars Character vector of auxiliary variable names
  #' @param population_totals Named vector of population totals
  
  # Extract weights
  weights <- data[[weight_col]]
  
  # Create auxiliary matrix
  formula_str <- paste("~", paste(auxiliary_vars, collapse = " + "), "- 1")
  X <- model.matrix(as.formula(formula_str), data = data)
  
  # Apply calibration
  result <- greg_calibration(weights, X, population_totals)
  
  # Add calibrated weights to data
  data$calibrated_weight <- result$weights
  data$g_factor <- result$g
  
  return(data)
}

cat("\n========================================\n")
cat("GREG Calibration Implementation Complete\n")
cat("========================================\n")
cat("\nThe implementation includes:\n")
cat("1. Robust handling of singular matrices\n")
cat("2. Multiple calibration methods (linear, raking, truncated)\n")
cat("3. Comprehensive diagnostics and validation\n")
cat("4. Visualization of weight adjustments\n")
cat("5. Practical application function for real data\n")
```

---

# Slide 153: Raking (IPF) Algorithm

```{r raking-algorithm, echo=TRUE}
# Iterative Proportional Fitting
raking <- function(weights, margins, data, max_iter = 100, tol = 1e-6) {
  
  w <- weights
  converged <- FALSE
  iter <- 0
  
  while(!converged && iter < max_iter) {
    iter <- iter + 1
    w_old <- w
    
    # Adjust for each margin
    for(margin in names(margins)) {
      # Calculate current margin
      current <- tapply(w, data[[margin]], sum)
      
      # Adjustment factors
      factors <- margins[[margin]] / current
      
      # Apply factors
      w <- w * factors[data[[margin]]]
    }
    
    # Check convergence
    converged <- max(abs(w - w_old)) < tol
  }
  
  cat("RAKING RESULTS\n")
  cat("=============\n")
  cat("Iterations:", iter, "\n")
  cat("Converged:", converged, "\n")
  cat("Weight range:", range(w), "\n")
  cat("CV of weights:", sd(w)/mean(w), "\n")
  
  return(w)
}

# Example structure
cat("\nRaking algorithm implemented\n")
```

---

# Slide 154: Weight Trimming Strategies

```{r weight-trimming, echo=FALSE}
trimming_methods <- tibble(
  Method = c("Fixed bounds", "Percentile", "CV-based", "MSE-optimal", "Adaptive"),
  Rule = c("w âˆˆ [L, U]", "P5-P95", "CV < threshold", "Min(BiasÂ² + Var)", "Data-driven"),
  Bias = c("High", "Medium", "Low", "Optimal", "Low"),
  Stability = c("High", "High", "Medium", "Low", "High")
)

trimming_methods %>%
  gt() %>%
  tab_header(
    title = "Weight Trimming Methods",
    subtitle = "Managing extreme weights"
  ) %>%
  data_color(
    columns = Bias,
    colors = scales::col_factor(
      palette = c("Low" = "#d4edda", "Medium" = "#fff3cd", 
                  "High" = "#ffcccc", "Optimal" = "#e8f4f8"),
      domain = c("Low", "Medium", "High", "Optimal")
    )
  )
```

---

# Slide 155: Ridge Calibration

```{r ridge-calibration, echo=TRUE}
# Ridge calibration for multicollinearity
ridge_calibration <- function(weights, X, totals, ridge_param = 0.01) {
  
  n <- length(weights)
  p <- ncol(X)
  
  # Ridge modification to normal equations
  B_ridge <- t(X) %*% diag(weights) %*% X + ridge_param * diag(p)
  
  # Solve for lambda
  lambda <- solve(B_ridge) %*% (totals - t(X) %*% weights)
  
  # Calculate g-weights with ridge penalty
  g <- 1 + X %*% lambda / weights
  
  # Bounded g-weights
  g <- pmax(0.3, pmin(g, 3))
  
  final_weights <- weights * g
  
  cat("RIDGE CALIBRATION\n")
  cat("================\n")
  cat("Ridge parameter:", ridge_param, "\n")
  cat("Condition number improved by factor:", 10, "\n")
  cat("Max weight ratio:", max(g), "\n")
  cat("Min weight ratio:", min(g), "\n")
  
  return(final_weights)
}

# Demonstration
cat("\nRidge calibration reduces weight variability\n")
```

---

# Slide 156: Propensity Score Weighting

```{r propensity-weighting, echo=FALSE}
ps_workflow <- tibble(
  Step = 1:5,
  Process = c("Model response", "Calculate propensities", 
              "Create strata", "Adjust weights", "Check balance"),
  Method = c("Logistic regression", "Predicted probabilities",
             "Quintiles", "Inverse propensity", "SMD < 0.1"),
  Output = c("Response model", "P(respond)", "5 strata", 
             "Adjusted weights", "Balanced covariates")
)

ps_workflow %>%
  ggplot(aes(x = Step, y = 1)) +
  geom_tile(aes(fill = Step), height = 0.8) +
  geom_text(aes(label = Process), size = 4, fontface = "bold") +
  geom_text(aes(label = Method), y = 0.7, size = 3) +
  scale_fill_gradient(low = "#e8f4f8", high = "#0066cc") +
  labs(title = "Propensity Score Weighting Workflow",
       subtitle = "Non-response adjustment methodology") +
  theme_void() +
  theme(legend.position = "none",
        plot.title = element_text(size = 16, hjust = 0.5),
        plot.subtitle = element_text(size = 12, hjust = 0.5))
```

---

# Slide 157: Calibration on Margins

```{r calibration-margins, echo=TRUE}
# Calibrate on multiple margins simultaneously
calibrate_margins <- function(data, initial_weights) {
  
  # Define population margins
  margins <- list(
    age_sex = matrix(c(
      18000, 17000,  # 18-34 M/F
      22000, 21000,  # 35-54 M/F
      15000, 16000   # 55+ M/F
    ), ncol = 2),
    
    region = c(
      North = 35000,
      South = 42000,
      East = 28000,
      West = 31000
    ),
    
    education = c(
      Primary = 45000,
      Secondary = 55000,
      Tertiary = 36000
    )
  )
  
  cat("CALIBRATION TARGETS\n")
  cat("==================\n")
  cat("Age-Sex cells: 6\n")
  cat("Regions: 4\n")
  cat("Education: 3\n")
  cat("Total constraints: 13\n")
  cat("\nCalibration method: Minimum distance\n")
  cat("Distance function: Chi-square\n")
  
  # In practice, use survey::calibrate()
  
  return(list(margins = margins, n_constraints = 13))
}

cal_setup <- calibrate_margins(NULL, NULL)
```

---

# Slide 158: Composite Weighting

```{r composite-weighting, echo=FALSE}
composite_stages <- tibble(
  Stage = c("Design", "Coverage", "Unit NR", "Item NR", "Calibration", "Trimming"),
  Factor = c("1/Ï€", "Frame adjustment", "Response model", 
             "Imputation", "Population totals", "Bounds"),
  Effect = c(1.00, 1.05, 1.20, 1.03, 0.95, 1.02),
  Cumulative = cumprod(c(1.00, 1.05, 1.20, 1.03, 0.95, 1.02))
) %>%
  mutate(CV = c(0.8, 0.9, 1.2, 1.3, 1.1, 1.0))

composite_stages %>%
  ggplot(aes(x = Stage, y = Cumulative)) +
  geom_line(group = 1, color = "#0066cc", size = 2) +
  geom_point(size = 4, color = "#0066cc") +
  geom_text(aes(label = round(Cumulative, 2)), vjust = -1) +
  labs(title = "Composite Weight Construction",
       subtitle = "Cumulative effect of adjustments",
       y = "Weight Factor") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

---

# Slide 159: Variance Estimation with Weights

```{r variance-weights, echo=TRUE}
# Variance estimation accounting for weight adjustments
variance_with_weights <- function(y, weights, strata, clusters) {
  
  # Taylor linearization for weighted estimates
  
  # Step 1: Calculate weighted mean
  y_bar <- sum(y * weights) / sum(weights)
  
  # Step 2: Calculate linearized variable
  z <- weights * (y - y_bar)
  
  # Step 3: Variance of linearized variable
  # Account for stratification and clustering
  
  var_components <- list(
    sampling = "Design-based variance",
    weighting = "Weight variation effect",
    calibration = "Calibration variance"
  )
  
  # Approximate variance inflation from weighting
  weight_cv <- sd(weights) / mean(weights)
  uw_effect <- 1 + weight_cv^2  # Unequal weighting effect
  
  cat("VARIANCE COMPONENTS\n")
  cat("==================\n")
  cat("Weight CV:", round(weight_cv, 2), "\n")
  cat("UW effect:", round(uw_effect, 2), "\n")
  cat("Effective sample size loss:", round((1/uw_effect)*100), "%\n")
  
  return(list(cv = weight_cv, uw_effect = uw_effect))
}

var_analysis <- variance_with_weights(rnorm(100), runif(100, 50, 150), NULL, NULL)
```

---

# Slide 160: Multi-Phase Weighting

```{r multiphase-weighting, echo=FALSE}
multiphase <- tibble(
  Phase = c("Phase 1", "Phase 2", "Phase 3"),
  Sample_Size = c(10000, 2000, 500),
  Variables = c("Basic demographics", "+ Income", "+ Detailed health"),
  Weight_Component = c("Ï€â‚", "Ï€â‚‚|â‚", "Ï€â‚ƒ|â‚‚"),
  Purpose = c("Screening", "Core measurement", "Detailed follow-up")
)

multiphase %>%
  gt() %>%
  tab_header(
    title = "Multi-Phase Survey Weighting",
    subtitle = "Sequential sampling with increasing detail"
  ) %>%
  tab_style(
    style = cell_fill(color = "#e8f4f8"),
    locations = cells_body(columns = Sample_Size)
  )
```

---

class: inverse, center, middle

# MODULE 7: MODERN DATA COLLECTION
## Slides 161-200

---

# Slide 161: CAPI/CATI Systems

## Computer-Assisted Interviewing

```{r capi-systems, echo=TRUE}
# CAPI system requirements
capi_system_design <- function() {
  
  requirements <- list(
    hardware = c(
      "Tablets with 8+ hour battery",
      "GPS capability",
      "Camera for photos",
      "Offline capability"
    ),
    
    software = c(
      "Survey Solutions / ODK / SurveyCTO",
      "Real-time validation",
      "Skip patterns",
      "Multi-language support"
    ),
    
    data_flow = c(
      "Encrypted transmission",
      "Automatic sync",
      "Version control",
      "Audit trails"
    )
  )
  
  cat("CAPI IMPLEMENTATION FRAMEWORK\n")
  cat("============================\n\n")
  
  for(component in names(requirements)) {
    cat(toupper(component), ":\n")
    cat(paste("-", requirements[[component]]), sep = "\n")
    cat("\n")
  }
  
  cat("Cost-benefit: 40% reduction after 18 months\n")
}

capi_system_design()
```

---

# Slide 162: Web Survey Design

```{r web-survey, echo=FALSE}
web_considerations <- tibble(
  Aspect = c("Device optimization", "Question types", "Progress indicators",
             "Save and continue", "Validation", "Incentives"),
  Best_Practice = c("Responsive design", "Varied formats", "Show completion %",
                    "Auto-save", "Real-time checks", "Digital payments"),
  Common_Error = c("Desktop only", "All radio buttons", "No progress shown",
                   "No save option", "Submit-time only", "Mail checks"),
  Impact = c("30% mobile users", "Lower engagement", "Higher break-off",
             "Lost responses", "Poor data quality", "Delayed participation")
)

web_considerations %>%
  gt() %>%
  tab_header(
    title = "Web Survey Design Principles",
    subtitle = "Maximizing online response quality"
  )
```

---

# Slide 163: Mixed-Mode Challenges

```{r mixed-mode, echo=TRUE}
# Handle mode effects in mixed-mode surveys
adjust_mode_effects <- function(data, mode_var) {
  
  # Identify mode effects
  modes <- unique(data[[mode_var]])
  
  cat("MODE EFFECT ADJUSTMENT\n")
  cat("=====================\n\n")
  
  # Common mode differences
  mode_biases <- list(
    "F2F" = list(social_desirability = +0.15, item_nr = -0.05),
    "Phone" = list(social_desirability = +0.10, item_nr = +0.10),
    "Web" = list(social_desirability = -0.05, item_nr = +0.15),
    "Paper" = list(social_desirability = 0, item_nr = +0.20)
  )
  
  cat("Detected modes:", paste(modes, collapse = ", "), "\n\n")
  
  cat("Adjustment strategies:\n")
  cat("1. Propensity score matching\n")
  cat("2. Statistical adjustment models\n")
  cat("3. Calibration to common standard\n")
  cat("4. Separate analysis by mode\n")
  
  return(mode_biases)
}

mode_analysis <- adjust_mode_effects(data.frame(mode = c("F2F", "Web")), "mode")
```

---

# Slide 164: Paradata Collection

```{r paradata-collection, echo=FALSE}
paradata_types <- tibble(
  Type = c("Contact attempts", "Interview timing", "Item timing",
           "Navigation", "Changes", "Device info"),
  Example = c("3 attempts before success", "Started 14:30, ended 15:15",
              "Q10: 180 seconds", "Back button 5 times",
              "Income changed 3 times", "Android 11, Chrome"),
  Use = c("Response analysis", "Burden assessment", "Difficulty flags",
          "Questionnaire flow", "Quality indicators", "Technical issues"),
  Storage = c("Contact table", "Session log", "Timestamp array",
              "Navigation log", "Audit table", "Device table")
)

paradata_types %>%
  gt() %>%
  tab_header(
    title = "Paradata Collection Framework",
    subtitle = "Meta-data about the survey process"
  ) %>%
  tab_style(
    style = cell_fill(color = "#fff3cd"),
    locations = cells_body(
      columns = Use,
      rows = Use %in% c("Quality indicators", "Difficulty flags")
    )
  )
```

---

# Slide 165: Real-Time Monitoring

```{r realtime-monitoring, echo=TRUE}
# Real-time field monitoring system
monitor_field_progress <- function(stream_data) {
  
  # Calculate real-time metrics
  metrics <- list(
    completion_rate = mean(stream_data$completed),
    avg_duration = mean(stream_data$duration[stream_data$completed]),
    refusal_rate = mean(stream_data$outcome == "refused"),
    by_interviewer = aggregate(completed ~ interviewer, stream_data, mean)
  )
  
  # Alert thresholds
  alerts <- character()
  
  if(metrics$completion_rate < 0.70) {
    alerts <- c(alerts, "âš ï¸ Low completion rate")
  }
  
  if(metrics$avg_duration > 60) {
    alerts <- c(alerts, "âš ï¸ Interviews taking too long")
  }
  
  if(any(metrics$by_interviewer$completed < 0.50)) {
    alerts <- c(alerts, "âš ï¸ Some interviewers struggling")
  }
  
  cat("REAL-TIME FIELD MONITOR\n")
  cat("======================\n")
  cat("Time:", Sys.time(), "\n\n")
  cat("Completion:", round(metrics$completion_rate * 100), "%\n")
  cat("Avg duration:", round(metrics$avg_duration), "min\n")
  cat("Active interviewers:", nrow(metrics$by_interviewer), "\n")
  
  if(length(alerts) > 0) {
    cat("\nALERTS:\n")
    cat(paste(alerts), sep = "\n")
  }
  
  return(metrics)
}

# Simulate monitoring
test_data <- data.frame(
  completed = rbinom(100, 1, 0.75),
  duration = rnorm(100, 45, 15),
  outcome = sample(c("complete", "refused", "not_home"), 100, 
                   prob = c(0.7, 0.1, 0.2), replace = TRUE),
  interviewer = sample(1:10, 100, replace = TRUE)
)

monitoring <- monitor_field_progress(test_data)
```

---

# Slide 166: GPS and Geospatial Data

```{r gps-data, echo=FALSE}
gps_quality <- tibble(
  Check = c("Location accuracy", "Timestamp validity", "Speed check",
            "Geofencing", "Cluster verification"),
  Threshold = c("< 10m", "Within interview time", "< 120 km/h",
                "Within EA boundary", "All HH in cluster"),
  Action = c("Recapture if > 20m", "Flag inconsistency", "Possible falsification",
             "Wrong location alert", "Check sampling"),
  Implementation = c("Android location API", "System time", "Calculate from points",
                     "Polygon contains", "Convex hull check")
)

gps_quality %>%
  gt() %>%
  tab_header(
    title = "GPS Data Quality Framework",
    subtitle = "Ensuring spatial data integrity"
  )
```

---

# Slide 167: Audio Recording for Quality

```{r audio-recording, echo=TRUE}
# Audio audit implementation
audio_quality_control <- function(interview_length, sample_rate = 0.10) {
  
  cat("AUDIO AUDIT SYSTEM\n")
  cat("==================\n\n")
  
  # Sampling strategy
  segments_to_record <- c(
    "Consent" = "First 2 minutes",
    "Random" = "3 random 1-minute segments",
    "Sensitive" = "Income and health sections",
    "Closing" = "Last minute"
  )
  
  # Quality checks
  checks <- c(
    "Proper introduction given",
    "Questions read as written",
    "Appropriate probing",
    "No leading/coaching",
    "Professional conduct"
  )
  
  cat("Recording strategy:\n")
  for(segment in names(segments_to_record)) {
    cat("-", segment, ":", segments_to_record[[segment]], "\n")
  }
  
  cat("\nQuality dimensions checked:\n")
  cat(paste("-", checks), sep = "\n")
  
  cat("\nSample rate:", sample_rate * 100, "% of interviews\n")
  cat("Storage required:", round(interview_length * sample_rate * 0.5), "MB/interview\n")
  
  return(list(segments = segments_to_record, checks = checks))
}

audio_setup <- audio_quality_control(45)
```

---

# Slide 168: Adaptive Questionnaires

```{r adaptive-questionnaire, echo=FALSE}
adaptive_flow <- tibble(
  Stage = c("Screener", "Core", "Branch A", "Branch B", "Follow-up"),
  Condition = c("All", "All", "If employed", "If unemployed", "If willing"),
  Questions = c(5, 20, 15, 10, 25),
  Skip_Rate = c(0, 0, 0.4, 0.6, 0.7)
) %>%
  mutate(
    Effective_Length = Questions * (1 - Skip_Rate),
    Time_Minutes = Effective_Length * 0.5
  )

adaptive_flow %>%
  ggplot(aes(x = Stage, y = Effective_Length)) +
  geom_col(fill = "#0066cc", alpha = 0.7) +
  geom_text(aes(label = round(Effective_Length)), vjust = -0.5) +
  labs(title = "Adaptive Questionnaire Flow",
       subtitle = "Questions asked depends on responses",
       y = "Average Questions Asked") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

---

# Slide 169: Machine Learning for Data Collection

```{r ml-datacollection, echo=TRUE}
# ML-enhanced data collection
ml_collection_enhancement <- function() {
  
  applications <- list(
    
    # Predictive calling
    best_contact_time = "Random Forest: 78% accuracy",
    
    # Interviewer assignment
    interviewer_matching = "Clustering: 15% response rate improvement",
    
    # Dynamic questionnaire
    question_ordering = "Reinforcement learning: Reduced break-off",
    
    # Quality prediction
    falsification_detection = "Anomaly detection: 92% precision",
    
    # Response prediction
    propensity_scoring = "XGBoost: AUC = 0.85"
  )
  
  cat("ML IN DATA COLLECTION\n")
  cat("====================\n\n")
  
  for(app in names(applications)) {
    cat(gsub("_", " ", toupper(app)), "\n")
    cat("  ", applications[[app]], "\n\n")
  }
  
  cat("Implementation note: Start with simple models, iterate\n")
}

ml_collection_enhancement()
```

---

# Slide 170: Smartphone Surveys

```{r smartphone-surveys, echo=FALSE}
smartphone_features <- tibble(
  Feature = c("Push notifications", "App-based", "Sensor data",
              "Photo capture", "Voice input", "Offline mode"),
  Benefit = c("Timely reminders", "Better UX", "Objective measures",
              "Visual validation", "Easier open-ends", "No connection needed"),
  Challenge = c("Opt-in required", "Installation barrier", "Privacy concerns",
                "Storage/bandwidth", "Transcription accuracy", "Sync complexity"),
  Adoption = c("High", "Medium", "Low", "Medium", "Low", "High")
)

smartphone_features %>%
  gt() %>%
  tab_header(
    title = "Smartphone Survey Capabilities",
    subtitle = "Leveraging mobile technology"
  ) %>%
  data_color(
    columns = Adoption,
    colors = scales::col_factor(
      palette = c("High" = "#d4edda", "Medium" = "#fff3cd", "Low" = "#ffcccc"),
      domain = c("High", "Medium", "Low")
    )
  )
```

---

class: inverse, center, middle

# MODULE 8: TOTAL SURVEY ERROR
## Slides 171-200

---

# Slide 171: TSE Framework Overview

```{r tse-framework2, echo=FALSE}
tse_components <- tibble(
  Error_Type = c("Coverage", "Sampling", "Nonresponse", "Measurement", "Processing"),
  Category = c("Representation", "Representation", "Representation", 
               "Measurement", "Measurement"),
  Magnitude = c(3, 2, 4, 3, 1),
  Reducible = c("Partially", "Yes", "Partially", "Yes", "Yes")
) %>%
  mutate(Color = case_when(
    Category == "Representation" ~ "#0066cc",
    TRUE ~ "#ff6b35"
  ))

tse_components %>%
  ggplot(aes(x = Error_Type, y = Magnitude, fill = Category)) +
  geom_col() +
  geom_text(aes(label = Magnitude), vjust = -0.5) +
  scale_fill_manual(values = c("Representation" = "#0066cc", 
                               "Measurement" = "#ff6b35")) +
  labs(title = "Total Survey Error Components",
       subtitle = "Relative magnitude in typical household survey",
       y = "Error Magnitude (relative scale)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

---

# Slide 172: Coverage Error Assessment

```{r coverage-error, echo=TRUE}
# Assess and adjust for coverage error
assess_coverage_error <- function(frame, target_pop) {
  
  # Types of coverage problems
  coverage_issues <- list(
    undercoverage = list(
      homeless = "No fixed address",
      new_construction = "Built after frame creation",
      informal_settlements = "Not in official records"
    ),
    
    overcoverage = list(
      duplicates = "Multiple listings",
      out_of_scope = "Businesses in HH frame",
      movers = "No longer in population"
    )
  )
  
  # Coverage rate calculation
  frame_count <- 95000
  population_count <- 100000
  coverage_rate <- frame_count / population_count
  
  cat("COVERAGE ERROR ASSESSMENT\n")
  cat("========================\n")
  cat("Frame coverage:", round(coverage_rate * 100, 1), "%\n")
  cat("Undercoverage:", round((1 - coverage_rate) * 100, 1), "%\n\n")
  
  cat("Main sources of undercoverage:\n")
  for(source in names(coverage_issues$undercoverage)) {
    cat("-", source, ":", coverage_issues$undercoverage[[source]], "\n")
  }
  
  cat("\nMitigation: Multiple frame approach\n")
  
  return(coverage_rate)
}

coverage <- assess_coverage_error(NULL, NULL)
```

---

# Slide 173: Measurement Error Sources

```{r measurement-error, echo=FALSE}
measurement_sources <- tibble(
  Source = c("Question wording", "Response scales", "Social desirability",
             "Recall error", "Interviewer effects", "Mode effects"),
  Example = c("Double-barreled questions", "Unbalanced scales", 
              "Income underreporting", "Forgetting doctor visits",
              "Leading probes", "Phone vs face-to-face"),
  Mitigation = c("Cognitive testing", "Pretesting scales", "Validation questions",
                 "Aided recall", "Training & monitoring", "Mode adjustment"),
  Impact = c("Medium", "Low", "High", "High", "Medium", "Medium")
)

measurement_sources %>%
  gt() %>%
  tab_header(
    title = "Measurement Error Sources",
    subtitle = "Common problems and solutions"
  ) %>%
  data_color(
    columns = Impact,
    colors = scales::col_factor(
      palette = c("Low" = "#d4edda", "Medium" = "#fff3cd", "High" = "#ffcccc"),
      domain = c("Low", "Medium", "High")
    )
  )
```

---

# Slide 174: Nonresponse Bias Analysis

```{r nonresponse-bias, echo=TRUE}
# Analyze nonresponse bias
analyze_nonresponse_bias <- function(respondents, nonrespondents_partial) {
  
  # Compare characteristics where available
  cat("NONRESPONSE BIAS ANALYSIS\n")
  cat("========================\n\n")
  
  # Simulated comparison
  comparisons <- data.frame(
    Variable = c("Urban", "Age", "Income_proxy"),
    Respondents = c(0.45, 42, 3.2),
    Nonrespondents = c(0.52, 38, 3.8),
    Difference = c(0.07, -4, 0.6),
    Std_Diff = c(0.14, -0.22, 0.31)
  )
  
  print(comparisons)
  
  cat("\nBias indicators:\n")
  cat("- Response rate: 68%\n")
  cat("- R-indicator: 0.72\n")
  cat("- CV of response propensities: 0.38\n")
  
  # Bias formula: Bias = (1-r) * (Y_r - Y_nr)
  response_rate <- 0.68
  bias_estimate <- (1 - response_rate) * 0.31  # Standardized difference
  
  cat("\nEstimated bias (standardized):", round(bias_estimate, 3), "\n")
  cat("Action: Apply nonresponse weighting\n")
  
  return(bias_estimate)
}

bias <- analyze_nonresponse_bias(NULL, NULL)
```

---

# Slide 175: Processing Error Control

```{r processing-error, echo=FALSE}
processing_controls <- tibble(
  Stage = c("Data entry", "Coding", "Editing", "Imputation", "Weighting", "Tabulation"),
  Error_Type = c("Keying errors", "Misclassification", "Over-editing",
                 "Model bias", "Calculation error", "Rounding"),
  Control = c("Double entry", "Verification sample", "Edit limits",
              "Multiple methods", "QC checks", "Exact calculations"),
  Residual_Rate = c("0.1%", "2%", "1%", "3%", "0.01%", "0.001%")
)

processing_controls %>%
  gt() %>%
  tab_header(
    title = "Processing Error Controls",
    subtitle = "Quality assurance at each stage"
  ) %>%
  tab_style(
    style = cell_fill(color = "#d4edda"),
    locations = cells_body(
      columns = Residual_Rate,
      rows = as.numeric(gsub("%", "", Residual_Rate)) < 1
    )
  )
```

---

# Slide 176: TSE Optimization

```{r tse-optimization, echo=TRUE}
# Optimize survey design for minimum TSE
optimize_tse <- function(budget, quality_params) {
  
  # Components and their cost-quality relationships
  components <- list(
    sample_size = list(cost_per = 50, error_reduction = "sqrt(n)"),
    nonresponse = list(cost_per = 20, error_reduction = "log(effort)"),
    measurement = list(cost_per = 30, error_reduction = "linear"),
    processing = list(cost_per = 10, error_reduction = "threshold")
  )
  
  cat("TSE OPTIMIZATION\n")
  cat("===============\n")
  cat("Budget: $", budget, "\n\n")
  
  # Optimal allocation (simplified)
  allocation <- c(
    sample_size = 0.40,
    nonresponse = 0.25,
    measurement = 0.25,
    processing = 0.10
  )
  
  cat("Optimal allocation:\n")
  for(comp in names(allocation)) {
    cat(sprintf("  %s: $%.0f (%.0f%%)\n",
                comp, budget * allocation[[comp]],
                allocation[[comp]] * 100))
  }
  
  cat("\nExpected TSE reduction: 35%\n")
  
  return(allocation)
}

optimal_tse <- optimize_tse(100000, NULL)
```

---

# Slide 177: Error Documentation

```{r error-documentation, echo=FALSE}
error_reporting <- tibble(
  Section = c("Coverage", "Sampling", "Nonresponse", "Measurement", "Processing", "Overall"),
  Metric = c("Coverage rate", "Design effect", "Response rate", 
             "Reliability", "Edit rate", "CV"),
  Value = c("94%", "1.8", "72%", "0.85", "12%", "5.2%"),
  Standard = c(">95%", "<2.0", ">80%", ">0.80", "<15%", "<10%"),
  Status = c("âš ï¸", "âœ“", "âš ï¸", "âœ“", "âœ“", "âœ“")
)

error_reporting %>%
  gt() %>%
  tab_header(
    title = "Survey Quality Report Card",
    subtitle = "TSE component assessment"
  ) %>%
  tab_style(
    style = cell_fill(color = "#ffcccc"),
    locations = cells_body(
      columns = Status,
      rows = Status == "âš ï¸"
    )
  )
```

---

class: inverse, center, middle

# MODULE 9: QUESTIONNAIRE DESIGN
## Slides 181-220

---

# Slide 181: Cognitive Response Process

```{r cognitive-process, echo=FALSE}
cognitive_model <- tibble(
  Stage = c("Comprehension", "Retrieval", "Judgment", "Response"),
  Process = c("Understand question", "Access memory", "Formulate answer", "Map to scale"),
  Error_Risk = c("Misunderstanding", "Forgetting", "Estimation error", "Scale mismatch"),
  Testing = c("Paraphrasing", "Think-aloud", "Probing", "Response distribution")
) %>%
  mutate(
    Duration_sec = c(3, 5, 4, 2),
    Cognitive_Load = c("Medium", "High", "High", "Low")
  )

cognitive_model %>%
  gt() %>%
  tab_header(
    title = "Cognitive Response Model",
    subtitle = "How respondents answer survey questions"
  )
```

---

# Slide 182: Question Wording Principles

```{r question-wording, echo=TRUE}
# Evaluate question quality
evaluate_question <- function(question_text) {
  
  issues <- list()
  
  # Check for common problems
  if(grepl(" and | or ", question_text, ignore.case = TRUE)) {
    issues$double_barreled <- "Contains 'and' or 'or' - might be double-barreled"
  }
  
  if(nchar(question_text) > 100) {
    issues$length <- "Too long - consider simplifying"
  }
  
  if(grepl("not|never|none", question_text, ignore.case = TRUE)) {
    issues$negatives <- "Contains negatives - can confuse respondents"
  }
  
  technical_terms <- c("utilize", "implement", "prioritize", "optimize")
  if(any(sapply(technical_terms, grepl, question_text, ignore.case = TRUE))) {
    issues$jargon <- "Contains jargon - use simpler words"
  }
  
  cat("QUESTION EVALUATION\n")
  cat("==================\n")
  cat("Question:", question_text, "\n\n")
  
  if(length(issues) > 0) {
    cat("Issues found:\n")
    for(issue in issues) {
      cat("âš ï¸", issue, "\n")
    }
  } else {
    cat("âœ“ No major issues detected\n")
  }
  
  return(issues)
}

evaluate_question("Do you utilize health services and educational facilities?")
```

---

# Slide 183: Response Scale Design

```{r response-scales, echo=FALSE}
scale_comparison <- tibble(
  Scale_Type = c("Dichotomous", "Likert 5-point", "Likert 7-point",
                 "Semantic differential", "Visual analog", "Ranking"),
  Example = c("Yes/No", "Strongly disagree...Strongly agree", "1-7 rating",
              "Bad ------- Good", "0-100 slider", "Order 1st, 2nd, 3rd"),
  Best_For = c("Factual", "Attitudes", "Fine discrimination",
                "Bipolar concepts", "Continuous", "Priorities"),
  Reliability = c("High", "Good", "Good", "Moderate", "Variable", "Good"),
  Analysis = c("Simple", "Ordinal", "Interval-like", "Interval", "Continuous", "Complex")
)

scale_comparison %>%
  gt() %>%
  tab_header(
    title = "Survey Response Scales",
    subtitle = "Choosing the right measurement approach"
  )
```

---

# Slide 184: Sensitive Questions

```{r sensitive-questions, echo=TRUE}
# Handle sensitive topics
design_sensitive_questions <- function(topic) {
  
  techniques <- list(
    indirect = "Ask about 'people like you' instead of 'you'",
    
    loading = "Many people have experienced X. Have you?",
    
    ranges = "Use categories instead of exact values",
    
    randomized_response = "Flip a coin, answer A if heads, truth if tails",
    
    placement = "Put after rapport built, before demographics",
    
    validation = "Include consistency checks"
  )
  
  cat("SENSITIVE QUESTION DESIGN\n")
  cat("========================\n")
  cat("Topic:", topic, "\n\n")
  
  cat("Recommended techniques:\n")
  for(tech in names(techniques)) {
    cat(sprintf("  %s:\n    %s\n", 
                toupper(gsub("_", " ", tech)), 
                techniques[[tech]]))
  }
  
  cat("\nAlways provide:\n")
  cat("- 'Prefer not to answer' option\n")
  cat("- Clear confidentiality statement\n")
  cat("- Explanation of why needed\n")
}

design_sensitive_questions("Income")
```

---

# Slide 185: Matrix Questions

```{r matrix-questions, echo=FALSE}
matrix_guidelines <- tibble(
  Aspect = c("Grid size", "Item similarity", "Mobile display",
             "Straight-lining", "Cognitive burden"),
  Guideline = c("Max 5x7", "All same construct", "Avoid or adapt",
                "Add attention checks", "Limit to 1-2 per survey"),
  Reason = c("Prevents fatigue", "Maintains focus", "Screen size",
             "Detect satisficing", "Reduce load"),
  Alternative = c("Break into sections", "Separate questions", "Card sort",
                  "Vary response direction", "Single items")
)

matrix_guidelines %>%
  gt() %>%
  tab_header(
    title = "Matrix Question Guidelines",
    subtitle = "When and how to use grid questions"
  ) %>%
  tab_style(
    style = cell_fill(color = "#fff3cd"),
    locations = cells_body(
      columns = Aspect,
      rows = Aspect %in% c("Straight-lining", "Cognitive burden")
    )
  )
```

---

# Slide 186: Skip Patterns and Routing

```{r skip-patterns, echo=TRUE}
# Implement skip logic
implement_skip_logic <- function() {
  
  routing_rules <- list(
    list(
      condition = "employment_status == 'Employed'",
      skip_to = "employment_section",
      skip_over = c("job_search", "unemployment_duration")
    ),
    
    list(
      condition = "age < 18",
      skip_to = "youth_section",
      skip_over = c("marriage", "retirement", "pension")
    ),
    
    list(
      condition = "has_children == 'No'",
      skip_over = c("child_education", "childcare_costs", "parenting")
    )
  )
  
  cat("SKIP PATTERN IMPLEMENTATION\n")
  cat("==========================\n\n")
  
  for(i in 1:length(routing_rules)) {
    rule <- routing_rules[[i]]
    cat(sprintf("Rule %d:\n", i))
    cat("  IF:", rule$condition, "\n")
    if(!is.null(rule$skip_to)) {
      cat("  THEN GO TO:", rule$skip_to, "\n")
    }
    if(!is.null(rule$skip_over)) {
      cat("  SKIP:", paste(rule$skip_over, collapse = ", "), "\n")
    }
    cat("\n")
  }
  
  cat("Testing: Verify all paths through questionnaire\n")
}

implement_skip_logic()
```

---

# Slide 187: Questionnaire Translation

```{r translation, echo=FALSE}
translation_process <- tibble(
  Step = 1:6,
  Activity = c("Forward translation", "Review", "Back translation",
               "Reconciliation", "Cognitive testing", "Finalization"),
  Who = c("2 translators", "Committee", "Independent translator",
          "Team meeting", "Target population", "Sign-off"),
  Output = c("2 versions", "Merged version", "English back",
             "Final draft", "Issues list", "Official version"),
  Days = c(5, 2, 3, 2, 5, 1)
)

translation_process %>%
  ggplot(aes(x = Step, y = Days)) +
  geom_col(fill = "#0066cc", alpha = 0.7) +
  geom_text(aes(label = Activity), angle = 45, hjust = 0, vjust = 0) +
  labs(title = "Survey Translation Protocol",
       subtitle = "18-day professional translation process",
       y = "Days Required") +
  theme_minimal()
```

---

# Slide 188: Pretesting Methods

```{r pretesting, echo=TRUE}
# Pretest protocol
conduct_pretest <- function(n_interviews = 30) {
  
  methods <- list(
    cognitive = list(
      n = 8,
      technique = "Think-aloud and probing",
      output = "Comprehension issues"
    ),
    
    pilot = list(
      n = n_interviews,
      technique = "Full administration",
      output = "Timing and flow issues"
    ),
    
    expert_review = list(
      n = 5,
      technique = "Questionnaire appraisal",
      output = "Technical problems"
    ),
    
    focus_groups = list(
      n = 12,
      technique = "Group discussion",
      output = "Cultural issues"
    )
  )
  
  cat("PRETESTING PROTOCOL\n")
  cat("==================\n\n")
  
  total_n <- 0
  for(method in names(methods)) {
    m <- methods[[method]]
    cat(toupper(gsub("_", " ", method)), "\n")
    cat("  Sample:", m$n, "\n")
    cat("  Method:", m$technique, "\n")
    cat("  Identifies:", m$output, "\n\n")
    total_n <- total_n + m$n
  }
  
  cat("Total pretest sample:", total_n, "\n")
  cat("Timeline: 3 weeks\n")
}

conduct_pretest()
```

---

# Slide 189: Questionnaire Length Optimization

```{r length-optimization, echo=FALSE}
length_impact <- tibble(
  Length_Minutes = c(10, 20, 30, 45, 60),
  Completion_Rate = c(95, 88, 78, 65, 48),
  Data_Quality = c(95, 92, 85, 75, 60),
  Respondent_Satisfaction = c(90, 80, 65, 40, 20),
  Cost_Per_Complete = c(30, 40, 55, 80, 120)
)

length_impact %>%
  pivot_longer(cols = -Length_Minutes, names_to = "Metric", values_to = "Value") %>%
  ggplot(aes(x = Length_Minutes, y = Value, color = Metric)) +
  geom_line(size = 1.5) +
  geom_point(size = 3) +
  geom_vline(xintercept = 30, linetype = "dashed", alpha = 0.5) +
  labs(title = "Interview Length Impact",
       subtitle = "30 minutes is typically optimal",
       x = "Interview Length (minutes)",
       y = "Performance (%)") +
  theme_minimal()
```

---

# Slide 190: Visual Design Elements

```{r visual-design, echo=TRUE}
# Visual design guidelines
apply_visual_design <- function(mode = "web") {
  
  design_elements <- list(
    web = list(
      font = "14pt sans-serif",
      spacing = "1.5 line height",
      progress = "Progress bar",
      images = "Support comprehension",
      color = "High contrast",
      mobile = "Responsive design"
    ),
    
    paper = list(
      font = "12pt serif",
      spacing = "Clear sections",
      progress = "Page X of Y",
      images = "Minimal to save cost",
      color = "Black and white",
      layout = "Portrait A4"
    ),
    
    capi = list(
      font = "16pt for tablets",
      spacing = "One question per screen",
      progress = "Breadcrumbs",
      images = "Show cards built in",
      color = "Dark mode option",
      gestures = "Swipe navigation"
    )
  )
  
  cat("VISUAL DESIGN:", toupper(mode), "\n")
  cat("====================\n")
  
  elements <- design_elements[[mode]]
  for(element in names(elements)) {
    cat(sprintf("  %s: %s\n", element, elements[[element]]))
  }
}

apply_visual_design("web")
```

---

class: inverse, center, middle

# MODULE 10: VARIANCE ESTIMATION
## Slides 191-220

---

# Slide 191: Complex Variance Estimation

```{r complex-variance, echo=FALSE}
variance_methods <- tibble(
  Method = c("SRS formula", "Taylor linearization", "Jackknife",
             "Bootstrap", "BRR", "Fay's BRR"),
  Complexity = c("Simple", "Moderate", "Moderate", "High", "Moderate", "High"),
  Handles = c("SRS only", "Most designs", "Most designs",
              "Any design", "2 PSU/stratum", "2 PSU/stratum"),
  Software = c("Any", "survey, Stata", "survey, Stata",
               "survey, boot", "survey", "survey")
)

variance_methods %>%
  gt() %>%
  tab_header(
    title = "Variance Estimation Methods",
    subtitle = "For complex survey designs"
  )
```

---

# Slide 192: Taylor Linearization

```{r taylor-linearization, echo=TRUE}
# Taylor linearization for ratio estimator
taylor_variance_ratio <- function(y, x, weights, clusters, strata) {
  
  # Ratio estimator: R = Y_total / X_total
  
  # Step 1: Calculate totals
  Y_hat <- sum(y * weights)
  X_hat <- sum(x * weights)
  R_hat <- Y_hat / X_hat
  
  # Step 2: Linearized variable
  z <- weights * (y - R_hat * x)
  
  # Step 3: Variance of linearized variable
  # (simplified - actual requires accounting for design)
  
  cat("TAYLOR LINEARIZATION\n")
  cat("===================\n")
  cat("Ratio estimate:", round(R_hat, 4), "\n")
  
  # Approximate variance components
  var_components <- list(
    sampling = "Within-stratum variance",
    between = "Between-stratum variance",
    finite_pop = "Finite population correction"
  )
  
  cat("\nVariance components:\n")
  for(comp in names(var_components)) {
    cat("-", var_components[[comp]], "\n")
  }
  
  # Design effect approximation
  deff <- 1.8
  se <- sqrt(var(z) / length(z)) * sqrt(deff)
  
  cat("\nStandard error:", round(se, 4), "\n")
  cat("CV:", round(se / R_hat * 100, 1), "%\n")
  
  return(list(estimate = R_hat, se = se))
}

# Example
taylor_variance_ratio(rnorm(100, 50), rnorm(100, 100), 
                     rep(100, 100), NULL, NULL)
```

---

# Slide 193: Jackknife Variance Estimation

```{r jackknife, echo=TRUE}
# Jackknife variance estimation
jackknife_variance <- function(data, statistic, clusters) {
  
  n_clusters <- length(unique(clusters))
  estimates <- numeric(n_clusters)
  
  # Leave out each cluster
  for(i in 1:n_clusters) {
    subset_data <- data[clusters != i, ]
    estimates[i] <- statistic(subset_data)
  }
  
  # Full sample estimate
  theta_hat <- statistic(data)
  
  # Jackknife variance
  var_jk <- ((n_clusters - 1) / n_clusters) * 
            sum((estimates - theta_hat)^2)
  
  se_jk <- sqrt(var_jk)
  
  cat("JACKKNIFE VARIANCE ESTIMATION\n")
  cat("============================\n")
  cat("Replications:", n_clusters, "\n")
  cat("Estimate:", round(theta_hat, 4), "\n")
  cat("Jackknife SE:", round(se_jk, 4), "\n")
  cat("95% CI: [", round(theta_hat - 1.96*se_jk, 4), ",",
      round(theta_hat + 1.96*se_jk, 4), "]\n")
  
  return(list(estimate = theta_hat, se = se_jk, replicates = estimates))
}

# Example function
mean_stat <- function(d) mean(d$value)
test_data <- data.frame(value = rnorm(100))

# Note: Simplified example
cat("\nJackknife method implemented\n")
```

---

# Slide 194: Bootstrap for Surveys

```{r bootstrap-surveys, echo=FALSE}
boot_comparison <- tibble(
  Bootstrap_Type = c("Naive", "Rescaling", "Mirror-match", "Rao-Wu", "Preston"),
  Accounts_For = c("None", "Weights only", "Clusters", "Full design", "Calibration"),
  Stages = c("Single", "Single", "Multi", "Multi", "Multi"),
  Consistency = c("No", "Partial", "Yes", "Yes", "Yes"),
  Computation = c("Fast", "Fast", "Moderate", "Slow", "Slow")
)

boot_comparison %>%
  gt() %>%
  tab_header(
    title = "Bootstrap Methods for Complex Surveys",
    subtitle = "Not all bootstraps are equal"
  ) %>%
  data_color(
    columns = Consistency,
    colors = scales::col_factor(
      palette = c("Yes" = "#d4edda", "Partial" = "#fff3cd", "No" = "#ffcccc"),
      domain = c("Yes", "Partial", "No")
    )
  )
```

---

# Slide 195: Replicate Weights

```{r replicate-weights, echo=TRUE}
# Create replicate weights
create_replicate_weights <- function(base_weights, design, method = "JK1") {
  
  n <- length(base_weights)
  
  if(method == "JK1") {
    # Delete-1 Jackknife
    n_reps <- n
    rep_weights <- matrix(0, n, n_reps)
    
    for(r in 1:n_reps) {
      rep_weights[, r] <- base_weights
      rep_weights[r, r] <- 0  # Delete observation r
      # Adjust weights to maintain sum
      rep_weights[, r] <- rep_weights[, r] * sum(base_weights) / 
                          sum(rep_weights[, r])
    }
    
  } else if(method == "BRR") {
    # Balanced Repeated Replication
    n_reps <- 32  # Hadamard matrix size
    cat("BRR requires special design\n")
  }
  
  cat("REPLICATE WEIGHTS CREATED\n")
  cat("========================\n")
  cat("Method:", method, "\n")
  cat("Base weight sum:", sum(base_weights), "\n")
  cat("Number of replicates:", ncol(rep_weights), "\n")
  cat("Each replicate sum:", sum(rep_weights[,1]), "\n")
  
  return(rep_weights)
}

# Example
base_w <- rep(100, 10)
reps <- create_replicate_weights(base_w[1:5], NULL, "JK1")
```

---

# Slide 196: Design Effects

```{r design-effects, echo=FALSE}
deff_examples <- tibble(
  Design_Feature = c("Clustering", "Stratification", "Unequal weights",
                     "Clustering + Strat", "Full complex"),
  Formula = c("1 + (b-1)Ï", "(1-f)", "1 + cvÂ²(w)", 
              "DEFF_c Ã— DEFF_s", "Product of all"),
  Typical_Value = c(2.5, 0.9, 1.3, 2.2, 3.0),
  Implication = c("n_eff = n/2.5", "10% gain", "30% loss",
                  "Combined effect", "n_eff = n/3")
) %>%
  mutate(
    Sample_Adjustment = paste0(
      ifelse(Typical_Value > 1, "+", ""),
      round((Typical_Value - 1) * 100), "%"
    )
  )

deff_examples %>%
  gt() %>%
  tab_header(
    title = "Design Effect Components",
    subtitle = "Impact on effective sample size"
  )
```

---

# Slide 197: Finite Population Correction

```{r fpc, echo=TRUE}
# Finite population correction
calculate_fpc <- function(n, N) {
  
  # Sampling fraction
  f <- n / N
  
  # FPC factor
  fpc <- (N - n) / (N - 1)
  
  # Standard error adjustment
  se_adjustment <- sqrt(fpc)
  
  cat("FINITE POPULATION CORRECTION\n")
  cat("===========================\n")
  cat("Population size (N):", N, "\n")
  cat("Sample size (n):", n, "\n")
  cat("Sampling fraction (f):", round(f * 100, 1), "%\n\n")
  
  if(f < 0.05) {
    cat("FPC negligible (f < 5%)\n")
    cat("Can ignore FPC\n")
  } else {
    cat("FPC factor:", round(fpc, 4), "\n")
    cat("SE multiplier:", round(se_adjustment, 4), "\n")
    cat("Variance reduction:", round((1-fpc)*100, 1), "%\n")
  }
  
  # Show impact on confidence intervals
  ci_width_ratio <- se_adjustment
  cat("\nCI width reduced by:", round((1-ci_width_ratio)*100, 1), "%\n")
  
  return(list(fpc = fpc, se_mult = se_adjustment))
}

# Examples
calculate_fpc(100, 10000)  # Small fraction
calculate_fpc(500, 1000)   # Large fraction
```

---

# Slide 198: Variance of Calibrated Estimators

```{r calibrated-variance, echo=FALSE}
# Load required libraries
library(tibble)
library(gt)
library(dplyr)
library(ggplot2)

# Create the calibration variance comparison table
calibration_variance <- tibble(
  Estimator = c("HT", "GREG", "Raking", "Post-stratified", "Ridge-calibrated"),
  Variance_Formula = c(
    "V(Å¶_HT) = âˆ‘âˆ‘ Î”_ij y_i y_j / Ï€_i Ï€_j",
    "V(Å¶_HT) Ã— (1 - RÂ²_aux)",
    "V(Å¶_HT) Ã— [1 + O(nâ»Â¹)]",
    "V(Å¶_HT) Ã— (1 - RÂ²_strata)",
    "V(Å¶_GREG) Ã— (1 - Î»/(1+Î»))"
  ),
  Efficiency_Gain = c("Baseline", "20-40%", "15-30%", "10-25%", "25-45%"),
  Efficiency_Numeric = c(0, 30, 22.5, 17.5, 35), # Numeric values for coloring
  Assumptions = c(
    "Design-based inference only",
    "Linear relationship with auxiliaries",
    "Convergence of IPF algorithm",
    "Known post-strata totals",
    "Optimal ridge parameter selection"
  ),
  Sample_Size_Requirement = c(
    "n > 30",
    "n > 50p (p = aux vars)",
    "n > 100",
    "n_h > 10 per stratum",
    "n > 50p"
  )
)

# VERSION 1: Basic table with simple styling
basic_table <- calibration_variance %>%
  select(-Efficiency_Numeric) %>%  # Remove numeric column for display
  gt() %>%
  tab_header(
    title = "Variance of Calibrated Estimators",
    subtitle = "Comparison of efficiency gains and requirements"
  ) %>%
  tab_spanner(
    label = "Performance",
    columns = c(Variance_Formula, Efficiency_Gain)
  ) %>%
  tab_spanner(
    label = "Requirements",
    columns = c(Assumptions, Sample_Size_Requirement)
  ) %>%
  cols_label(
    Estimator = "Estimator",
    Variance_Formula = "Variance Formula",
    Efficiency_Gain = "Efficiency Gain",
    Assumptions = "Key Assumptions",
    Sample_Size_Requirement = "Sample Size"
  ) %>%
  # Style individual rows without case_when
  tab_style(
    style = list(
      cell_fill(color = "#f8f9fa"),
      cell_text(weight = "bold")
    ),
    locations = cells_body(
      columns = Estimator,
      rows = 1  # HT estimator
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "#d4edda"),
    locations = cells_body(
      columns = Efficiency_Gain,
      rows = c(2, 5)  # GREG and Ridge
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "#fff3cd"),
    locations = cells_body(
      columns = Efficiency_Gain,
      rows = c(3, 4)  # Raking and Post-stratified
    )
  ) %>%
  cols_width(
    Estimator ~ px(120),
    Variance_Formula ~ px(200),
    Efficiency_Gain ~ px(100),
    Assumptions ~ px(250),
    Sample_Size_Requirement ~ px(120)
  ) %>%
  tab_footnote(
    footnote = "RÂ² represents coefficient of determination",
    locations = cells_body(columns = Variance_Formula, rows = 2)
  ) %>%
  tab_footnote(
    footnote = "IPF = Iterative Proportional Fitting",
    locations = cells_body(columns = Assumptions, rows = 3)
  ) %>%
  tab_footnote(
    footnote = "Î» is the ridge regularization parameter",
    locations = cells_body(columns = Variance_Formula, rows = 5)
  )

# Display basic table
print(basic_table)

# VERSION 2: Table with average efficiency values
enhanced_table <- calibration_variance %>%
  mutate(
    `Avg Gain %` = Efficiency_Numeric
  ) %>%
  select(-Efficiency_Numeric) %>%
  gt() %>%
  tab_header(
    title = "Variance of Calibrated Estimators",
    subtitle = "Efficiency gains from calibration methods"
  ) %>%
  cols_label(
    Estimator = "Method",
    Variance_Formula = "Variance Formula",
    Efficiency_Gain = "Gain Range",
    `Avg Gain %` = "Average",
    Assumptions = "Key Assumptions",
    Sample_Size_Requirement = "Min. n"
  ) %>%
  fmt_number(
    columns = `Avg Gain %`,
    decimals = 1
  ) %>%
  # Apply styling row by row
  tab_style(
    style = list(
      cell_fill(color = "#f0f0f0"),
      cell_text(style = "italic")
    ),
    locations = cells_body(
      columns = everything(),
      rows = 1  # HT baseline
    )
  ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold", color = "#155724"),
      cell_fill(color = "#d4edda")
    ),
    locations = cells_body(
      columns = Efficiency_Gain,
      rows = 2  # GREG
    )
  ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold", color = "#155724"),
      cell_fill(color = "#d4edda")
    ),
    locations = cells_body(
      columns = Efficiency_Gain,
      rows = 5  # Ridge-calibrated
    )
  ) %>%
  cols_align(
    align = "center",
    columns = c(Efficiency_Gain, `Avg Gain %`)
  ) %>%
  cols_align(
    align = "left",
    columns = c(Estimator, Assumptions)
  ) %>%
  tab_options(
    table.font.size = 12,
    heading.title.font.size = 16,
    heading.subtitle.font.size = 14
  )

# Display enhanced table
print(enhanced_table)

# VERSION 3: Create efficiency visualization
efficiency_viz_data <- calibration_variance %>%
  filter(Estimator != "HT") %>%
  mutate(
    Min_Efficiency = c(20, 15, 10, 25),
    Max_Efficiency = c(40, 30, 25, 45),
    Avg_Efficiency = (Min_Efficiency + Max_Efficiency) / 2
  )

# Create the plot
efficiency_plot <- ggplot(efficiency_viz_data, 
                          aes(x = reorder(Estimator, Avg_Efficiency))) +
  # Range bars
  geom_segment(aes(xend = Estimator, y = Min_Efficiency, yend = Max_Efficiency),
               linewidth = 4, color = "gray70", alpha = 0.6) +
  # Points for min, max, and average
  geom_point(aes(y = Min_Efficiency), size = 3, color = "#dc3545") +
  geom_point(aes(y = Max_Efficiency), size = 3, color = "#28a745") +
  geom_point(aes(y = Avg_Efficiency), size = 4, color = "#007bff") +
  # Labels
  geom_text(aes(y = Avg_Efficiency, label = paste0(round(Avg_Efficiency, 0), "%")),
            hjust = -0.3, size = 3.5, fontface = "bold") +
  coord_flip() +
  labs(
    title = "Efficiency Gain Ranges by Calibration Method",
    subtitle = "Percentage reduction in variance vs. Horvitz-Thompson",
    x = "",
    y = "Efficiency Gain (%)",
    caption = "Min (red) | Average (blue) | Max (green)"
  ) +
  theme_minimal() +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_blank(),
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11, color = "gray40"),
    plot.caption = element_text(size = 9, style = "italic"),
    axis.text.y = element_text(size = 10, face = "bold")
  ) +
  scale_y_continuous(breaks = seq(0, 50, 10), limits = c(0, 50))

print(efficiency_plot)

# VERSION 4: Method selection guide
selection_guide <- tibble(
  Criterion = c(
    "Linear relationships",
    "Categorical data",
    "Known strata totals",
    "High dimensions",
    "Computation speed",
    "Theory foundation"
  ),
  GREG = c("Excellent", "Good", "Good", "Poor", "Good", "Excellent"),
  Raking = c("Good", "Excellent", "Good", "Good", "Poor", "Good"),
  PostStrat = c("Poor", "Good", "Excellent", "Poor", "Excellent", "Good"),
  Ridge = c("Good", "Good", "Good", "Excellent", "Good", "Good")
)

guide_table <- selection_guide %>%
  gt() %>%
  tab_header(
    title = "Calibration Method Selection Guide",
    subtitle = "When to use each approach"
  ) %>%
  cols_label(
    Criterion = "Selection Criterion",
    GREG = "GREG",
    Raking = "Raking",
    PostStrat = "Post-Stratification",
    Ridge = "Ridge"
  ) %>%
  # Apply color coding based on performance level
  tab_style(
    style = cell_fill(color = "#d4edda"),
    locations = cells_body(
      columns = GREG,
      rows = selection_guide$GREG == "Excellent"
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "#d4edda"),
    locations = cells_body(
      columns = Raking,
      rows = selection_guide$Raking == "Excellent"
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "#d4edda"),
    locations = cells_body(
      columns = PostStrat,
      rows = selection_guide$PostStrat == "Excellent"
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "#d4edda"),
    locations = cells_body(
      columns = Ridge,
      rows = selection_guide$Ridge == "Excellent"
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "#f8d7da"),
    locations = cells_body(
      columns = GREG,
      rows = selection_guide$GREG == "Poor"
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "#f8d7da"),
    locations = cells_body(
      columns = Raking,
      rows = selection_guide$Raking == "Poor"
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "#f8d7da"),
    locations = cells_body(
      columns = PostStrat,
      rows = selection_guide$PostStrat == "Poor"
    )
  ) %>%
  cols_align(
    align = "center",
    columns = -Criterion
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_body(columns = Criterion)
  )

print(guide_table)

# PRACTICAL APPLICATION CALCULATIONS
cat("\n================================================\n")
cat("CALIBRATION VARIANCE ANALYSIS\n")
cat("================================================\n\n")

# Expected efficiency for the household survey
n_sample <- 5000
n_provinces <- 8
n_districts <- 25
pop_size <- 10000

cat("HOUSEHOLD SURVEY APPLICATION\n")
cat("-----------------------------\n")
cat("Sample size: ", n_sample, "\n")
cat("Population size: ", pop_size, "\n")
cat("Number of provinces: ", n_provinces, "\n")
cat("Number of districts: ", n_districts, "\n\n")

# Calculate expected gains
expected_r2 <- 0.35  # Reasonable for demographic auxiliaries
greg_efficiency <- round(expected_r2 * 100, 1)
cat("Expected GREG efficiency gain (RÂ² = ", expected_r2, "): ", 
    greg_efficiency, "%\n", sep = "")

# Post-stratification efficiency
n_strata <- n_provinces * 2  # Province Ã— Urban/Rural
avg_stratum_size <- n_sample / n_strata
poststrat_efficiency <- round(15 * (1 - 10/avg_stratum_size), 1)
cat("Expected post-stratification gain: ", poststrat_efficiency, "%\n", sep = "")

# Design effect from calibration
n_constraints <- n_provinces + 2 + 5  # Province + urban/rural + demographics
deff_calibration <- 1 + (n_constraints / n_sample) * 10
cat("Design effect from calibration: ", round(deff_calibration, 2), "\n", sep = "")

# Effective sample size
eff_sample_size <- round(n_sample / deff_calibration, 0)
cat("Effective sample size: ", eff_sample_size, "\n\n", sep = "")

cat("RECOMMENDATIONS:\n")
cat("----------------\n")
cat("1. Use GREG for continuous auxiliary variables\n")
cat("   (household size, number of rooms, etc.)\n\n")
cat("2. Use raking for categorical calibration\n")
cat("   (province Ã— urban/rural Ã— dwelling type)\n\n")
cat("3. Monitor weight variation (CV of weights < 0.5)\n")
cat("4. Check calibration convergence diagnostics\n")
cat("5. Validate against known population totals\n")
```

---

# Slide 199: Generalized Variance Functions

```{r gvf, echo=TRUE}
# Generalized Variance Function
estimate_gvf <- function(estimates, standard_errors) {
  
  # GVF model: SE = sqrt(a * estimate + b * estimateÂ²)
  
  # Log transformation for fitting
  log_se <- log(standard_errors)
  log_est <- log(estimates)
  
  # Fit linear model
  gvf_model <- lm(log_se ~ log_est)
  
  a <- exp(coef(gvf_model)[1])
  b <- coef(gvf_model)[2]
  
  cat("GENERALIZED VARIANCE FUNCTION\n")
  cat("============================\n")
  cat("Model: SEÂ² = a Ã— p + b Ã— pÂ²\n")
  cat("Parameters:\n")
  cat("  a =", round(a, 6), "\n")
  cat("  b =", round(b, 4), "\n")
  cat("R-squared:", round(summary(gvf_model)$r.squared, 3), "\n\n")
  
  # Prediction example
  new_estimate <- 0.25
  predicted_se <- sqrt(a * new_estimate + b * new_estimate^2)
  
  cat("Example prediction:\n")
  cat("  For estimate =", new_estimate, "\n")
  cat("  Predicted SE =", round(predicted_se, 4), "\n")
  cat("  Predicted CV =", round(predicted_se/new_estimate*100, 1), "%\n")
  
  return(list(a = a, b = b, model = gvf_model))
}

# Example with simulated data
estimates <- runif(20, 0.1, 0.5)
ses <- sqrt(estimates * (1-estimates) / 1000) * runif(20, 0.8, 1.2)
gvf <- estimate_gvf(estimates, ses)
```

---

# Slide 200: Variance Estimation Summary

```{r variance-summary, echo=FALSE}
variance_decision <- tibble(
  Scenario = c("Simple design", "Stratified only", "Clusters only", 
               "Complex design", "Calibrated", "Small samples"),
  Recommended = c("Direct formula", "Stratified formula", "Taylor/JK",
                  "Taylor/Replication", "Replication", "Bootstrap"),
  Software = c("Base R", "survey", "survey", "survey/Stata", "survey", "boot")
)

variance_decision %>%
  gt() %>%
  tab_header(
    title = "Variance Method Selection Guide",
    subtitle = "Choose based on design complexity"
  )
```

---

# MODULE 11: SMALL AREA ESTIMATION
## Slides 201-250

---

# Slide 201: Small Area Estimation Overview

## When Sample Sizes Are Too Small

```{r sae-overview, echo=FALSE}
sae_problem <- tibble(
  Domain = c("National", "Province A", "District 1", "Ward 1a"),
  Sample_Size = c(5000, 800, 120, 15),
  Direct_CV = c(2, 5, 15, 45),
  SAE_CV = c(2, 4, 8, 12),
  Method = c("Direct", "Direct", "Model", "Model")
)

sae_problem %>%
  ggplot(aes(x = Sample_Size, y = Direct_CV)) +
  geom_point(size = 4, color = "red") +
  geom_point(aes(y = SAE_CV), size = 4, color = "blue") +
  geom_text(aes(label = Domain), vjust = -1) +
  scale_x_log10() +
  labs(title = "Small Area Estimation Impact",
       subtitle = "Red: Direct estimates, Blue: SAE estimates",
       x = "Sample Size (log scale)", y = "CV (%)") +
  theme_minimal()
```

---

# Slide 202: Basic Area-Level Model

```{r area-level-model, echo=TRUE}
# Fay-Herriot area-level model
fay_herriot_model <- function(direct_estimates, auxiliary_data, variances) {
  
  # Model: Y_i = X_i'Î² + v_i + e_i
  # v_i ~ N(0, ÏƒÂ²_v) - model error
  # e_i ~ N(0, Ïˆ_i) - sampling error (known)
  
  cat("FAY-HERRIOT MODEL\n")
  cat("================\n\n")
  
  # Components
  cat("Direct estimate = True value + Model error + Sampling error\n")
  cat("Y_i = X_i'Î² + v_i + e_i\n\n")
  
  # Estimation steps
  steps <- c(
    "1. Estimate ÏƒÂ²_v (model variance)",
    "2. Estimate Î² (regression coefficients)",
    "3. Calculate shrinkage factor Î³_i",
    "4. Compute EBLUP: Å¶_i = Î³_i*Y_i + (1-Î³_i)*X_i'Î²"
  )
  
  cat("Estimation steps:\n")
  cat(paste(steps, collapse = "\n"), "\n\n")
  
  # Shrinkage factor
  model_var <- 0.5
  sampling_var <- mean(variances)
  gamma <- model_var / (model_var + sampling_var)
  
  cat("Example shrinkage factor:", round(gamma, 3), "\n")
  cat("Interpretation: Use", round(gamma*100), "% direct,", 
      round((1-gamma)*100), "% model\n")
  
  return(gamma)
}

# Example
fay_herriot_model(NULL, NULL, c(0.1, 0.2, 0.3))
```

---

# Slide 203: Unit-Level Models

```{r unit-level-model, echo=FALSE}
model_comparison <- tibble(
  Aspect = c("Data required", "Auxiliary info", "Computation", 
             "Software", "Precision gain"),
  Area_Level = c("Area aggregates", "Area-level", "Simple", 
                 "sae package", "Moderate"),
  Unit_Level = c("Microdata", "Unit-level", "Intensive", 
                 "lme4 + custom", "High")
)

model_comparison %>%
  gt() %>%
  tab_header(
    title = "Area vs Unit Level Models",
    subtitle = "Choosing the right SAE approach"
  )
```

---

# Slide 204: EBLUP Estimation

```{r eblup, echo=TRUE}
# Empirical Best Linear Unbiased Predictor
calculate_eblup <- function(direct_est, model_pred, shrinkage) {
  
  # EBLUP combines direct and synthetic estimates
  eblup <- shrinkage * direct_est + (1 - shrinkage) * model_pred
  
  # MSE has two components
  mse_components <- list(
    g1 = "Variance due to estimating fixed effects",
    g2 = "Variance due to predicting random effects",
    g3 = "Variance due to estimating variance components"
  )
  
  cat("EBLUP CALCULATION\n")
  cat("================\n")
  cat("Direct estimate:", direct_est, "\n")
  cat("Model prediction:", model_pred, "\n")
  cat("Shrinkage factor:", shrinkage, "\n")
  cat("EBLUP:", round(eblup, 3), "\n\n")
  
  cat("MSE components:\n")
  for(comp in names(mse_components)) {
    cat("-", mse_components[[comp]], "\n")
  }
  
  return(eblup)
}

calculate_eblup(0.25, 0.30, 0.7)
```

---

# Slide 205: Hierarchical Bayes Models

```{r hierarchical-bayes, echo=FALSE}
hb_structure <- tibble(
  Level = c("Data", "Parameters", "Hyperparameters", "Hyperpriors"),
  Model = c("y_i | Î¸_i", "Î¸_i | Î², ÏƒÂ²", "Î², ÏƒÂ²", "Î² ~ N(), ÏƒÂ² ~ IG()"),
  Estimation = c("Likelihood", "Random effects", "Empirical Bayes", "Full Bayes")
)

hb_structure %>%
  gt() %>%
  tab_header(
    title = "Hierarchical Bayesian Structure",
    subtitle = "Multiple levels of uncertainty"
  )
```

---

# Slide 206: Spatial Models

```{r spatial-sae, echo=TRUE}
# Spatial SAE models
spatial_sae_model <- function() {
  
  cat("SPATIAL SAE MODELS\n")
  cat("==================\n\n")
  
  models <- list(
    SAR = "Spatial Auto-Regressive: Y = ÏWY + XÎ² + Îµ",
    CAR = "Conditional Auto-Regressive: Y_i | Y_-i ~ N(XÎ² + ÏÎ£w_ij*Y_j, ÏƒÂ²)",
    GWR = "Geographically Weighted Regression: Î² varies by location",
    Kriging = "Gaussian process: Spatial interpolation"
  )
  
  cat("Model types:\n")
  for(model in names(models)) {
    cat(sprintf("  %s:\n    %s\n", model, models[[model]]))
  }
  
  cat("\nSpatial weight matrix W:\n")
  cat("- Contiguity-based (neighbors)\n")
  cat("- Distance-based (inverse distance)\n")
  cat("- K-nearest neighbors\n")
  
  cat("\nBenefits:\n")
  cat("- Borrows strength from neighbors\n")
  cat("- Accounts for spatial correlation\n")
  cat("- Improves precision for all areas\n")
}

spatial_sae_model()
```

---

# Slide 207: Time Series SAE

```{r time-series-sae, echo=FALSE}
ts_models <- tibble(
  Model = c("Rao-Yu", "Time-varying FH", "State-space", "Dynamic linear"),
  Temporal = c("AR(1)", "Time-varying variance", "Kalman filter", "Full dynamic"),
  Spatial = c("No", "No", "Optional", "Yes"),
  Software = c("sae", "Custom", "dlm", "INLA")
)

ts_models %>%
  gt() %>%
  tab_header(
    title = "Time Series Small Area Models",
    subtitle = "Borrowing strength over time"
  )
```

---

# Slide 208: Benchmarking SAE

```{r benchmarking-sae, echo=TRUE}
# Benchmark SAE to known totals
benchmark_sae <- function(sae_estimates, weights, national_total) {
  
  # Initial SAE total
  sae_total <- sum(sae_estimates * weights)
  
  # Benchmarking ratio
  ratio <- national_total / sae_total
  
  # Adjusted estimates
  benchmarked <- sae_estimates * ratio
  
  cat("SAE BENCHMARKING\n")
  cat("===============\n")
  cat("Original total:", round(sae_total), "\n")
  cat("Target total:", national_total, "\n")
  cat("Adjustment ratio:", round(ratio, 4), "\n\n")
  
  # Check coherence
  new_total <- sum(benchmarked * weights)
  cat("Benchmarked total:", round(new_total), "\n")
  cat("Coherence achieved:", abs(new_total - national_total) < 1, "\n")
  
  return(benchmarked)
}

# Example
sae_est <- c(0.2, 0.3, 0.25, 0.35)
weights <- c(1000, 1500, 800, 1200)
benchmark_sae(sae_est, weights, 1200)
```

---

# Slide 209: MSE Estimation

```{r mse-estimation, echo=FALSE}
mse_methods <- tibble(
  Method = c("Analytical", "Jackknife", "Bootstrap", "MCMC"),
  Type = c("Prasad-Rao", "Delete-area", "Parametric", "Posterior variance"),
  Accounts_For = c("g1 + g2", "All", "All", "Full uncertainty"),
  Computation = c("Fast", "Moderate", "Intensive", "Very intensive")
)

mse_methods %>%
  gt() %>%
  tab_header(
    title = "MSE Estimation Methods for SAE",
    subtitle = "Measuring uncertainty in small area estimates"
  )
```

---

# Slide 210: Model Diagnostics

```{r sae-diagnostics, echo=TRUE}
# SAE model diagnostics
diagnose_sae_model <- function(model_output) {
  
  diagnostics <- list(
    residuals = "Check normality and patterns",
    leverage = "Identify influential areas",
    coverage = "95% CI coverage rates",
    bias = "Compare with design-based where possible"
  )
  
  cat("SAE MODEL DIAGNOSTICS\n")
  cat("====================\n\n")
  
  # Residual checks
  cat("1. RESIDUAL ANALYSIS\n")
  cat("   - Shapiro-Wilk test for normality\n")
  cat("   - Plot against predictors\n")
  cat("   - Spatial autocorrelation test\n\n")
  
  # Model selection
  cat("2. MODEL SELECTION\n")
  cat("   - AIC/BIC comparison\n")
  cat("   - Cross-validation\n")
  cat("   - Conditional AIC for mixed models\n\n")
  
  # Validation
  cat("3. VALIDATION\n")
  cat("   - Leave-one-out CV\n")
  cat("   - Compare with direct estimates (large areas)\n")
  cat("   - Benchmarking diagnostics\n")
  
  return(diagnostics)
}

diagnose_sae_model(NULL)
```

---

# MODULE 12: SURVEY DATA ANALYSIS
## Slides 211-250

---

# Slide 211: Survey-Weighted Analysis

```{r weighted-analysis, echo=FALSE}
analysis_types <- tibble(
  Analysis = c("Means", "Proportions", "Regression", "Quantiles", "Correlations"),
  Unweighted = c("Simple", "Simple", "OLS", "Order statistics", "Pearson"),
  Weighted = c("Weighted mean", "Weighted prop", "WLS", "Weighted quantiles", "Weighted corr"),
  R_Function = c("svymean()", "svymean()", "svyglm()", "svyquantile()", "svycor()")
)

analysis_types %>%
  gt() %>%
  tab_header(
    title = "Survey-Weighted Analysis Methods",
    subtitle = "Accounting for complex designs"
  )
```

---

# Slide 212: Domain Estimation

```{r domain-estimation, echo=TRUE}
# Domain (subpopulation) estimation
estimate_domains <- function(design, domains) {
  
  cat("DOMAIN ESTIMATION\n")
  cat("================\n\n")
  
  # Important principle
  cat("KEY PRINCIPLE:\n")
  cat("Always use full sample, even for subdomains\n")
  cat("Set values to 0 outside domain, not subset\n\n")
  
  # Example domains
  example_domains <- c(
    "Urban areas only",
    "Age 18-34",
    "Employed persons",
    "Province Ã— Gender cells"
  )
  
  cat("Example domains:\n")
  cat(paste("-", example_domains), sep = "\n")
  
  cat("\n\nCorrect approach:\n")
  cat("svyby(~income, ~domain, design, svymean)\n\n")
  
  cat("WRONG approach:\n")
  cat("subset(design, domain == 'A') %>% svymean(~income, .)\n")
  cat("This gives wrong standard errors!\n")
  
  return(TRUE)
}

estimate_domains(NULL, NULL)
```

---

# Slide 213: Regression with Survey Data

```{r survey-regression, echo=TRUE}
# Survey-weighted regression
survey_regression <- function() {
  
  cat("SURVEY-WEIGHTED REGRESSION\n")
  cat("=========================\n\n")
  
  # Key differences from OLS
  differences <- list(
    "1. Weights in likelihood" = "Pseudo-maximum likelihood",
    "2. Variance estimation" = "Sandwich estimator",
    "3. Design effects" = "Affects standard errors",
    "4. Finite population" = "Can incorporate FPC"
  )
  
  for(diff in names(differences)) {
    cat(diff, ":", differences[[diff]], "\n")
  }
  
  cat("\nR implementation:\n")
  cat("model <- svyglm(y ~ x1 + x2, design = survey_design)\n")
  cat("summary(model)  # Design-adjusted SEs\n\n")
  
  cat("Interpretation notes:\n")
  cat("- Coefficients: Population parameters\n")
  cat("- SEs: Account for clustering/stratification\n")
  cat("- RÂ²: Use adjusted version for complex surveys\n")
}

survey_regression()
```

---

# Slide 214: Testing with Complex Surveys

```{r survey-testing, echo=FALSE}
test_adjustments <- tibble(
  Test = c("t-test", "Chi-square", "ANOVA", "Correlation"),
  Standard = c("t-statistic", "Pearson Ï‡Â²", "F-statistic", "Pearson r"),
  Survey_Adjusted = c("Design-based t", "Rao-Scott Ï‡Â²", "Adjusted F", "Weighted r"),
  R_Function = c("svyttest()", "svychisq()", "svyglm() + anova()", "svycor()")
)

test_adjustments %>%
  gt() %>%
  tab_header(
    title = "Statistical Tests for Survey Data",
    subtitle = "Design-adjusted versions required"
  )
```

---

# Slide 215: Survey Data Visualization

```{r survey-viz, echo=TRUE}
# Visualizing survey data properly
plot_survey_data <- function(design, variable) {
  
  cat("SURVEY DATA VISUALIZATION\n")
  cat("========================\n\n")
  
  cat("Essential elements:\n")
  cat("1. WEIGHTED estimates (not raw counts)\n")
  cat("2. CONFIDENCE INTERVALS (design-based)\n")
  cat("3. SAMPLE SIZES (for transparency)\n")
  cat("4. DESIGN EFFECTS (where relevant)\n\n")
  
  # Example ggplot code
  cat("Example code:\n")
  cat("estimates <- svyby(~var, ~group, design, svymean)\n")
  cat("estimates %>%\n")
  cat("  ggplot(aes(x = group, y = var)) +\n")
  cat("  geom_col() +\n")
  cat("  geom_errorbar(aes(ymin = var - 1.96*se,\n")
  cat("                    ymax = var + 1.96*se)) +\n")
  cat("  labs(caption = 'Error bars show 95% CI')\n")
  
  return(TRUE)
}

plot_survey_data(NULL, NULL)
```

---

# MODULE 13: SURVEY QUALITY FRAMEWORK
## Slides 216-250

---

# Slide 216: Quality Dimensions

```{r quality-dimensions, echo=FALSE}
quality_framework <- tibble(
  Dimension = c("Relevance", "Accuracy", "Timeliness", "Accessibility", 
                "Interpretability", "Coherence"),
  Definition = c("Meets user needs", "Close to true values", "Available when needed",
                 "Easy to obtain", "Clear metadata", "Consistent over time"),
  Indicators = c("User satisfaction", "CV, bias, coverage", "Days to release",
                 "Download stats", "Documentation score", "Revision rates")
)

quality_framework %>%
  gt() %>%
  tab_header(
    title = "Survey Quality Framework",
    subtitle = "Based on Statistics Canada Quality Guidelines"
  )
```

---

# Slide 217: Quality Indicators

```{r quality-indicators, echo=TRUE}
# Calculate survey quality indicators
calculate_quality_indicators <- function(survey_results) {
  
  indicators <- list(
    # Response quality
    response_rate = 0.72,
    item_response = 0.95,
    
    # Sampling quality  
    coverage_rate = 0.94,
    design_effect = 1.8,
    
    # Estimation quality
    cv_key_estimates = 0.05,
    revision_rate = 0.02,
    
    # Process quality
    edit_failure_rate = 0.08,
    imputation_rate = 0.03
  )
  
  cat("SURVEY QUALITY INDICATORS\n")
  cat("========================\n\n")
  
  # Overall quality score
  weights <- c(0.3, 0.1, 0.2, 0.1, 0.2, 0.05, 0.03, 0.02)
  quality_score <- sum(unlist(indicators) * weights)
  
  for(ind in names(indicators)) {
    cat(sprintf("%-20s: %.1f%%\n", 
                gsub("_", " ", ind), 
                indicators[[ind]] * 100))
  }
  
  cat("\nOVERALL QUALITY SCORE:", round(quality_score * 100), "/100\n")
  
  return(indicators)
}

quality <- calculate_quality_indicators(NULL)
```

---

# Slide 218: Quality Control Process

```{r quality-control-process, echo=FALSE}
qc_timeline <- tibble(
  Stage = c("Design", "Collection", "Processing", "Estimation", "Dissemination"),
  Checks = c("Expert review", "Field monitoring", "Edit rules", "Variance checks", "Disclosure"),
  Frequency = c("Once", "Daily", "Batch", "Each estimate", "Each output"),
  Responsible = c("Methodology", "Field supervisor", "Data team", "Analysts", "Reviewers")
)

qc_timeline %>%
  gt() %>%
  tab_header(
    title = "Quality Control Timeline",
    subtitle = "Continuous monitoring throughout survey"
  )
```

---

# MODULE 14: ADMINISTRATIVE DATA INTEGRATION
## Slides 219-250

---

# Slide 219: Admin Data for Surveys

```{r admin-data, echo=TRUE}
# Integrate administrative data
integrate_admin_data <- function(survey_frame, admin_source) {
  
  cat("ADMINISTRATIVE DATA INTEGRATION\n")
  cat("===============================\n\n")
  
  sources <- list(
    tax_records = "Income validation",
    health_records = "Health service use", 
    education_db = "Enrollment verification",
    social_registry = "Benefit receipt",
    utility_bills = "Consumption patterns"
  )
  
  cat("Common admin sources:\n")
  for(source in names(sources)) {
    cat("-", source, ":", sources[[source]], "\n")
  }
  
  cat("\nIntegration methods:\n")
  cat("1. EXACT matching (unique ID)\n")
  cat("2. PROBABILISTIC matching (name, DOB, address)\n")
  cat("3. STATISTICAL matching (similar characteristics)\n")
  
  cat("\nBenefits:\n")
  cat("- Reduce respondent burden\n")
  cat("- Improve accuracy\n")
  cat("- Enable validation\n")
  cat("- Cost reduction\n")
  
  return(TRUE)
}

integrate_admin_data(NULL, NULL)
```

---

# Slide 220: Record Linkage

```{r record-linkage, echo=FALSE}
linkage_steps <- tibble(
  Step = 1:6,
  Process = c("Standardization", "Blocking", "Comparison", "Classification", 
              "Clerical review", "Analysis"),
  Description = c("Clean and standardize fields", "Create candidate pairs",
                  "Calculate similarity scores", "Classify as match/non-match",
                  "Review uncertain cases", "Create linked dataset"),
  Tools = c("stringr", "blocking", "RecordLinkage", "Machine learning",
            "Manual review", "Analysis weights")
)

linkage_steps %>%
  gt() %>%
  tab_header(
    title = "Record Linkage Process",
    subtitle = "Linking surveys to admin data"
  )
```

---

# MODULE 15: SURVEY DOCUMENTATION
## Slides 221-250

---

# Slide 221: Documentation Standards

```{r documentation-standards, echo=TRUE}
# Survey documentation framework
create_documentation <- function(survey_name) {
  
  cat("SURVEY DOCUMENTATION STANDARDS\n")
  cat("=============================\n\n")
  
  sections <- list(
    "1. Overview" = c("Purpose", "Scope", "Key indicators"),
    "2. Methodology" = c("Design", "Frame", "Sample size"),
    "3. Questionnaire" = c("Instruments", "Testing", "Languages"),
    "4. Collection" = c("Mode", "Period", "Response rate"),
    "5. Processing" = c("Editing", "Imputation", "Weighting"),
    "6. Quality" = c("Accuracy", "Comparability", "Limitations"),
    "7. Dissemination" = c("Products", "Access", "Citation")
  )
  
  for(section in names(sections)) {
    cat(section, "\n")
    for(item in sections[[section]]) {
      cat("  -", item, "\n")
    }
  }
  
  cat("\nMetadata standards:\n")
  cat("- DDI (Data Documentation Initiative)\n")
  cat("- SDMX (Statistical Data and Metadata eXchange)\n")
  cat("- Dublin Core\n")
  
  return(sections)
}

doc_structure <- create_documentation("Household Survey 2025")
```

---

# Slide 222: Reproducible Research

```{r reproducible-research, echo=FALSE}
reproducibility <- tibble(
  Component = c("Code", "Data", "Environment", "Documentation", "Version control"),
  Tool = c("R scripts", "Data packages", "renv/Docker", "Rmarkdown", "Git"),
  Purpose = c("Analysis steps", "Input files", "Dependencies", "Narrative", "History")
)

reproducibility %>%
  gt() %>%
  tab_header(
    title = "Reproducible Survey Research",
    subtitle = "Components for full reproducibility"
  )
```

---

# MODULE 16: SURVEY COSTS AND BUDGETING
## Slides 223-250

---

# Slide 223: Cost Components

```{r cost-components, echo=TRUE}
# Survey cost breakdown
calculate_survey_costs <- function(sample_size, mode) {
  
  cat("SURVEY COST COMPONENTS\n")
  cat("=====================\n\n")
  
  # Cost structure
  fixed_costs <- list(
    design = 50000,
    questionnaire = 30000,
    training = 40000,
    systems = 60000
  )
  
  variable_costs <- list(
    f2f = 60,
    phone = 20,
    web = 5,
    mail = 15
  )
  
  cat("FIXED COSTS:\n")
  total_fixed <- 0
  for(item in names(fixed_costs)) {
    cat(sprintf("  %-15s: $%s\n", item, format(fixed_costs[[item]], big.mark=",")))
    total_fixed <- total_fixed + fixed_costs[[item]]
  }
  
  cat("\nVARIABLE COSTS (per unit):\n")
  for(m in names(variable_costs)) {
    cat(sprintf("  %-10s: $%d\n", m, variable_costs[[m]]))
  }
  
  # Total calculation
  total <- total_fixed + sample_size * variable_costs[[mode]]
  
  cat("\nTOTAL COST CALCULATION:\n")
  cat("Fixed:", format(total_fixed, big.mark=","), "\n")
  cat("Variable:", format(sample_size * variable_costs[[mode]], big.mark=","), "\n")
  cat("TOTAL: $", format(total, big.mark=","), "\n")
  
  return(total)
}

budget <- calculate_survey_costs(5000, "f2f")
```

---

# Slide 224: Cost Optimization

```{r cost-optimization2, echo=FALSE}
# Load required libraries
library(tibble)
library(gt)
library(dplyr)
library(ggplot2)

# Create the optimization strategies data with numeric savings
optimization_strategies <- tibble(
  Strategy = c("Mixed mode", "Adaptive design", "Admin data", "Panel design", "Technology"),
  Savings = c("30%", "20%", "40%", "25%", "35%"),
  Savings_Numeric = c(30, 20, 40, 25, 35),  # Numeric version for calculations
  Investment = c("Medium", "Low", "High", "Medium", "High"),
  Payback = c("1 year", "Immediate", "2 years", "2nd wave", "18 months"),
  Implementation_Time = c("3-6 months", "1-2 months", "6-12 months", "Survey cycle", "4-8 months"),
  Risk_Level = c("Low", "Low", "Medium", "Low", "High")
)

# Version 1: Table with proper color scaling using numeric column
table_v1 <- optimization_strategies %>%
  gt() %>%
  tab_header(
    title = "Cost Optimization Strategies",
    subtitle = "Reducing survey costs while maintaining quality"
  ) %>%
  cols_hide(columns = Savings_Numeric) %>%  # Hide numeric column
  cols_label(
    Strategy = "Strategy",
    Savings = "Cost Savings",
    Investment = "Investment Level",
    Payback = "Payback Period",
    Implementation_Time = "Implementation",
    Risk_Level = "Risk"
  ) %>%
  # Apply color based on savings levels using row numbers
  tab_style(
    style = cell_fill(color = "#d4edda"),
    locations = cells_body(
      columns = Savings,
      rows = c(1, 3, 5)  # 30%+ savings
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "#e7f3ea"),
    locations = cells_body(
      columns = Savings,
      rows = 4  # 25% savings
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "#f5f9f6"),
    locations = cells_body(
      columns = Savings,
      rows = 2  # 20% savings
    )
  ) %>%
  # Color code investment levels
  tab_style(
    style = list(
      cell_fill(color = "#f8d7da"),
      cell_text(weight = "bold")
    ),
    locations = cells_body(
      columns = Investment,
      rows = Investment == "High"
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "#fff3cd"),
    locations = cells_body(
      columns = Investment,
      rows = Investment == "Medium"
    )
  ) %>%
  tab_style(
    style = cell_fill(color = "#d1ecf1"),
    locations = cells_body(
      columns = Investment,
      rows = Investment == "Low"
    )
  ) %>%
  cols_align(
    align = "center",
    columns = c(Savings, Investment, Payback, Risk_Level)
  ) %>%
  tab_footnote(
    footnote = "Savings percentages are based on typical implementation results",
    locations = cells_column_labels(columns = Savings)
  ) %>%
  tab_footnote(
    footnote = "Payback periods assume full-scale implementation",
    locations = cells_column_labels(columns = Payback)
  )

print(table_v1)

# Version 2: Enhanced table with ROI calculations
optimization_enhanced <- optimization_strategies %>%
  mutate(
    # Calculate ROI scores (simplified)
    Investment_Score = case_when(
      Investment == "Low" ~ 1,
      Investment == "Medium" ~ 2,
      Investment == "High" ~ 3
    ),
    Payback_Months = case_when(
      Payback == "Immediate" ~ 0,
      Payback == "1 year" ~ 12,
      Payback == "18 months" ~ 18,
      Payback == "2nd wave" ~ 6,
      Payback == "2 years" ~ 24
    ),
    ROI_Score = round(Savings_Numeric / (Investment_Score * sqrt(Payback_Months + 1)), 1),
    Priority = case_when(
      ROI_Score > 10 ~ "High Priority",
      ROI_Score > 5 ~ "Medium Priority",
      TRUE ~ "Low Priority"
    )
  )

table_v2 <- optimization_enhanced %>%
  select(Strategy, Savings, Investment, Payback, ROI_Score, Priority) %>%
  gt() %>%
  tab_header(
    title = "Cost Optimization Strategies with ROI Analysis",
    subtitle = "Prioritization based on return on investment"
  ) %>%
  cols_label(
    Strategy = "Strategy",
    Savings = "Cost Savings",
    Investment = "Investment",
    Payback = "Payback",
    ROI_Score = "ROI Score",
    Priority = "Priority"
  ) %>%
  fmt_number(
    columns = ROI_Score,
    decimals = 1
  ) %>%
  # Color code priority levels
  tab_style(
    style = list(
      cell_fill(color = "#28a745"),
      cell_text(color = "white", weight = "bold")
    ),
    locations = cells_body(
      columns = Priority,
      rows = Priority == "High Priority"
    )
  ) %>%
  tab_style(
    style = list(
      cell_fill(color = "#ffc107"),
      cell_text(weight = "bold")
    ),
    locations = cells_body(
      columns = Priority,
      rows = Priority == "Medium Priority"
    )
  ) %>%
  cols_width(
    Strategy ~ px(150),
    Savings ~ px(100),
    Investment ~ px(100),
    Payback ~ px(100),
    ROI_Score ~ px(80),
    Priority ~ px(120)
  )

print(table_v2)

# Version 3: Visualization of cost savings vs investment
viz_data <- optimization_strategies %>%
  mutate(
    Investment_Level = factor(Investment, 
                             levels = c("Low", "Medium", "High"),
                             ordered = TRUE),
    Investment_Numeric = case_when(
      Investment == "Low" ~ 1,
      Investment == "Medium" ~ 2,
      Investment == "High" ~ 3
    )
  )

# Create scatter plot
cost_plot <- ggplot(viz_data, aes(x = Investment_Numeric, y = Savings_Numeric)) +
  geom_point(size = 8, aes(color = Strategy), alpha = 0.7) +
  geom_text(aes(label = Strategy), vjust = -1.5, size = 3.5) +
  scale_x_continuous(
    breaks = c(1, 2, 3),
    labels = c("Low", "Medium", "High"),
    limits = c(0.5, 3.5)
  ) +
  scale_y_continuous(
    breaks = seq(0, 50, 10),
    limits = c(0, 45),
    labels = function(x) paste0(x, "%")
  ) +
  scale_color_brewer(palette = "Set2") +
  labs(
    title = "Cost Savings vs Investment Requirements",
    subtitle = "Optimization strategies comparison",
    x = "Investment Level",
    y = "Potential Cost Savings",
    caption = "Bubble size represents implementation complexity"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11, color = "gray40"),
    panel.grid.minor = element_blank()
  ) +
  geom_hline(yintercept = 30, linetype = "dashed", alpha = 0.3) +
  geom_vline(xintercept = 2, linetype = "dashed", alpha = 0.3) +
  annotate("text", x = 3.3, y = 30, label = "30% threshold", 
           size = 3, alpha = 0.5)

print(cost_plot)

# Version 4: Implementation timeline
timeline_data <- optimization_strategies %>%
  mutate(
    Implementation_Months = case_when(
      grepl("1-2 months", Implementation_Time) ~ 1.5,
      grepl("3-6 months", Implementation_Time) ~ 4.5,
      grepl("4-8 months", Implementation_Time) ~ 6,
      grepl("6-12 months", Implementation_Time) ~ 9,
      TRUE ~ 12
    ),
    Payback_Numeric = case_when(
      Payback == "Immediate" ~ 0,
      Payback == "1 year" ~ 12,
      Payback == "18 months" ~ 18,
      Payback == "2nd wave" ~ 6,
      Payback == "2 years" ~ 24
    ),
    Total_Time = Implementation_Months + Payback_Numeric
  )

timeline_plot <- ggplot(timeline_data, aes(y = reorder(Strategy, -Total_Time))) +
  # Implementation phase
  geom_segment(aes(x = 0, xend = Implementation_Months, yend = Strategy),
               size = 8, color = "#dc3545", alpha = 0.7) +
  # Payback phase
  geom_segment(aes(x = Implementation_Months, 
                  xend = Implementation_Months + Payback_Numeric, 
                  yend = Strategy),
               size = 8, color = "#28a745", alpha = 0.7) +
  # Labels
  geom_text(aes(x = Implementation_Months/2, label = "Implementation"),
            color = "white", size = 3, fontface = "bold") +
  geom_text(aes(x = Implementation_Months + Payback_Numeric/2, label = "Payback"),
            color = "white", size = 3, fontface = "bold") +
  # Savings labels
  geom_text(aes(x = Total_Time + 2, label = Savings),
            size = 4, fontface = "bold", color = "#28a745") +
  scale_x_continuous(
    breaks = seq(0, 36, 6),
    labels = paste0(seq(0, 36, 6), " mo"),
    limits = c(0, 40)
  ) +
  labs(
    title = "Implementation Timeline and Payback Periods",
    subtitle = "Time to realize cost savings by strategy",
    x = "Time (months)",
    y = "",
    caption = "Red: Implementation phase | Green: Payback period"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 11, color = "gray40"),
    axis.text.y = element_text(size = 10, face = "bold"),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_blank()
  )

print(timeline_plot)

# Detailed strategy comparison matrix
strategy_matrix <- tibble(
  Criteria = c("Cost Savings", "Implementation Speed", "Risk Level", 
               "Scalability", "Quality Impact", "Overall Score"),
  `Mixed Mode` = c(4, 3, 4, 5, 4, 4.0),
  `Adaptive Design` = c(3, 5, 5, 4, 4, 4.2),
  `Admin Data` = c(5, 2, 3, 3, 3, 3.2),
  `Panel Design` = c(3, 3, 4, 4, 5, 3.8),
  Technology = c(4, 2, 2, 5, 4, 3.4)
)

matrix_table <- strategy_matrix %>%
  gt() %>%
  tab_header(
    title = "Strategy Evaluation Matrix",
    subtitle = "Comparative scoring (1-5 scale, 5 = best)"
  ) %>%
  fmt_number(
    columns = -Criteria,
    decimals = 1
  ) %>%
  data_color(
    columns = -Criteria,
    colors = scales::col_numeric(
      palette = c("#f8d7da", "#fff3cd", "#d4edda"),
      domain = c(1, 5)
    )
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_body(
      columns = Criteria,
      rows = 6  # Overall Score row
    )
  ) %>%
  tab_style(
    style = cell_borders(
      sides = "top",
      weight = px(2)
    ),
    locations = cells_body(
      rows = 6  # Overall Score row
    )
  )

print(matrix_table)

# Summary and recommendations
cat("\n================================================\n")
cat("COST OPTIMIZATION STRATEGY ANALYSIS\n")
cat("================================================\n\n")

cat("TOP RECOMMENDATIONS BY SCENARIO:\n")
cat("---------------------------------\n\n")

cat("1. QUICK WINS (Low investment, immediate payback):\n")
cat("   â€¢ Adaptive Design: 20% savings, minimal investment\n")
cat("   â€¢ Best for: Pilot studies, ongoing surveys\n\n")

cat("2. MAXIMUM SAVINGS (Highest cost reduction):\n")
cat("   â€¢ Administrative Data: 40% savings\n")
cat("   â€¢ Best for: Long-term programs with data access\n\n")

cat("3. BALANCED APPROACH (Good ROI, moderate risk):\n")
cat("   â€¢ Mixed Mode: 30% savings, proven effectiveness\n")
cat("   â€¢ Best for: Most household surveys\n\n")

cat("4. FUTURE-PROOF (Technology investment):\n")
cat("   â€¢ Technology Solutions: 35% savings, scalable\n")
cat("   â€¢ Best for: Large-scale, repeated surveys\n\n")

cat("5. QUALITY FOCUS (Maintains high data quality):\n")
cat("   â€¢ Panel Design: 25% savings, improved estimates\n")
cat("   â€¢ Best for: Longitudinal studies\n\n")

# Calculate combined strategy potential
combined_savings <- mean(optimization_strategies$Savings_Numeric)
cat("COMBINED STRATEGY POTENTIAL:\n")
cat("----------------------------\n")
cat("Average savings from single strategy: ", round(combined_savings, 1), "%\n", sep = "")
cat("Potential from combining 2-3 strategies: ", 
    round(combined_savings * 1.5, 1), "-", 
    round(combined_savings * 1.8, 1), "%\n", sep = "")
cat("Implementation period: 6-12 months\n")
cat("Full payback period: 12-24 months\n")
```

---

# MODULE 17: EMERGING TECHNOLOGIES
## Slides 225-250

---

# Slide 225: AI in Surveys

```{r ai-surveys, echo=TRUE}
# AI applications in surveys
implement_ai_surveys <- function() {
  
  cat("AI IN SURVEY RESEARCH\n")
  cat("====================\n\n")
  
  applications <- list(
    "Natural Language Processing" = c(
      "Automated coding of open-ends",
      "Sentiment analysis",
      "Question generation"
    ),
    
    "Machine Learning" = c(
      "Response propensity modeling",
      "Fraud detection",
      "Adaptive questionnaires"
    ),
    
    "Computer Vision" = c(
      "Image data extraction",
      "Facial emotion recognition",
      "Document scanning"
    ),
    
    "Voice AI" = c(
      "Voice surveys",
      "Emotion detection",
      "Automated transcription"
    )
  )
  
  for(category in names(applications)) {
    cat(category, ":\n")
    for(app in applications[[category]]) {
      cat("  â€¢", app, "\n")
    }
    cat("\n")
  }
  
  cat("Implementation considerations:\n")
  cat("- Bias in algorithms\n")
  cat("- Transparency requirements\n")
  cat("- Validation needs\n")
}

implement_ai_surveys()
```

---

# Slide 226: Passive Data Collection

```{r passive-data, echo=FALSE}
passive_sources <- tibble(
  Source = c("Mobile CDR", "Social media", "Sensors", "Satellite", "Web scraping"),
  Data_Type = c("Location/calls", "Text/networks", "Movement/environment", 
                "Land use", "Prices/sentiment"),
  Survey_Application = c("Mobility studies", "Opinion tracking", "Time use",
                        "Area sampling", "Price indices"),
  Challenges = c("Privacy", "Bias", "Consent", "Resolution", "Ethics")
)

passive_sources %>%
  gt() %>%
  tab_header(
    title = "Passive Data for Surveys",
    subtitle = "Complementing traditional collection"
  )
```

---

# Slide 227: Blockchain for Surveys

```{r blockchain-surveys, echo=TRUE}
# Blockchain implementation for surveys
implement_blockchain_survey <- function() {
  
  cat("BLOCKCHAIN IN SURVEYS\n")
  cat("====================\n\n")
  
  use_cases <- list(
    "Consent Management" = "Immutable consent records",
    "Data Integrity" = "Tamper-proof responses",
    "Incentive Payments" = "Smart contract rewards",
    "Panel Management" = "Decentralized participant registry",
    "Quality Assurance" = "Transparent audit trail"
  )
  
  cat("Use cases:\n")
  for(use in names(use_cases)) {
    cat(sprintf("  %-20s: %s\n", use, use_cases[[use]]))
  }
  
  cat("\nImplementation example:\n")
  cat("1. Response submitted â†’ Hash created\n")
  cat("2. Hash added to blockchain\n")
  cat("3. Timestamp and signature recorded\n")
  cat("4. Immutable proof of data collection\n")
  
  cat("\nBenefits:\n")
  cat("âœ“ Transparency\n")
  cat("âœ“ Security\n")
  cat("âœ“ Auditability\n")
  cat("âœ“ Trust\n")
}

implement_blockchain_survey()
```

---

# MODULE 18: INTERNATIONAL FRAMEWORKS
## Slides 228-250

---

# Slide 228: UN Statistical Standards

```{r un-standards, echo=FALSE}
un_framework <- tibble(
  Principle = 1:10,
  Title = c("Relevance", "Professional standards", "Accountability",
            "Prevention of misuse", "Cost-effectiveness", "Confidentiality",
            "Legislation", "Coordination", "International standards", "Cooperation"),
  Application = c("Meet society needs", "Scientific methods", "Transparent methods",
                  "Proper interpretation", "Optimal resource use", "Privacy protection",
                  "Legal framework", "National coordination", "Use international concepts",
                  "Bilateral cooperation")
)

un_framework %>%
  select(Principle, Title, Application) %>%
  head(5) %>%
  gt() %>%
  tab_header(
    title = "UN Fundamental Principles of Official Statistics",
    subtitle = "First 5 of 10 principles"
  )
```

---

# Slide 229: SDG Indicators

```{r sdg-indicators, echo=TRUE}
# SDG indicator requirements
implement_sdg_monitoring <- function() {
  
  cat("SDG INDICATOR MONITORING\n")
  cat("=======================\n\n")
  
  # Example: SDG 1.1.1 - Extreme poverty
  sdg_1_1_1 <- list(
    indicator = "Proportion below $2.15/day (2017 PPP)",
    data_source = "Household survey",
    frequency = "Annual or biennial",
    disaggregation = c("Sex", "Age", "Urban/rural", "Disability"),
    quality_requirements = c(
      "CV < 10% at national level",
      "Harmonized methodology",
      "Validated poverty line",
      "PPP adjustments"
    )
  )
  
  cat("Example: SDG 1.1.1\n")
  cat("Indicator:", sdg_1_1_1$indicator, "\n")
  cat("Source:", sdg_1_1_1$data_source, "\n")
  cat("Disaggregation:", paste(sdg_1_1_1$disaggregation, collapse=", "), "\n\n")
  
  cat("Quality requirements:\n")
  for(req in sdg_1_1_1$quality_requirements) {
    cat("-", req, "\n")
  }
  
  cat("\nTotal SDG indicators from surveys: 92 of 231\n")
}

implement_sdg_monitoring()
```

---

# Slide 230: International Comparability

```{r comparability, echo=FALSE}
comparability_framework <- tibble(
  Level = c("Concepts", "Definitions", "Classifications", "Methods", "Quality"),
  Standard = c("UN SNA", "ILO definitions", "ISIC/ISCO", "UN handbook", "IMF DQAF"),
  Example = c("Household definition", "Employment status", "Industry codes",
              "Sampling methods", "Quality dimensions"),
  Harmonization = c("High", "High", "Medium", "Medium", "Low")
)

comparability_framework %>%
  gt() %>%
  tab_header(
    title = "International Comparability Framework",
    subtitle = "Achieving cross-country comparability"
  ) %>%
  data_color(
    columns = Harmonization,
    colors = scales::col_factor(
      palette = c("High" = "#d4edda", "Medium" = "#fff3cd", "Low" = "#ffcccc"),
      domain = c("High", "Medium", "Low")
    )
  )
```

---

# MODULE 19: CRISIS AND EMERGENCY SURVEYS
## Slides 231-250

---

# Slide 231: Rapid Response Surveys

```{r rapid-response, echo=TRUE}
# Rapid response survey design
design_rapid_survey <- function(crisis_type, timeframe_days = 7) {
  
  cat("RAPID RESPONSE SURVEY DESIGN\n")
  cat("===========================\n")
  cat("Crisis:", crisis_type, "\n")
  cat("Deployment:", timeframe_days, "days\n\n")
  
  rapid_design <- list(
    sample = "Previous respondents or RDD",
    size = "500-1000 for quick estimates",
    mode = "Phone or SMS only",
    questionnaire = "5-10 key questions",
    duration = "5 minutes maximum",
    analysis = "Simple weighted estimates"
  )
  
  cat("Design elements:\n")
  for(element in names(rapid_design)) {
    cat(sprintf("  %-15s: %s\n", element, rapid_design[[element]]))
  }
  
  cat("\nDay-by-day plan:\n")
  schedule <- c(
    "Day 1: Design and questionnaire",
    "Day 2: Programming and testing",
    "Day 3-5: Data collection", 
    "Day 6: Processing and weights",
    "Day 7: Analysis and release"
  )
  
  for(day in schedule) {
    cat("  ", day, "\n")
  }
  
  return(rapid_design)
}

covid_survey <- design_rapid_survey("Pandemic", 7)
```

---

# Slide 232: High-Frequency Monitoring

```{r high-frequency, echo=FALSE}
hf_design <- tibble(
  Wave = paste("Week", 1:8),
  Sample_Size = c(1000, 1000, 900, 850, 800, 750, 700, 650),
  Topics = c("Core", "Core", "Core+Health", "Core", "Core+Econ", "Core", "Core+Social", "Core"),
  Mode = c("Phone", "SMS", "Phone", "SMS", "Phone", "SMS", "Phone", "SMS"),
  Cost = c(20000, 5000, 18000, 4500, 16000, 4000, 14000, 3500)
)

hf_design %>%
  ggplot(aes(x = Wave, y = Sample_Size)) +
  geom_col(fill = "#0066cc", alpha = 0.7) +
  geom_text(aes(label = Mode), angle = 90, hjust = 0, vjust = 0.5) +
  labs(title = "High-Frequency Phone Survey Design",
       subtitle = "Weekly monitoring during crisis",
       y = "Sample Size") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

---

# MODULE 20: FUTURE OF SURVEYS
## Slides 233-250

---

# Slide 233: Digital Transformation

```{r digital-transformation, echo=TRUE}
# Future survey landscape
future_survey_landscape <- function() {
  
  cat("FUTURE OF SURVEY RESEARCH\n")
  cat("========================\n\n")
  
  transformations <- list(
    "2025-2027" = c(
      "Full CAPI adoption",
      "Real-time dashboards",
      "AI-assisted coding"
    ),
    
    "2028-2030" = c(
      "Voice-first surveys",
      "Passive data integration",
      "Automated quality control"
    ),
    
    "2031+" = c(
      "Virtual reality interviews",
      "Predictive sampling",
      "Continuous measurement"
    )
  )
  
  for(period in names(transformations)) {
    cat(period, ":\n")
    for(change in transformations[[period]]) {
      cat("  â†’", change, "\n")
    }
    cat("\n")
  }
  
  cat("Persistent challenges:\n")
  cat("- Digital divide\n")
  cat("- Privacy concerns\n")
  cat("- Survey fatigue\n")
  cat("- Cost pressures\n")
}

future_survey_landscape()
```

---

# Slide 234: Hybrid Data Systems

```{r hybrid-systems, echo=FALSE}
hybrid_architecture <- tibble(
  Component = c("Survey data", "Admin data", "Big data", "Sensor data", "Model-based"),
  Strength = c("Designed", "Complete", "Timely", "Objective", "Small areas"),
  Weakness = c("Expensive", "Limited variables", "Biased", "Limited coverage", "Assumptions"),
  Integration = c("Core", "Validation", "Nowcasting", "Supplement", "Enhancement")
)

hybrid_architecture %>%
  gt() %>%
  tab_header(
    title = "Hybrid Statistical Systems",
    subtitle = "Combining multiple data sources"
  )
```

---

# Slide 235: Adaptive Survey Design Evolution

```{r adaptive-evolution, echo=TRUE}
# Next generation adaptive design
implement_adaptive_design <- function() {
  
  cat("ADAPTIVE DESIGN 2.0\n")
  cat("==================\n\n")
  
  cat("Real-time optimization:\n")
  
  components <- list(
    "Machine Learning" = "Predict response propensity hourly",
    "Dynamic Allocation" = "Shift resources automatically",
    "Cost Monitoring" = "Track cost per complete live",
    "Quality Metrics" = "Monitor representativeness continuously",
    "Intervention Triggers" = "Automated design changes"
  )
  
  for(comp in names(components)) {
    cat(sprintf("  %-20s: %s\n", comp, components[[comp]]))
  }
  
  cat("\nExample intervention:\n")
  cat("IF response_rate < 0.60 AND day > 5 THEN\n")
  cat("  increase_incentive(10)\n")
  cat("  deploy_best_interviewers()\n")
  cat("  switch_to_evening_calls()\n")
  cat("END IF\n")
  
  cat("\nExpected improvement: 25% cost reduction\n")
}

implement_adaptive_design()
```

---

# MODULE 21: CAPACITY BUILDING
## Slides 236-250

---

# Slide 236: Training Framework

```{r training-framework, echo=FALSE}
training_modules <- tibble(
  Level = c("Basic", "Intermediate", "Advanced", "Expert"),
  Duration = c("1 week", "2 weeks", "1 month", "3 months"),
  Topics = c("Survey basics, Ethics", "Sampling, Weights", "Variance, SAE", "Research, Innovation"),
  Certification = c("Field interviewer", "Survey analyst", "Survey statistician", "Survey scientist"),
  Participants = c(100, 50, 20, 5)
)

training_modules %>%
  gt() %>%
  tab_header(
    title = "Survey Capacity Building Program",
    subtitle = "Structured training pathway"
  )
```

---

# Slide 237: Knowledge Management

```{r knowledge-management, echo=TRUE}
# Build institutional knowledge
manage_survey_knowledge <- function() {
  
  cat("SURVEY KNOWLEDGE MANAGEMENT\n")
  cat("==========================\n\n")
  
  knowledge_assets <- list(
    explicit = c(
      "Documentation standards",
      "Code libraries",
      "Training materials",
      "Best practice guides"
    ),
    
    tacit = c(
      "Field experience",
      "Problem-solving skills",
      "Stakeholder relationships",
      "Quality intuition"
    )
  )
  
  cat("Knowledge capture:\n")
  cat("\nEXPLICIT KNOWLEDGE:\n")
  for(item in knowledge_assets$explicit) {
    cat("  âœ“", item, "\n")
  }
  
  cat("\nTACIT KNOWLEDGE:\n")
  for(item in knowledge_assets$tacit) {
    cat("  âœ“", item, "\n")
  }
  
  cat("\nTransfer mechanisms:\n")
  cat("- Mentoring programs\n")
  cat("- Communities of practice\n")
  cat("- After-action reviews\n")
  cat("- Job rotation\n")
  cat("- Documentation requirements\n")
}

manage_survey_knowledge()
```

---

# Slide 238: Building Survey Infrastructure

```{r survey-infrastructure, echo=FALSE}
infrastructure <- tibble(
  Component = c("Legal framework", "IT systems", "Field network", "Quality system", "Dissemination"),
  Current = c("Outdated", "Basic", "Ad-hoc", "Informal", "Limited"),
  Target = c("Modern act", "Integrated platform", "Permanent staff", "ISO certified", "Open data"),
  Investment = c("Low", "High", "Medium", "Medium", "Low"),
  Priority = c(1, 2, 3, 4, 5)
)

infrastructure %>%
  arrange(Priority) %>%
  gt() %>%
  tab_header(
    title = "Survey Infrastructure Development",
    subtitle = "Building sustainable capacity"
  ) %>%
  data_color(
    columns = Priority,
    colors = scales::col_numeric(
      palette = c("#d4edda", "#fff3cd", "#ffcccc"),
      domain = c(1, 5)
    )
  )
```

---

# MODULE 22: ETHICS AND PRIVACY
## Slides 239-250

---

# Slide 239: Ethical Framework

```{r ethics-framework, echo=TRUE}
# Survey ethics framework
implement_ethics_framework <- function() {
  
  cat("SURVEY ETHICS FRAMEWORK\n")
  cat("======================\n\n")
  
  principles <- list(
    "Respect for Persons" = c(
      "Informed consent",
      "Voluntary participation",
      "Right to withdraw"
    ),
    
    "Beneficence" = c(
      "Maximize benefits",
      "Minimize harm",
      "Risk assessment"
    ),
    
    "Justice" = c(
      "Fair selection",
      "Equitable burden",
      "Share benefits"
    ),
    
    "Integrity" = c(
      "Honest methods",
      "Transparent reporting",
      "Acknowledge limitations"
    )
  )
  
  for(principle in names(principles)) {
    cat(toupper(principle), "\n")
    for(element in principles[[principle]]) {
      cat("  â€¢", element, "\n")
    }
    cat("\n")
  }
  
  cat("Operationalization:\n")
  cat("âœ“ Ethics review board\n")
  cat("âœ“ Standard protocols\n")
  cat("âœ“ Training requirements\n")
  cat("âœ“ Monitoring system\n")
}

implement_ethics_framework()
```

---

# Slide 240: Data Privacy Compliance

```{r privacy-compliance, echo=FALSE}
privacy_requirements <- tibble(
  Regulation = c("GDPR", "CCPA", "POPI", "National Stats Law"),
  Jurisdiction = c("EU", "California", "South Africa", "National"),
  Key_Requirements = c("Consent, right to delete", "Opt-out, disclosure",
                       "Purpose limitation", "Statistical use only"),
  Penalties = c("4% revenue", "$7,500 per violation", "10M Rand", "Criminal")
)

privacy_requirements %>%
  gt() %>%
  tab_header(
    title = "Data Privacy Regulations",
    subtitle = "Compliance requirements for surveys"
  ) %>%
  tab_style(
    style = cell_fill(color = "#ffe6e6"),
    locations = cells_body(columns = Penalties)
  )
```

---

# Slide 241: Informed Consent Design

```{r informed-consent, echo=TRUE}
# Design informed consent process
design_consent_process <- function(survey_type, sensitive_topics = FALSE) {
  
  cat("INFORMED CONSENT DESIGN\n")
  cat("======================\n")
  cat("Survey type:", survey_type, "\n")
  cat("Sensitive topics:", sensitive_topics, "\n\n")
  
  consent_elements <- list(
    required = c(
      "Study purpose",
      "Voluntary participation",
      "Confidentiality measures",
      "How data will be used",
      "Contact information"
    ),
    
    conditional = c(
      "Audio recording permission",
      "Data linkage consent",
      "Follow-up contact permission",
      "International data transfer"
    )
  )
  
  cat("REQUIRED elements:\n")
  for(element in consent_elements$required) {
    cat("  â˜‘", element, "\n")
  }
  
  cat("\nCONDITIONAL elements:\n")
  for(element in consent_elements$conditional) {
    cat("  â˜", element, "\n")
  }
  
  cat("\nConsent documentation:\n")
  cat("- Written (paper/electronic)\n")
  cat("- Verbal (recorded)\n")
  cat("- Implied (by participation)\n")
  
  return(consent_elements)
}

consent <- design_consent_process("Health survey", TRUE)
```

---

# MODULE 23: COMMUNICATION AND DISSEMINATION
## Slides 242-250

---

# Slide 242: Stakeholder Engagement

```{r stakeholder-engagement, echo=FALSE}
stakeholders <- tibble(
  Group = c("Government", "Researchers", "Media", "Public", "Donors"),
  Interest = c("Policy evidence", "Microdata", "Headlines", "Results", "Impact"),
  Format = c("Brief + dashboard", "Dataset + docs", "Press release", "Infographic", "Report"),
  Timing = c("Pre-release", "Embargo", "Release day", "Release day", "Quarterly"),
  Engagement = c("High", "Medium", "High", "Low", "High")
)

stakeholders %>%
  gt() %>%
  tab_header(
    title = "Stakeholder Communication Strategy",
    subtitle = "Targeted dissemination approach"
  )
```

---

# Slide 243: Data Visualization Best Practices

```{r dataviz-best-practices, echo=TRUE}
# Survey data visualization principles
create_effective_visualizations <- function() {
  
  cat("SURVEY DATA VISUALIZATION\n")
  cat("========================\n\n")
  
  cat("Core principles:\n")
  principles <- c(
    "Show uncertainty (confidence intervals)",
    "Weight appropriately (not raw counts)",
    "Indicate sample sizes",
    "Highlight survey design effects",
    "Use appropriate scales"
  )
  
  for(i in 1:length(principles)) {
    cat(i, ".", principles[i], "\n")
  }
  
  cat("\nVisualization types:\n")
  viz_types <- list(
    "Proportions" = "Bar chart with error bars",
    "Trends" = "Line graph with confidence bands",
    "Comparisons" = "Dot plot with CIs",
    "Distributions" = "Weighted histogram/density",
    "Relationships" = "Scatter with size = weight"
  )
  
  for(type in names(viz_types)) {
    cat(sprintf("  %-15s: %s\n", type, viz_types[[type]]))
  }
  
  cat("\nAccessibility:\n")
  cat("- Color-blind friendly palettes\n")
  cat("- Alternative text descriptions\n")
  cat("- High contrast\n")
  cat("- Multiple formats (table + chart)\n")
}

create_effective_visualizations()
```

---

# Slide 244: Public Use Files

```{r public-use-files, echo=FALSE}
puf_preparation <- tibble(
  Step = c("Review", "De-identify", "Disclosure control", "Documentation", "Review", "Release"),
  Process = c("Legal/ethics check", "Remove identifiers", "Apply SDC methods",
              "Create codebook", "Final disclosure review", "Publish dataset"),
  Responsible = c("Legal team", "Data team", "Methodology", "Documentation team",
                  "Disclosure board", "Dissemination"),
  Duration = c("1 week", "2 days", "1 week", "2 weeks", "3 days", "1 day")
)

puf_preparation %>%
  gt() %>%
  tab_header(
    title = "Public Use File Preparation",
    subtitle = "6-week process for safe data release"
  )
```

---

# Slide 245: Report Automation

```{r report-automation, echo=TRUE}
# Automated survey reporting
automate_survey_reports <- function(survey_data, output_format = "HTML") {
  
  cat("AUTOMATED REPORT GENERATION\n")
  cat("==========================\n\n")
  
  cat("Report components:\n")
  components <- c(
    "Executive summary (1 page)",
    "Key findings (bullets)",
    "Methodology box",
    "Main estimates (tables)",
    "Trends (charts)",
    "Comparisons (graphics)",
    "Quality indicators",
    "Technical appendix"
  )
  
  for(comp in components) {
    cat("  âœ“", comp, "\n")
  }
  
  cat("\nR implementation:\n")
  cat("---\n")
  cat("library(rmarkdown)\n")
  cat("library(officer)  # Word\n")
  cat("library(pagedown) # PDF\n")
  cat("library(flexdashboard) # Dashboard\n\n")
  
  cat("render('survey_report.Rmd',\n")
  cat("       output_format = '", output_format, "',\n", sep = "")
  cat("       params = list(data = survey_data))\n")
  
  cat("\nOutput formats available:\n")
  cat("HTML | PDF | Word | PowerPoint | Dashboard\n")
}

automate_survey_reports(NULL)
```

---

# MODULE 24: LESSONS LEARNED
## Slides 246-250

---

# Slide 246: Common Survey Failures

```{r survey-failures, echo=FALSE}
failures <- tibble(
  Problem = c("Low response", "Coverage gaps", "Measurement error", 
              "Weight explosion", "Budget overrun"),
  Root_Cause = c("Poor design", "Old frame", "Bad questions", 
                 "Non-response bias", "Scope creep"),
  Impact = c("Biased estimates", "Missing groups", "Invalid data",
             "Unstable estimates", "Incomplete survey"),
  Prevention = c("Pilot testing", "Frame updates", "Cognitive testing",
                 "Adaptive design", "Clear scope")
)

failures %>%
  gt() %>%
  tab_header(
    title = "Common Survey Failures",
    subtitle = "Learn from others' mistakes"
  ) %>%
  tab_style(
    style = cell_fill(color = "#ffe6e6"),
    locations = cells_body(columns = Impact)
  )
```

---

# Slide 247: Success Factors

```{r success-factors, echo=TRUE}
# Critical success factors for surveys
ensure_survey_success <- function() {
  
  cat("SURVEY SUCCESS FACTORS\n")
  cat("=====================\n\n")
  
  success_factors <- list(
    Planning = c(
      "Clear objectives",
      "Realistic timeline",
      "Adequate budget"
    ),
    
    Design = c(
      "Appropriate methodology",
      "Quality questionnaire",
      "Sufficient sample size"
    ),
    
    Implementation = c(
      "Trained staff",
      "Quality control",
      "Responsive management"
    ),
    
    Analysis = c(
      "Proper weighting",
      "Variance estimation",
      "Honest reporting"
    )
  )
  
  cat("Critical success factors:\n\n")
  for(phase in names(success_factors)) {
    cat(toupper(phase), "PHASE:\n")
    for(factor in success_factors[[phase]]) {
      cat("  â˜…", factor, "\n")
    }
    cat("\n")
  }
  
  cat("Remember: Quality over quantity!\n")
}

ensure_survey_success()
```

---

# Slide 248: Regional Best Practices

```{r regional-practices, echo=FALSE}
regional_best <- tibble(
  Country = c("South Africa", "Kenya", "Ghana", "Rwanda", "Mauritius"),
  Innovation = c("GIS frame", "Mobile money incentives", "CAPI adoption",
                 "Admin integration", "Web-first design"),
  Impact = c("Better coverage", "Higher response", "Faster processing",
             "Cost savings", "Youth participation"),
  Scalability = c("High", "High", "High", "Medium", "Low")
)

regional_best %>%
  gt() %>%
  tab_header(
    title = "African Survey Innovations",
    subtitle = "Learning from regional leaders"
  ) %>%
  data_color(
    columns = Scalability,
    colors = scales::col_factor(
      palette = c("High" = "#d4edda", "Medium" = "#fff3cd", "Low" = "#ffcccc"),
      domain = c("High", "Medium", "Low")
    )
  )
```

---

# Slide 249: Harry's Wisdom

## Key Takeaways from the Week

```{r harrys-wisdom, echo=TRUE}
# Harry's final advice
harrys_final_wisdom <- function() {
  
  cat("HARRY'S TOP 10 SURVEY COMMANDMENTS\n")
  cat("==================================\n\n")
  
  commandments <- c(
    "Know thy population before sampling",
    "Test thy questionnaire with real people",
    "Document everything as you go",
    "Weight properly or suffer biased results",
    "Calculate variance correctly",
    "Never ignore nonresponse",
    "Quality beats quantity every time",
    "Invest in training field staff",
    "Automate what you can, validate everything",
    "Learn from each survey for the next"
  )
  
  for(i in 1:10) {
    cat(sprintf("%2d. %s\n", i, commandments[i]))
  }
  
  cat("\n'Good surveys are not accidents -\n")
  cat("they result from careful planning,\n")
  cat("rigorous implementation, and\n")
  cat("continuous learning.'\n")
  cat("        - Harry, Survey Scientist\n")
}

harrys_final_wisdom()
```

---

# Slide 250: Course Completion

## Friday 5:00 PM - Victory!

```{r course-completion, echo=FALSE}
completion_summary <- tibble(
  Day = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday"),
  Topic = c("Foundations", "Frame & Design", "Weights & Variance", 
            "Integration", "Advanced Topics"),
  Competency_Gained = c("UNSD/WB standards", "Multi-frame design", 
                        "Complex estimation", "System automation", 
                        "Research methods"),
  Confidence = c(40, 60, 75, 85, 95)
)

completion_summary %>%
  ggplot(aes(x = Day, y = Confidence)) +
  geom_line(color = "#0066cc", size = 3) +
  geom_point(size = 5, color = "#0066cc") +
  geom_text(aes(label = paste0(Confidence, "%")), vjust = -1, size = 5) +
  labs(title = "Harry's Week: From Crisis to Confidence",
       subtitle = "Building world-class survey capability",
       y = "Confidence Level (%)") +
  theme_minimal() +
  ylim(0, 100)
```

**Minister's closing remarks:** "This transformation will revolutionize our statistical system!"

**Harry's thoughts:** "From panic to proficiency in one week. We did it!"

---

class: inverse, center, middle

# ðŸŽ“ COURSE COMPLETE ðŸŽ“

## You are now equipped to:
### âœ… Design complex surveys to international standards
### âœ… Implement advanced sampling techniques
### âœ… Calculate proper weights and variances
### âœ… Integrate modern technology and methods
### âœ… Lead statistical transformation

---

# APPENDICES AND RESOURCES
## Slides 251-400

---

# Slide 251: R Code Repository

## Complete Script Library

```{r code-repository, echo=TRUE}
# Master script directory
create_script_library <- function() {
  
  cat("COMPLETE R SCRIPT LIBRARY\n")
  cat("========================\n\n")
  
  scripts <- list(
    "01_sampling/" = c(
      "pps_selection.R",
      "stratified_sample.R", 
      "systematic_sample.R",
      "cluster_sample.R"
    ),
    "02_frames/" = c(
      "frame_assessment.R",
      "multi_frame_integration.R",
      "frame_updating.R"
    ),
    "03_weights/" = c(
      "base_weights.R",
      "nonresponse_adjustment.R",
      "calibration.R",
      "weight_trimming.R"
    ),
    "04_variance/" = c(
      "taylor_linearization.R",
      "replicate_weights.R",
      "bootstrap_variance.R"
    ),
    "05_analysis/" = c(
      "survey_means.R",
      "regression.R",
      "domain_estimation.R"
    )
  )
  
  cat("GitHub repository: github.com/sadc/survey-methods\n\n")
  
  for(folder in names(scripts)) {
    cat(folder, "\n")
    for(script in scripts[[folder]]) {
      cat("  â””â”€â”€", script, "\n")
    }
  }
  
  cat("\nTotal scripts: 50+\n")
  cat("Documentation: Complete\n")
  cat("License: MIT\n")
}

create_script_library()
```

---

# Slide 252: Mathematical Formulas

## Key Survey Statistics Formulas

```{r formulas, echo=FALSE}
formulas <- tribble(
  ~Statistic, ~Formula, ~Description,
  "HT estimator", "Å¶ = Î£(y_i/Ï€_i)", "Horvitz-Thompson total",
  "Variance", "V(Å¶) = Î£Î£((Ï€_ij - Ï€_i*Ï€_j)/Ï€_ij)*y_i*y_j/Ï€_i*Ï€_j", "HT variance",
  "GREG", "Å¶_GREG = Å¶_HT + (X - XÌ‚_HT)'B", "Calibration estimator",
  "Design effect", "DEFF = V(Î¸Ì‚_complex)/V(Î¸Ì‚_srs)", "Variance inflation",
  "ICC", "Ï = ÏƒÂ²_between/(ÏƒÂ²_between + ÏƒÂ²_within)", "Intraclass correlation"
)

formulas %>%
  gt() %>%
  tab_header(
    title = "Essential Survey Formulas",
    subtitle = "Mathematical foundation"
  )
```

---

# Slide 253: Software Comparison

```{r software-comparison, echo=FALSE}
software <- tibble(
  Software = c("R", "Stata", "SAS", "SPSS", "Python"),
  Strengths = c("Free, flexible", "User-friendly", "Enterprise", "GUI", "ML integration"),
  Survey_Features = c("Excellent", "Excellent", "Good", "Basic", "Growing"),
  Learning_Curve = c("Steep", "Moderate", "Steep", "Easy", "Moderate"),
  Cost = c("Free", "$1,800", "$9,000+", "$5,000+", "Free")
)

software %>%
  gt() %>%
  tab_header(
    title = "Survey Software Comparison",
    subtitle = "Choosing the right tool"
  )
```

---

# Slide 254: Sample Size Tables

```{r sample-size-tables, echo=TRUE}
# Generate sample size tables
generate_sample_size_table <- function() {
  
  cat("SAMPLE SIZE QUICK REFERENCE\n")
  cat("==========================\n\n")
  
  # For proportions
  cat("For PROPORTIONS (95% CI, P=0.5):\n")
  cat("Margin of Error -> Sample Size\n")
  
  margins <- c(0.01, 0.02, 0.03, 0.05, 0.10)
  for(me in margins) {
    n <- ceiling(0.25 / (me^2 / 3.84))
    cat(sprintf("  Â±%.0f%%  ->  n = %d\n", me*100, n))
  }
  
  cat("\nWith DESIGN EFFECT = 2:\n")
  for(me in margins) {
    n <- ceiling(0.25 / (me^2 / 3.84)) * 2
    cat(sprintf("  Â±%.0f%%  ->  n = %d\n", me*100, n))
  }
  
  cat("\nFor DOMAIN estimation:\n")
  cat("Multiply by 1/proportion in domain\n")
  cat("Example: 20% domain -> n Ã— 5\n")
}

generate_sample_size_table()
```

---

# Slide 255: Standard Error Quick Formulas

```{r se-formulas, echo=FALSE}
se_guide <- tibble(
  Estimator = c("Mean", "Proportion", "Total", "Ratio", "Difference"),
  SRS_Formula = c("s/âˆšn", "âˆš(p(1-p)/n)", "NÃ—s/âˆšn", "Complex", "âˆš(SEâ‚Â² + SEâ‚‚Â²)"),
  With_FPC = c("Ã—âˆš((N-n)/N)", "Ã—âˆš((N-n)/N)", "Ã—âˆš((N-n)/N)", "Ã—âˆš((N-n)/N)", "Each term"),
  With_Clustering = c("Ã—âˆšDEFF", "Ã—âˆšDEFF", "Ã—âˆšDEFF", "Ã—âˆšDEFF", "Ã—âˆšDEFF")
)

se_guide %>%
  gt() %>%
  tab_header(
    title = "Standard Error Quick Reference",
    subtitle = "Common formulas with adjustments"
  )
```

---

# Slide 256: Response Rate Formulas

```{r response-rates, echo=TRUE}
# AAPOR response rate calculations
calculate_response_rates <- function() {
  
  cat("AAPOR RESPONSE RATE DEFINITIONS\n")
  cat("===============================\n\n")
  
  # Disposition codes
  cat("Disposition codes:\n")
  cat("I  = Complete interview\n")
  cat("P  = Partial interview\n")
  cat("R  = Refusal\n")
  cat("NC = Non-contact\n")
  cat("O  = Other\n")
  cat("UH = Unknown if household\n")
  cat("UO = Unknown other\n\n")
  
  # Response rate formulas
  cat("Response Rate 1 (minimum):\n")
  cat("RR1 = I / (I + P + R + NC + O + UH + UO)\n\n")
  
  cat("Response Rate 2 (partial included):\n")
  cat("RR2 = (I + P) / (I + P + R + NC + O + UH + UO)\n\n")
  
  cat("Response Rate 3 (estimated eligible):\n")
  cat("RR3 = I / (I + P + R + NC + O + e(UH + UO))\n")
  cat("where e = estimated proportion eligible\n\n")
  
  cat("Cooperation Rate:\n")
  cat("COOP = I / (I + P + R)\n")
}

calculate_response_rates()
```

---

# Slide 257: Glossary of Terms

```{r glossary, echo=FALSE}
glossary <- tibble(
  Term = c("CAPI", "DEFF", "EBLUP", "FPC", "GREG", "HT", "ICC", "PSU", "SAE", "TSE"),
  Full_Name = c(
    "Computer-Assisted Personal Interviewing",
    "Design Effect",
    "Empirical Best Linear Unbiased Predictor",
    "Finite Population Correction",
    "Generalized Regression Estimator",
    "Horvitz-Thompson",
    "Intraclass Correlation Coefficient",
    "Primary Sampling Unit",
    "Small Area Estimation",
    "Total Survey Error"
  ),
  Definition = c(
    "Electronic data collection using tablets",
    "Ratio of actual variance to SRS variance",
    "Small area estimation method",
    "Adjustment when sampling fraction is large",
    "Calibration estimation method",
    "Design-based estimation approach",
    "Measure of clustering effect",
    "First stage selection unit",
    "Methods for small domains",
    "Framework for all error sources"
  )
)

glossary %>%
  gt() %>%
  tab_header(
    title = "Survey Terminology Glossary",
    subtitle = "Key terms and acronyms"
  )
```

---

# Slide 258: Checklist Templates

```{r checklists, echo=TRUE}
# Master survey checklist
create_survey_checklist <- function() {
  
  cat("SURVEY IMPLEMENTATION CHECKLIST\n")
  cat("==============================\n\n")
  
  phases <- list(
    "PLANNING" = c(
      "â˜ Objectives defined",
      "â˜ Budget approved",
      "â˜ Timeline realistic",
      "â˜ Team assembled"
    ),
    
    "DESIGN" = c(
      "â˜ Frame assessed",
      "â˜ Sample size calculated",
      "â˜ Stratification planned",
      "â˜ Questionnaire tested"
    ),
    
    "FIELD" = c(
      "â˜ Training completed",
      "â˜ Materials ready",
      "â˜ Pilot conducted",
      "â˜ Monitoring system active"
    ),
    
    "PROCESSING" = c(
      "â˜ Data cleaning rules",
      "â˜ Weights calculated",
      "â˜ Variance estimated",
      "â˜ Documentation complete"
    )
  )
  
  for(phase in names(phases)) {
    cat(phase, "PHASE:\n")
    for(item in phases[[phase]]) {
      cat(" ", item, "\n")
    }
    cat("\n")
  }
  
  cat("Sign-off required at each phase gate\n")
}

create_survey_checklist()
```

---

# Slide 259: Common R Functions

```{r r-functions, echo=TRUE}
# Essential R functions for surveys
essential_survey_functions <- function() {
  
  cat("ESSENTIAL R SURVEY FUNCTIONS\n")
  cat("===========================\n\n")
  
  cat("# Setup\n")
  cat("library(survey)\n")
  cat("library(srvyr)  # dplyr-like syntax\n\n")
  
  cat("# Create survey design\n")
  cat("design <- svydesign(\n")
  cat("  ids = ~cluster,\n")
  cat("  strata = ~stratum,\n")
  cat("  weights = ~weight,\n")
  cat("  fpc = ~fpc,\n")
  cat("  data = mydata\n")
  cat(")\n\n")
  
  cat("# Estimation\n")
  cat("svymean(~variable, design)     # Mean\n")
  cat("svytotal(~variable, design)    # Total\n")
  cat("svyby(~y, ~domain, design, svymean)  # Domain\n")
  cat("svyquantile(~y, design, c(0.25, 0.5, 0.75))  # Quantiles\n\n")
  
  cat("# Variance\n")
  cat("SE()          # Standard errors\n")
  cat("cv()          # Coefficient of variation\n")
  cat("confint()     # Confidence intervals\n")
  cat("deff()        # Design effect\n")
}

essential_survey_functions()
```

---

# Slide 260: Data Quality Indicators

```{r quality-indicators2, echo=FALSE}
indicators <- tibble(
  Indicator = c("Unit response rate", "Item response rate", "Coverage rate",
                "Edit failure rate", "Imputation rate", "Coefficient of variation"),
  Formula = c("Completes/Eligible", "Answered/Applicable", "Frame/Population",
              "Failed edits/Total", "Imputed/Total", "SE/Estimate"),
  Good = c(">80%", ">95%", ">95%", "<5%", "<5%", "<5%"),
  Acceptable = c("70-80%", "90-95%", "90-95%", "5-10%", "5-10%", "5-15%"),
  Poor = c("<70%", "<90%", "<90%", ">10%", ">10%", ">15%")
)

indicators %>%
  gt() %>%
  tab_header(
    title = "Data Quality Thresholds",
    subtitle = "Standards for survey quality"
  ) %>%
  data_color(
    columns = c(Good, Acceptable, Poor),
    colors = scales::col_factor(
      palette = c("#d4edda", "#fff3cd", "#ffcccc"),
      domain = NULL
    )
  )
```

---

# Slide 261: Field Materials Templates

```{r field-materials, echo=TRUE}
# Generate field materials
create_field_materials <- function() {
  
  cat("FIELD MATERIALS PACKAGE\n")
  cat("======================\n\n")
  
  materials <- list(
    "Interviewer materials" = c(
      "ID badge",
      "Introduction letter",
      "Questionnaire (paper backup)",
      "Show cards",
      "Contact log",
      "Maps/GPS unit"
    ),
    
    "Training materials" = c(
      "Training manual",
      "Practice questionnaires",
      "Role-play scenarios",
      "FAQ document",
      "Ethics guidelines"
    ),
    
    "Respondent materials" = c(
      "Advance letter",
      "Brochure",
      "Consent form",
      "Thank you letter",
      "Contact card"
    )
  )
  
  for(category in names(materials)) {
    cat(toupper(category), ":\n")
    for(item in materials[[category]]) {
      cat("  â–¡", item, "\n")
    }
    cat("\n")
  }
  
  cat("Templates available at: survey-materials/\n")
}

create_field_materials()
```

---

# Slide 262: Budget Template

```{r budget-template, echo=FALSE}
budget <- tibble(
  Category = c("Personnel", "Training", "Field operations", "Technology", 
               "Processing", "Dissemination", "Overhead"),
  Percentage = c(35, 10, 25, 15, 8, 5, 2),
  Typical_Amount = c(175000, 50000, 125000, 75000, 40000, 25000, 10000)
) %>%
  mutate(
    Cumulative = cumsum(Typical_Amount),
    Notes = c("Includes management", "3-week program", "Transport, incentives",
              "Tablets, software", "Data processing", "Reports, website", "Admin")
  )

budget %>%
  gt() %>%
  tab_header(
    title = "Survey Budget Template",
    subtitle = "Based on $500,000 total budget"
  ) %>%
  fmt_currency(columns = c(Typical_Amount, Cumulative)) %>%
  fmt_percent(columns = Percentage, scale_values = FALSE)
```

---

# Slide 263: Timeline Template

```{r timeline-template, echo=TRUE}
# Survey timeline generator
generate_survey_timeline <- function(months = 12) {
  
  cat("SURVEY TIMELINE (", months, "months)\n")
  cat("=======================\n\n")
  
  phases <- list(
    "Planning" = c(1, 2),
    "Design" = c(2, 3),
    "Testing" = c(3, 4),
    "Training" = c(4, 5),
    "Field" = c(5, 8),
    "Processing" = c(7, 10),
    "Analysis" = c(9, 11),
    "Reporting" = c(11, 12)
  )
  
  cat("Month: ")
  for(m in 1:months) cat(sprintf("%2d ", m))
  cat("\n")
  
  for(phase in names(phases)) {
    cat(sprintf("%-11s", phase))
    for(m in 1:months) {
      if(m >= phases[[phase]][1] && m <= phases[[phase]][2]) {
        cat(" â–  ")
      } else {
        cat(" Â· ")
      }
    }
    cat("\n")
  }
  
  cat("\nâ–  = Active phase\n")
  cat("Note: Phases overlap for efficiency\n")
}

generate_survey_timeline(12)
```

---

# Slide 264: Contract Templates

```{r contracts, echo=FALSE}
contract_elements <- tibble(
  Section = c("Scope", "Deliverables", "Timeline", "Payment", "Quality", "IP Rights"),
  Key_Points = c(
    "Clear objectives, sample size, coverage",
    "Data files, reports, documentation",
    "Milestones with dates",
    "Schedule tied to deliverables",
    "Quality standards, penalties",
    "Data ownership, usage rights"
  ),
  Common_Issues = c(
    "Scope creep",
    "Unclear formats",
    "Unrealistic dates",
    "Front-loaded payments",
    "No quality metrics",
    "Ambiguous ownership"
  )
)

contract_elements %>%
  gt() %>%
  tab_header(
    title = "Survey Contract Elements",
    subtitle = "Key sections for outsourcing"
  )
```

---

# Slide 265: Training Curricula

```{r training-curricula, echo=TRUE}
# Design training program
design_training_curriculum <- function(role = "interviewer", days = 5) {
  
  cat("TRAINING CURRICULUM:", toupper(role), "\n")
  cat("Duration:", days, "days\n")
  cat("========================\n\n")
  
  if(role == "interviewer") {
    curriculum <- list(
      "Day 1" = c("Survey overview", "Ethics", "Sampling basics"),
      "Day 2" = c("Questionnaire review", "Skip patterns", "Practice"),
      "Day 3" = c("Interview techniques", "Difficult situations", "Role play"),
      "Day 4" = c("Technology training", "Data transmission", "Troubleshooting"),
      "Day 5" = c("Field practice", "Feedback", "Certification test")
    )
  } else if(role == "supervisor") {
    curriculum <- list(
      "Day 1" = c("Management responsibilities", "Quality control"),
      "Day 2" = c("Monitoring tools", "Problem solving"),
      "Day 3" = c("Team management", "Motivation"),
      "Day 4" = c("Reporting", "Documentation"),
      "Day 5" = c("Emergency procedures", "Evaluation")
    )
  }
  
  for(day in names(curriculum)) {
    cat(day, ":\n")
    for(topic in curriculum[[day]]) {
      cat("  â€¢", topic, "\n")
    }
    cat("\n")
  }
  
  cat("Assessment: Written test + practical\n")
}

design_training_curriculum("interviewer", 5)
```

---

# Slide 266: Quality Assurance Plans

```{r qa-plans, echo=FALSE}
qa_plan <- tibble(
  Stage = c("Pre-field", "During field", "Post-field", "Analysis", "Dissemination"),
  Activities = c(
    "Questionnaire testing, Training assessment",
    "Supervision, Spot checks, Audio recording",
    "Data cleaning, Consistency checks",
    "Verification, Sensitivity analysis",
    "Review process, Disclosure check"
  ),
  Metrics = c(
    "Test scores >80%",
    "5% verification rate",
    "Edit failure <5%",
    "Replicate key findings",
    "Zero disclosure risk"
  ),
  Responsible = c("QA team", "Supervisors", "Data team", "Analysts", "Review board")
)

qa_plan %>%
  gt() %>%
  tab_header(
    title = "Quality Assurance Plan",
    subtitle = "Stage-gate quality process"
  )
```

---

# Slide 267: Metadata Standards

```{r metadata-standards, echo=TRUE}
# DDI metadata structure
create_ddi_metadata <- function() {
  
  cat("DDI METADATA STRUCTURE\n")
  cat("=====================\n\n")
  
  cat("<?xml version='1.0' encoding='UTF-8'?>\n")
  cat("<codeBook version='2.5'>\n\n")
  
  cat("  <stdyDscr>\n")
  cat("    <citation>\n")
  cat("      <titlStmt>\n")
  cat("        <titl>Household Survey 2025</titl>\n")
  cat("      </titlStmt>\n")
  cat("    </citation>\n")
  cat("  </stdyDscr>\n\n")
  
  cat("  <fileDscr>\n")
  cat("    <fileTxt>\n")
  cat("      <fileName>household_2025.dta</fileName>\n")
  cat("      <dimnsns>\n")
  cat("        <caseQnty>5000</caseQnty>\n")
  cat("        <varQnty>250</varQnty>\n")
  cat("      </dimnsns>\n")
  cat("    </fileTxt>\n")
  cat("  </fileDscr>\n\n")
  
  cat("  <dataDscr>\n")
  cat("    <!-- Variable descriptions -->\n")
  cat("  </dataDscr>\n\n")
  
  cat("</codeBook>\n")
  
  cat("\nDDI tools: Nesstar, Colectica, R package 'DDIwR'\n")
}

create_ddi_metadata()
```

---

# Slide 268: Report Templates

```{r report-templates, echo=FALSE}
report_structure <- tibble(
  Section = c("Executive Summary", "Introduction", "Methodology", "Key Findings",
              "Detailed Results", "Conclusions", "Appendices"),
  Pages = c(2, 3, 5, 10, 30, 3, 20),
  Content = c(
    "Main findings, recommendations",
    "Background, objectives",
    "Design, sample, collection",
    "Major indicators with graphics",
    "All tables and analysis",
    "Implications, limitations",
    "Technical details, questionnaire"
  )
)

report_structure %>%
  mutate(Cumulative = cumsum(Pages)) %>%
  gt() %>%
  tab_header(
    title = "Survey Report Template",
    subtitle = "Standard structure (~75 pages)"
  )
```

---

# Slide 269: Dashboard Examples

```{r dashboard-examples, echo=TRUE}
# Create survey dashboard structure
design_survey_dashboard <- function() {
  
  cat("SURVEY DASHBOARD LAYOUT\n")
  cat("======================\n\n")
  
  cat("Header: Survey Title, Date, Response Rate\n")
  cat("=" %>% rep(50) %>% paste(collapse = ""), "\n\n")
  
  cat("Row 1: KEY INDICATORS\n")
  cat("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n")
  cat("â”‚Poverty %â”‚ â”‚Unemploy%â”‚ â”‚Literacy%â”‚ â”‚Access % â”‚\n")
  cat("â”‚  23.4   â”‚ â”‚  18.2   â”‚ â”‚  87.3   â”‚ â”‚  64.5   â”‚\n")
  cat("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n")
  
  cat("Row 2: TRENDS AND COMPARISONS\n")
  cat("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n")
  cat("â”‚ Time Series      â”‚ â”‚ Regional Compare â”‚\n")
  cat("â”‚ [Line Chart]     â”‚ â”‚ [Bar Chart]      â”‚\n")
  cat("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n")
  
  cat("Row 3: DETAILED TABLES\n")
  cat("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n")
  cat("â”‚ Disaggregated Results               â”‚\n")
  cat("â”‚ [Interactive Table]                 â”‚\n")
  cat("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n")
  
  cat("Tools: flexdashboard, shiny, plotly\n")
}

design_survey_dashboard()
```

---

# Slide 270: Case Studies

```{r case-studies, echo=FALSE}
cases <- tibble(
  Country = c("Rwanda", "South Africa", "Kenya"),
  Survey = c("EICV", "GHS", "KIHBS"),
  Innovation = c("Tablet-based", "Multi-frame", "Mobile money"),
  Challenge = c("Hilly terrain", "Gated communities", "Urban slums"),
  Solution = c("Local recruitment", "Multiple modes", "Community entry"),
  Result = c("95% response", "Improved coverage", "Higher quality")
)

cases %>%
  gt() %>%
  tab_header(
    title = "African Survey Case Studies",
    subtitle = "Learning from regional experience"
  )
```

---

# Slide 271: International Resources

```{r resources, echo=TRUE}
# Compile international resources
compile_survey_resources <- function() {
  
  cat("INTERNATIONAL SURVEY RESOURCES\n")
  cat("=============================\n\n")
  
  resources <- list(
    "Guidelines" = c(
      "UN: Household Survey Handbook",
      "World Bank: LSMS Guidelines",
      "Eurostat: Quality Guidelines",
      "OECD: Survey Methods"
    ),
    
    "Software" = c(
      "R: survey, sampling, srvyr packages",
      "CSPro: Census and Survey Processing",
      "Survey Solutions: World Bank platform",
      "ODK: Open Data Kit"
    ),
    
    "Networks" = c(
      "IASS: International Association of Survey Statisticians",
      "AAPOR: American Association for Public Opinion Research",
      "ESRA: European Survey Research Association",
      "ISI: International Statistical Institute"
    ),
    
    "Training" = c(
      "IHSN: International Household Survey Network",
      "MEASURE DHS: Online courses",
      "Statistics Canada: Survey methods course",
      "Michigan Summer Program"
    )
  )
  
  for(category in names(resources)) {
    cat(toupper(category), ":\n")
    for(resource in resources[[category]]) {
      cat("  â€¢", resource, "\n")
    }
    cat("\n")
  }
}

compile_survey_resources()
```

---

# Slide 272: Troubleshooting Guide

```{r troubleshooting, echo=FALSE}
problems <- tibble(
  Problem = c("Low response rate", "High variance", "Coverage gaps", 
              "Measurement error", "Processing delays"),
  Diagnosis = c("Check contact protocol", "Review design effect", "Assess frame",
                "Test questions", "Review workflow"),
  Solution = c("Increase attempts, incentives", "Increase sample, improve design",
               "Multiple frames", "Cognitive testing", "Automate processes"),
  Prevention = c("Pilot test", "Better design", "Frame maintenance",
                 "Pretesting", "Clear procedures")
)

problems %>%
  gt() %>%
  tab_header(
    title = "Survey Troubleshooting Guide",
    subtitle = "Common problems and solutions"
  )
```

---

# Slide 273: Publication Standards

```{r publication-standards, echo=TRUE}
# Publication standards checklist
check_publication_standards <- function() {
  
  cat("PUBLICATION STANDARDS CHECKLIST\n")
  cat("==============================\n\n")
  
  cat("TRANSPARENCY:\n")
  cat("â˜ Methodology clearly described\n")
  cat("â˜ Sample size and response rate reported\n")
  cat("â˜ Weights and variance estimation explained\n")
  cat("â˜ Limitations acknowledged\n\n")
  
  cat("PRECISION:\n")
  cat("â˜ Confidence intervals provided\n")
  cat("â˜ Coefficient of variation shown\n")
  cat("â˜ Sample sizes for subgroups\n")
  cat("â˜ Design effects where relevant\n\n")
  
  cat("ACCESSIBILITY:\n")
  cat("â˜ Plain language summary\n")
  cat("â˜ Visual aids included\n")
  cat("â˜ Technical appendix separate\n")
  cat("â˜ Data availability statement\n\n")
  
  cat("ETHICS:\n")
  cat("â˜ Confidentiality protected\n")
  cat("â˜ No disclosure risk\n")
  cat("â˜ Appropriate citations\n")
  cat("â˜ Funding acknowledged\n")
}

check_publication_standards()
```

---

# Slide 274: Version Control

```{r version-control, echo=FALSE}
version_practice <- tibble(
  File_Type = c("Questionnaire", "Data", "Scripts", "Reports", "Documentation"),
  Naming = c("quest_v1.2.docx", "data_20250321.dta", "analysis_v3.R",
             "report_draft2.pdf", "metadata_v1.xml"),
  Version_System = c("Track changes", "Date stamps", "Git", "Drafts folder", "XML versions"),
  Backup = c("OneDrive", "Server + cloud", "GitHub", "SharePoint", "Repository")
)

version_practice %>%
  gt() %>%
  tab_header(
    title = "Version Control Best Practices",
    subtitle = "Managing survey materials"
  )
```

---

# Slide 275: Final Exam Questions

```{r exam-questions, echo=TRUE}
# Sample exam questions
generate_exam_questions <- function() {
  
  cat("SAMPLE CERTIFICATION EXAM QUESTIONS\n")
  cat("==================================\n\n")
  
  cat("1. SAMPLING (25 points)\n")
  cat("Calculate the sample size needed for a proportion\n")
  cat("with 3% margin of error, 95% confidence, DEFF=2\n\n")
  
  cat("2. WEIGHTING (25 points)\n")
  cat("Describe the steps in creating calibrated weights\n")
  cat("for a stratified two-stage design\n\n")
  
  cat("3. VARIANCE (25 points)\n")
  cat("Compare Taylor linearization vs replication methods.\n")
  cat("When would you use each?\n\n")
  
  cat("4. PRACTICAL (25 points)\n")
  cat("Design a rapid phone survey for COVID impact.\n")
  cat("Include: frame, sample, questionnaire outline\n\n")
  
  cat("PASSING SCORE: 70%\n")
  cat("TIME LIMIT: 3 hours\n")
}

generate_exam_questions()
```

---

# Slide 276: Project Introduction

## Your Mission: Design the 2026 National Household Survey

**The Minister has approved your approach! Now design the actual survey.**

**Project Scenario:**
- Country: Republic of Zambezia (fictional SADC member)
- Population: 15 million
- Provinces: 8
- Districts: 72
- Objective: Measure poverty, employment, health access
- Budget: $2 million USD
- Timeline: 18 months

**Your Role:** Lead Survey Methodologist

**Deliverables:** Complete survey design with all technical specifications

---

# Slide 277: Project Structure

## Five Project Phases - 125 Slides

```{r project-structure, echo=FALSE}
phases <- tibble(
  Phase = c("I", "II", "III", "IV", "V"),
  Title = c("Planning & Design", "Sampling Strategy", "Data Collection", 
            "Processing & Analysis", "Quality & Reporting"),
  Slides = c("278-302", "303-327", "328-352", "353-377", "378-400"),
  Duration = c("25 slides", "25 slides", "25 slides", "25 slides", "23 slides"),
  Deliverable = c("Survey proposal", "Sample design", "Field plan", 
                  "Analysis plan", "Final report")
)

phases %>%
  gt() %>%
  tab_header(
    title = "Capstone Project Phases",
    subtitle = "Building a complete survey step-by-step"
  )
```

---

class: inverse, center, middle

# PHASE I: PLANNING & DESIGN
## Slides 278-302
### Setting the Foundation

---

# Slide 278: Step 1 - Stakeholder Analysis

## Who Needs What?

```{r stakeholder-analysis, echo=TRUE}
# Identify and analyze stakeholders
stakeholder_analysis <- function() {
  
  stakeholders <- data.frame(
    group = c("Ministry of Planning", "Ministry of Finance", "World Bank",
              "Civil Society", "Local Government", "Statistics Users"),
    interest = c("Poverty reduction", "Budget allocation", "SDG monitoring",
                 "Inequality", "Service delivery", "Research"),
    power = c("High", "High", "Medium", "Low", "Medium", "Low"),
    influence = c("High", "High", "Medium", "Low", "Medium", "Low"),
    data_needs = c("Poverty rates by district", "Economic indicators",
                   "International comparable", "Disaggregated data",
                   "Local area estimates", "Microdata access")
  )
  
  cat("STAKEHOLDER ANALYSIS COMPLETE\n")
  cat("Key finding: Must balance local needs with international standards\n")
  
  return(stakeholders)
}

stakeholders <- stakeholder_analysis()
```

**Task:** List your stakeholders and their requirements

---

# Slide 279: Step 2 - Define Objectives

## Clear, Measurable Goals

```{r objectives, echo=FALSE}
objectives <- tibble(
  Objective = c("Primary", "Secondary", "Secondary", "Tertiary"),
  Description = c("Measure national poverty rate", 
                  "Estimate unemployment by province",
                  "Assess health service access",
                  "Create baseline for SDGs"),
  Precision = c("Â±1% at national", "Â±3% at provincial", 
                "Â±5% at district", "Per SDG requirements"),
  Priority = c(1, 2, 2, 3)
)

objectives %>%
  gt() %>%
  tab_header(
    title = "Survey Objectives Hierarchy",
    subtitle = "What we must achieve"
  ) %>%
  data_color(
    columns = Priority,
    colors = scales::col_numeric(
      palette = c("#d4edda", "#fff3cd", "#ffcccc"),
      domain = c(1, 3)
    )
  )
```

**Your task:** Write SMART objectives for your survey

---

# Slide 280: Step 3 - Budget Breakdown

## Allocating $2 Million Wisely

```{r budget-allocation, echo=TRUE}
# Create detailed budget
allocate_budget <- function(total_budget = 2000000) {
  
  budget <- list(
    planning_design = total_budget * 0.10,  # 10%
    training = total_budget * 0.08,         # 8%
    data_collection = total_budget * 0.50,  # 50%
    processing = total_budget * 0.12,       # 12%
    analysis = total_budget * 0.10,         # 10%
    dissemination = total_budget * 0.05,    # 5%
    contingency = total_budget * 0.05       # 5%
  )
  
  # Field costs breakdown
  field_budget <- budget$data_collection
  field_details <- list(
    interviewer_payments = field_budget * 0.60,
    transport = field_budget * 0.20,
    materials = field_budget * 0.10,
    supervision = field_budget * 0.10
  )
  
  cat("BUDGET ALLOCATION:\n")
  cat("Total: $", format(total_budget, big.mark=","), "\n\n")
  
  for(item in names(budget)) {
    cat(sprintf("%-20s: $%9s (%.0f%%)\n", 
                item, format(budget[[item]], big.mark=","),
                budget[[item]]/total_budget*100))
  }
  
  return(budget)
}

project_budget <- allocate_budget()
```

---

# Slide 281: Step 4 - Timeline Development

## 18-Month Project Plan

```{r timeline, echo=FALSE}
timeline <- tibble(
  Phase = c("Planning", "Design", "Testing", "Training", "Field", 
            "Processing", "Analysis", "Reporting"),
  Start_Month = c(1, 2, 4, 5, 6, 8, 10, 12),
  End_Month = c(3, 5, 5, 6, 10, 12, 14, 18),
  Duration = End_Month - Start_Month + 1
)

timeline %>%
  ggplot(aes(xmin = Start_Month, xmax = End_Month, 
             y = fct_rev(Phase), fill = Phase)) +
  geom_rect(ymin = as.numeric(fct_rev(timeline$Phase)) - 0.4,
            ymax = as.numeric(fct_rev(timeline$Phase)) + 0.4) +
  scale_x_continuous(breaks = 1:18, labels = 1:18) +
  labs(title = "18-Month Survey Timeline",
       subtitle = "Gantt Chart with Overlapping Phases",
       x = "Month", y = "") +
  theme_minimal() +
  theme(legend.position = "none")
```

**Critical path:** Design â†’ Training â†’ Field â†’ Processing

---

# Slide 282: Step 5 - Legal Framework

## Establishing Authority

```{r legal-framework, echo=TRUE}
# Legal requirements checklist
establish_legal_framework <- function() {
  
  cat("LEGAL FRAMEWORK CHECKLIST\n")
  cat("========================\n\n")
  
  requirements <- c(
    "â˜‘ Statistics Act provides authority",
    "â˜‘ Cabinet approval obtained",
    "â˜ Gazette notice to be published",
    "â˜ Ethics committee approval pending",
    "â˜‘ Data protection compliance verified",
    "â˜ Confidentiality oaths for staff",
    "â˜ MOU with partner agencies",
    "â˜‘ Procurement procedures followed"
  )
  
  for(req in requirements) {
    cat(req, "\n")
  }
  
  cat("\nLegal basis: Statistics Act Section 12\n")
  cat("Mandatory participation: Yes\n")
  cat("Penalty for non-response: Warning only\n")
  cat("Data sharing restrictions: Statistical use only\n")
  
  return(TRUE)
}

legal_status <- establish_legal_framework()
```

---

# Slide 283: Step 6 - Quality Framework Design

## Building Quality from Start

```{r quality-framework, echo=FALSE}
quality_plan <- tibble(
  Dimension = c("Relevance", "Accuracy", "Timeliness", "Coherence", 
                "Accessibility", "Clarity"),
  Target = c("Meet all stakeholder needs", "CV < 5% national", 
             "Results in 6 months", "Align with Census 2022",
             "Public use file available", "Full documentation"),
  Measure = c("User satisfaction survey", "Calculate CVs", 
              "Track milestones", "Comparison analysis",
              "Download statistics", "User feedback"),
  Responsible = c("Management", "Methodology", "Operations", 
                  "Analysis", "Dissemination", "Documentation")
)

quality_plan %>%
  gt() %>%
  tab_header(
    title = "Quality Assurance Framework",
    subtitle = "Eurostat quality dimensions applied"
  )
```

---

# Slide 284: Step 7 - Risk Assessment

## What Could Go Wrong?

```{r risk-assessment, echo=TRUE}
# Comprehensive risk assessment
assess_project_risks <- function() {
  
  risks <- data.frame(
    risk = c("Low response rate", "Budget overrun", "Political interference",
             "Natural disaster", "Key staff turnover", "Technology failure"),
    probability = c(0.6, 0.4, 0.3, 0.1, 0.5, 0.3),
    impact = c(4, 3, 5, 5, 3, 4),
    risk_score = NA
  )
  
  risks$risk_score <- risks$probability * risks$impact
  
  # Mitigation strategies
  mitigation <- c(
    "Multiple contact attempts, incentives",
    "Contingency fund, phased implementation",
    "Clear legal framework, transparency",
    "Insurance, backup plans",
    "Knowledge management, succession planning",
    "Backup systems, paper forms ready"
  )
  
  risks$mitigation <- mitigation
  
  # Sort by risk score
  risks <- risks[order(risks$risk_score, decreasing = TRUE), ]
  
  cat("TOP 3 RISKS:\n")
  for(i in 1:3) {
    cat(i, ". ", risks$risk[i], " (Score: ", risks$risk_score[i], ")\n", sep="")
    cat("   Mitigation: ", risks$mitigation[i], "\n\n", sep="")
  }
  
  return(risks)
}

risk_register <- assess_project_risks()
```

---

# Slide 285: Step 8 - Team Structure

## Building Your Dream Team

```{r team-structure, echo=FALSE}
team <- tibble(
  Role = c("Project Director", "Sampling Expert", "Field Manager", 
           "Data Manager", "Analysis Lead", "Quality Officer"),
  Name = c("Harry", "Sarah", "John", "Maria", "David", "Grace"),
  FTE = c(1.0, 1.0, 1.0, 1.0, 0.8, 0.5),
  Experience = c("15 years", "12 years", "10 years", "8 years", "10 years", "7 years"),
  Key_Responsibility = c("Overall management", "Sample design", "Field operations",
                         "Data processing", "Statistical analysis", "Quality control")
) %>%
  mutate(
    Monthly_Cost = c(8000, 7000, 6000, 6000, 5000, 3000)
  )

team %>%
  gt() %>%
  tab_header(
    title = "Core Survey Team",
    subtitle = "5.3 FTE positions"
  ) %>%
  fmt_currency(columns = Monthly_Cost) %>%
  tab_footnote(
    footnote = "Plus 50 field interviewers and 10 supervisors",
    locations = cells_title()
  )
```

---

# Slide 286: Step 9 - Technology Stack Selection

## Choosing the Right Tools

```{r technology-selection, echo=TRUE}
# Select technology stack
select_technology <- function(budget_constraint = 50000) {
  
  cat("TECHNOLOGY STACK SELECTION\n")
  cat("=========================\n\n")
  
  # Evaluate options
  options <- data.frame(
    component = c("Data Collection", "Data Processing", "Analysis", "Dissemination"),
    selected = c("Survey Solutions", "R + PostgreSQL", "R + Stata", "R Shiny"),
    cost = c(0, 5000, 10000, 2000),
    alternative = c("ODK", "SPSS", "SAS", "Tableau"),
    reason = c("World Bank free", "Open source", "Team skills", "Interactive")
  )
  
  total_cost <- sum(options$cost)
  
  print(options)
  
  cat("\nTotal technology cost: $", total_cost, "\n")
  cat("Budget available: $", budget_constraint, "\n")
  cat("Remaining for hardware: $", budget_constraint - total_cost, "\n")
  
  # Hardware requirements
  cat("\nHardware needs:\n")
  cat("- 60 tablets @ $300 each = $18,000\n")
  cat("- 1 server @ $5,000\n")
  cat("- Network equipment @ $2,000\n")
  
  return(options)
}

tech_stack <- select_technology()
```

---

# Slide 287: Step 10 - Pilot Survey Planning

## Test Before You Invest

```{r pilot-planning, echo=FALSE}
pilot_plan <- tibble(
  Aspect = c("Sample size", "Locations", "Duration", "Focus", "Budget"),
  Main_Survey = c("10,000 HH", "All 8 provinces", "5 months", "Full scope", "$1M"),
  Pilot = c("200 HH", "2 provinces", "3 weeks", "Test instruments", "$30K"),
  Ratio = c("2%", "25%", "15%", "Core modules", "3%")
)

pilot_plan %>%
  gt() %>%
  tab_header(
    title = "Pilot Survey Specifications",
    subtitle = "Small scale test of all systems"
  ) %>%
  tab_style(
    style = cell_fill(color = "#e8f4f8"),
    locations = cells_body(columns = Pilot)
  )

cat("\nPilot objectives:\n")
cat("1. Test questionnaire flow and timing\n")
cat("2. Verify sampling procedures\n")
cat("3. Train core team\n")
cat("4. Test technology\n")
cat("5. Identify problems early\n")
```

---

# Slide 288: Step 11 - Questionnaire Structure

## Designing the Instrument

```{r questionnaire-structure, echo=TRUE}
# Design questionnaire structure
design_questionnaire <- function() {
  
  modules <- list(
    A = list(name = "Household Roster", questions = 15, time = 5),
    B = list(name = "Education", questions = 20, time = 7),
    C = list(name = "Health", questions = 25, time = 8),
    D = list(name = "Employment", questions = 30, time = 10),
    E = list(name = "Income", questions = 15, time = 8),
    F = list(name = "Expenditure", questions = 40, time = 12),
    G = list(name = "Housing", questions = 20, time = 5),
    H = list(name = "Assets", questions = 15, time = 3),
    I = list(name = "Shocks", questions = 10, time = 3)
  )
  
  total_questions <- sum(sapply(modules, function(x) x$questions))
  total_time <- sum(sapply(modules, function(x) x$time))
  
  cat("QUESTIONNAIRE DESIGN\n")
  cat("===================\n\n")
  
  for(mod in names(modules)) {
    cat(sprintf("Module %s: %-15s (%d questions, %d min)\n",
                mod, modules[[mod]]$name, 
                modules[[mod]]$questions, modules[[mod]]$time))
  }
  
  cat("\nTotal questions:", total_questions, "\n")
  cat("Total time:", total_time, "minutes\n")
  cat("\nMatrix sampling: Modules F-I rotating (25% each)\n")
  
  return(modules)
}

questionnaire <- design_questionnaire()
```

---

# Slide 289: Step 12 - Translation Planning

## Multi-Language Strategy

```{r translation-plan, echo=FALSE}
languages <- tibble(
  Language = c("English", "Bemba", "Nyanja", "Tonga", "Lozi"),
  Speakers_Pct = c(100, 35, 20, 15, 10),
  Regions = c("All", "Northern", "Eastern", "Southern", "Western"),
  Translation = c("Original", "Required", "Required", "Required", "Required"),
  Cost = c(0, 5000, 5000, 5000, 5000)
)

languages %>%
  ggplot(aes(x = reorder(Language, -Speakers_Pct), y = Speakers_Pct)) +
  geom_col(fill = sadc_colors[2]) +
  geom_text(aes(label = paste0(Speakers_Pct, "%")), vjust = -0.5) +
  labs(title = "Language Coverage Strategy",
       subtitle = "Ensuring no one is left behind",
       x = "Language", y = "Population Coverage (%)") +
  theme_minimal()

cat("Translation process:\n")
cat("1. Forward translation by two independent translators\n")
cat("2. Reconciliation meeting\n")
cat("3. Back translation\n")
cat("4. Expert review\n")
cat("5. Cognitive testing in each language\n")
cat("6. Final harmonization\n")
```

---

# Slide 290: Step 13 - Training Program Design

## Building Capacity

```{r training-design, echo=TRUE}
# Design comprehensive training program
design_training_program <- function() {
  
  training_components <- list(
    supervisors = list(
      duration = 5,
      participants = 10,
      topics = c("Management", "Quality control", "Problem solving")
    ),
    interviewers = list(
      duration = 10,
      participants = 50,
      topics = c("Interview skills", "Questionnaire", "Technology", "Ethics")
    ),
    data_team = list(
      duration = 3,
      participants = 5,
      topics = c("Data processing", "Quality checks", "Documentation")
    )
  )
  
  # Training schedule
  cat("TRAINING PROGRAM DESIGN\n")
  cat("======================\n\n")
  
  total_days <- 0
  total_cost <- 0
  
  for(group in names(training_components)) {
    comp <- training_components[[group]]
    cost <- comp$duration * comp$participants * 50  # $50 per person per day
    
    cat(toupper(group), ":\n")
    cat("  Duration:", comp$duration, "days\n")
    cat("  Participants:", comp$participants, "\n")
    cat("  Cost: $", cost, "\n\n")
    
    total_days <- total_days + comp$duration
    total_cost <- total_cost + cost
  }
  
  cat("Total training cost: $", total_cost, "\n")
  
  return(training_components)
}

training <- design_training_program()
```

---

# Slide 291: Step 14 - Quality Control System

## Multi-Layer Quality Assurance

```{r quality-control-system, echo=FALSE}
qc_layers <- tibble(
  Level = c("Field", "Supervisor", "Central", "Statistical"),
  Check_Type = c("Real-time validation", "Spot checks", "Batch processing", "Analysis"),
  Frequency = c("Every interview", "10% of interviews", "Daily", "Weekly"),
  Method = c("CAPI rules", "Re-interview", "Consistency checks", "Statistical tests"),
  Action = c("Immediate correction", "Feedback to interviewer", "Flag for review", "Investigation")
)

qc_layers %>%
  gt() %>%
  tab_header(
    title = "Four-Layer Quality Control System",
    subtitle = "Catching errors at every stage"
  ) %>%
  tab_style(
    style = cell_fill(color = "#e8f4f8"),
    locations = cells_body(rows = Level == "Statistical")
  )
```

---

# Slide 292: Step 15 - Documentation Planning

## Creating Institutional Memory

```{r documentation-planning, echo=TRUE}
# Plan comprehensive documentation
plan_documentation <- function() {
  
  documents <- data.frame(
    document = c("Survey Protocol", "Sampling Manual", "Field Guide", 
                 "Data Processing Guide", "Analysis Plan", "Quality Report",
                 "User Manual", "Technical Report"),
    when = c("Before field", "Before field", "Before training", 
             "During field", "Before analysis", "After field",
             "With data release", "Final"),
    pages = c(50, 30, 40, 25, 35, 20, 60, 100),
    responsible = c("Director", "Sampling team", "Field manager", 
                    "Data manager", "Analysis team", "Quality officer",
                    "Documentation team", "All"),
    stringsAsFactors = FALSE
  )
  
  cat("DOCUMENTATION PLAN\n")
  cat("==================\n\n")
  
  print(documents)
  
  cat("\nTotal pages:", sum(documents$pages), "\n")
  cat("\nVersion control: Git repository\n")
  cat("Format: Markdown â†’ PDF/HTML\n")
  cat("Review process: Two-stage approval\n")
  
  return(documents)
}

documentation <- plan_documentation()
```

---

class: inverse, center, middle

# PHASE II: SAMPLING STRATEGY
## Slides 303-327
### The Technical Heart

---

# Slide 293: Step 16 - Frame Assessment

## Understanding Your Universe

```{r frame-assessment, echo=TRUE}
# Assess sampling frame quality
assess_sampling_frame <- function() {
  
  cat("SAMPLING FRAME ASSESSMENT\n")
  cat("========================\n\n")
  
  # Frame sources
  frames <- data.frame(
    source = c("2022 Census", "Electoral Roll", "Utility Records", "Tax Register"),
    coverage = c(0.95, 0.78, 0.65, 0.42),
    currency = c(3, 1, 0, 0),  # Years old
    quality = c("Good", "Fair", "Fair", "Poor"),
    use = c("Primary", "Validation", "Supplement", "Not used")
  )
  
  print(frames)
  
  cat("\nFrame decision: Use 2022 Census as primary frame\n")
  cat("Coverage rate: 95%\n")
  cat("Missing: Informal settlements, new developments\n")
  cat("Solution: Area-based supplementation\n")
  
  # Calculate frame statistics
  total_units <- 3000000  # households
  covered <- total_units * 0.95
  
  cat("\nFrame statistics:\n")
  cat("Total households (estimated):", format(total_units, big.mark=","), "\n")
  cat("In frame:", format(covered, big.mark=","), "\n")
  cat("Missing:", format(total_units - covered, big.mark=","), "\n")
  
  return(frames)
}

frame <- assess_sampling_frame()
```

---

# Slide 294: Step 17 - Sample Size Calculation

## How Many Do We Need?

```{r sample-size-calc, echo=TRUE}
# Calculate required sample size
calculate_sample_size <- function() {
  
  cat("SAMPLE SIZE CALCULATION\n")
  cat("======================\n\n")
  
  # Parameters
  p <- 0.35          # Expected poverty rate
  e <- 0.01          # 1% margin of error
  conf <- 0.95       # 95% confidence
  z <- 1.96
  deff <- 2.5        # Design effect
  provinces <- 8
  
  # National level
  n_srs <- (z^2 * p * (1-p)) / e^2
  n_complex <- n_srs * deff
  
  cat("National level:\n")
  cat("  SRS sample:", round(n_srs), "\n")
  cat("  With DEFF:", round(n_complex), "\n\n")
  
  # Provincial level (3% margin)
  e_prov <- 0.03
  n_prov <- (z^2 * p * (1-p)) / e_prov^2 * deff
  n_total_prov <- n_prov * provinces
  
  cat("Provincial level:\n")
  cat("  Per province:", round(n_prov), "\n")
  cat("  Total:", round(n_total_prov), "\n\n")
  
  # Final decision
  n_final <- max(n_complex, n_total_prov)
  cat("FINAL SAMPLE SIZE:", round(n_final), "households\n")
  
  # Add reserve
  reserve <- n_final * 0.10
  cat("Plus 10% reserve:", round(reserve), "\n")
  cat("TOTAL TO SELECT:", round(n_final + reserve), "\n")
  
  return(n_final)
}

sample_size <- calculate_sample_size()
```

---

# Slide 295: Step 18 - Stratification Design

## Dividing the Universe

```{r stratification, echo=FALSE}
strata <- expand.grid(
  Province = paste("P", 1:8, sep=""),
  Urban_Rural = c("Urban", "Rural")
) %>%
  mutate(
    Stratum_ID = paste(Province, substr(Urban_Rural, 1, 1), sep="_"),
    Population = c(500000, 300000, 400000, 600000, 350000, 450000, 
                  250000, 550000, 200000, 800000, 150000, 650000,
                  180000, 720000, 220000, 480000),
    Sample_Proportional = round(Population / sum(Population) * 10000),
    Sample_Equal = 625,
    Sample_Optimal = c(650, 400, 550, 750, 500, 600, 350, 700,
                       300, 900, 250, 800, 280, 820, 320, 630)
  )

strata %>%
  head(8) %>%
  gt() %>%
  tab_header(
    title = "Stratification Scheme",
    subtitle = "16 strata (8 provinces Ã— 2 urban/rural)"
  )

cat("\nAllocation comparison:\n")
cat("Proportional: Maintains representativeness\n")
cat("Equal: Good for provincial estimates\n")
cat("Optimal: Compromise approach (selected)\n")
```

---

# Slide 296: Step 19 - PSU Selection

## First Stage Sampling

```{r psu-selection, echo=TRUE}
# Select Primary Sampling Units
select_psus <- function(frame, n_psu = 500) {
  
  cat("PRIMARY SAMPLING UNIT SELECTION\n")
  cat("===============================\n\n")
  
  # PSU characteristics
  cat("Total EAs in frame: 15,000\n")
  cat("Target PSUs: ", n_psu, "\n")
  cat("Method: PPS (Probability Proportional to Size)\n")
  cat("Size measure: Number of households\n\n")
  
  # Simulate selection
  set.seed(2025)
  
  # By stratum
  strata_psu <- data.frame(
    stratum = paste0("S", 1:16),
    n_psu = c(32, 20, 28, 38, 25, 30, 18, 35,
              15, 45, 13, 40, 14, 41, 16, 32),
    selection_interval = round(15000/16/n_psu * 
                               c(32, 20, 28, 38, 25, 30, 18, 35,
                                 15, 45, 13, 40, 14, 41, 16, 32))
  )
  
  cat("PSU allocation by stratum:\n")
  print(head(strata_psu, 6))
  
  cat("\nSystematic PPS procedure:\n")
  cat("1. Sort EAs by geography within stratum\n")
  cat("2. Calculate cumulative size\n")
  cat("3. Generate random start\n")
  cat("4. Select at intervals\n")
  
  return(strata_psu)
}

psu_allocation <- select_psus()
```

---

# Slide 297: Step 20 - Second Stage Selection

## Selecting Households

```{r second-stage, echo=FALSE}
second_stage <- tibble(
  PSU_Type = c("Urban high density", "Urban low density", 
               "Rural clustered", "Rural dispersed"),
  Avg_HH_per_EA = c(150, 80, 60, 40),
  Sample_per_PSU = c(20, 20, 20, 15),
  Sampling_Rate = c(0.133, 0.250, 0.333, 0.375),
  Method = c("Systematic", "Systematic", "Systematic", "Simple random")
) %>%
  mutate(
    Skip_Interval = round(1/Sampling_Rate)
  )

second_stage %>%
  gt() %>%
  tab_header(
    title = "Second Stage Sampling Strategy",
    subtitle = "Household selection within PSUs"
  ) %>%
  fmt_percent(columns = Sampling_Rate)

cat("\nOperational procedure:\n")
cat("1. List all households in selected PSU\n")
cat("2. Apply systematic selection\n")
cat("3. Random start between 1 and k\n")
cat("4. Select every kth household\n")
```

---

# Slide 298: Step 21 - Sample Allocation

## Final Distribution

```{r sample-allocation, echo=TRUE}
# Final sample allocation
allocate_final_sample <- function() {
  
  allocation <- data.frame(
    Province = paste("Province", 1:8),
    Urban_PSU = c(32, 28, 25, 18, 30, 15, 14, 16),
    Rural_PSU = c(20, 38, 30, 35, 45, 40, 41, 32),
    Urban_HH = c(640, 560, 500, 360, 600, 300, 280, 320),
    Rural_HH = c(400, 760, 600, 700, 900, 800, 820, 640),
    Total_HH = c(1040, 1320, 1100, 1060, 1500, 1100, 1100, 960)
  )
  
  allocation$Percent <- round(allocation$Total_HH / sum(allocation$Total_HH) * 100, 1)
  
  cat("FINAL SAMPLE ALLOCATION\n")
  cat("======================\n\n")
  
  print(allocation)
  
  cat("\nSummary:\n")
  cat("Total PSUs:", sum(allocation$Urban_PSU + allocation$Rural_PSU), "\n")
  cat("Total Households:", sum(allocation$Total_HH), "\n")
  cat("Average per PSU:", round(mean(allocation$Total_HH/
                                     (allocation$Urban_PSU + allocation$Rural_PSU))), "\n")
  
  return(allocation)
}

final_allocation <- allocate_final_sample()
```

---

# Slide 299: Step 22 - Weight Calculation Plan

## From Sample to Population

```{r weight-plan, echo=FALSE}
weight_components <- tibble(
  Stage = c("Base weight", "PSU adjustment", "HH adjustment", 
            "Non-response", "Calibration", "Trimming"),
  Formula = c("1/(Ï€â‚ Ã— Ï€â‚‚)", "N_psu/n_psu", "N_hh|psu/n_hh|psu",
              "1/RR", "Î£pop/Î£weighted", "Bounded"),
  When = c("Design", "Design", "Design", "After field", 
           "Post-processing", "Final"),
  Impact = c("Base", "Ã—1.0", "Ã—1.0", "Ã—1.25", "Ã—0.95", "Stabilize")
)

weight_components %>%
  gt() %>%
  tab_header(
    title = "Weight Calculation Plan",
    subtitle = "Six-stage weight construction"
  )
```

---

# Slide 300: Step 23 - Replacement Strategy

## When Things Go Wrong

```{r replacement-strategy, echo=TRUE}
# Define replacement protocol
define_replacement_protocol <- function() {
  
  cat("REPLACEMENT PROTOCOL\n")
  cat("===================\n\n")
  
  cat("PSU LEVEL REPLACEMENT:\n")
  cat("Trigger: Entire PSU inaccessible\n")
  cat("Action: Use pre-selected replacement PSU\n")
  cat("Documentation: Full justification required\n\n")
  
  cat("HOUSEHOLD LEVEL:\n")
  
  replacement_rules <- data.frame(
    Situation = c("Vacant", "Refused", "Not found", "Away long-term"),
    Attempts = c(1, 4, 3, 2),
    Replace = c("No", "No", "Yes", "Yes"),
    Weight_Adjust = c("Yes", "Yes", "No", "No")
  )
  
  print(replacement_rules)
  
  cat("\nReplacement procedure:\n")
  cat("1. Use next household on list\n")
  cat("2. Same characteristics if possible\n")
  cat("3. Document all replacements\n")
  cat("4. Maximum 10% replacement rate\n")
  
  return(replacement_rules)
}

replacement <- define_replacement_protocol()
```

---

# Slide 301: Step 24 - Variance Estimation Plan

## Measuring Our Precision

```{r variance-plan, echo=FALSE}
variance_plan <- tibble(
  Method = c("Taylor linearization", "Jackknife", "Bootstrap", "BRR"),
  Use_Case = c("Main estimates", "Quantiles", "Complex statistics", "If needed"),
  Software = c("survey package", "survey package", "Custom code", "survey package"),
  Computation = c("Fast", "Moderate", "Intensive", "Moderate")
)

variance_plan %>%
  gt() %>%
  tab_header(
    title = "Variance Estimation Strategy",
    subtitle = "Methods for different statistics"
  )

cat("\nKey design variables to preserve:\n")
cat("â€¢ Stratum identifier\n")
cat("â€¢ PSU identifier\n")
cat("â€¢ Base weights\n")
cat("â€¢ Final weights\n")
cat("â€¢ Finite population corrections\n")
```

---

# Slide 302: Phase I Complete - Design Review

## Checkpoint: Ready for Implementation?

```{r phase1-review, echo=TRUE}
# Phase I completion checklist
phase1_review <- function() {
  
  cat("PHASE I COMPLETION REVIEW\n")
  cat("========================\n\n")
  
  checklist <- c(
    "âœ“ Objectives clearly defined",
    "âœ“ Budget allocated ($2M)",
    "âœ“ Timeline established (18 months)",
    "âœ“ Team assembled",
    "âœ“ Legal framework in place",
    "âœ“ Quality framework designed",
    "âœ“ Risks assessed and mitigated",
    "âœ“ Technology selected",
    "âœ“ Pilot planned",
    "âœ“ Questionnaire structured",
    "âœ“ Training program designed",
    "âœ“ Documentation planned"
  )
  
  for(item in checklist) {
    cat(item, "\n")
  }
  
  cat("\nDECISION POINT:\n")
  cat("Proceed to Phase II? YES\n")
  cat("Budget committed: $200,000 (10%)\n")
  cat("Next milestone: Pilot survey in 2 months\n")
  
  return(TRUE)
}

phase1_complete <- phase1_review()
```

---

class: inverse, center, middle

# PHASE III: DATA COLLECTION
## Slides 328-352
### Making It Happen

---

# Slide 328: Step 25 - Field Organization Structure

## Building the Field Army

```{r field-organization, echo=FALSE}
field_structure <- tibble(
  Level = c("National", "Regional", "District", "Team", "Individual"),
  Role = c("Field Director", "Regional Coordinator", "District Supervisor",
           "Team Leader", "Interviewer"),
  Number = c(1, 4, 16, 50, 200),
  Span = c("4 regions", "4 districts", "3-4 teams", "4 interviewers", "20 HH/week"),
  Training_Days = c(10, 7, 5, 5, 10)
)

field_structure %>%
  gt() %>%
  tab_header(
    title = "Field Organization Hierarchy",
    subtitle = "271 field staff total"
  )
```

---

# Slide 329: Step 26 - Field Materials Preparation

## Everything They Need

```{r field-materials2, echo=TRUE}
# Prepare field materials checklist
prepare_field_materials <- function() {
  
  cat("FIELD MATERIALS PREPARATION\n")
  cat("==========================\n\n")
  
  materials <- list(
    documents = c(
      "Letter of introduction",
      "ID cards",
      "Survey authorization",
      "Questionnaires (backup)",
      "Household listing forms",
      "Contact sheets"
    ),
    equipment = c(
      "Tablets (60 + 10 spare)",
      "Power banks",
      "GPS units",
      "Measuring tape",
      "Calculators",
      "Bags"
    ),
    supplies = c(
      "Pens (500)",
      "Notebooks (100)",
      "Folders (200)",
      "Clipboards (60)",
      "First aid kits (20)"
    )
  )
  
  total_items <- sum(lengths(materials))
  
  cat("Total unique items:", total_items, "\n\n")
  
  cat("BUDGET REQUIRED:\n")
  cat("Documents: $5,000\n")
  cat("Equipment: $25,000\n")
  cat("Supplies: $3,000\n")
  cat("TOTAL: $33,000\n")
  
  return(materials)
}

materials <- prepare_field_materials()
```

---

# Slide 330: Step 27 - CAPI Programming

## Digital Questionnaire Development

```{r capi-programming, echo=FALSE}
capi_timeline <- tibble(
  Week = 1:8,
  Task = c("Requirements gathering", "Initial programming", "Logic implementation",
           "Validation rules", "Testing", "Pilot adjustments", 
           "Final testing", "Deployment"),
  Status = c("Complete", "Complete", "Complete", "In progress", 
             "Pending", "Pending", "Pending", "Pending"),
  Deliverable = c("Specifications", "Basic form", "Skip patterns work",
                  "Quality checks active", "Bug list", "Version 2.0",
                  "Sign-off", "Live system")
)

capi_timeline %>%
  gt() %>%
  tab_header(
    title = "CAPI Development Timeline",
    subtitle = "8-week programming schedule"
  ) %>%
  data_color(
    columns = Status,
    colors = scales::col_factor(
      palette = c("Complete" = "#d4edda", "In progress" = "#fff3cd", "Pending" = "#e8f4f8"),
      domain = c("Complete", "In progress", "Pending")
    )
  )
```

---

# Slide 331: Step 28 - Training Execution

## Building Competence

```{r training-execution, echo=TRUE}
# Execute training program
execute_training <- function() {
  
  cat("TRAINING EXECUTION PLAN\n")
  cat("======================\n\n")
  
  # Week 1: Supervisors
  cat("WEEK 1 - SUPERVISORS (10 participants)\n")
  cat("Day 1: Survey overview, objectives\n")
  cat("Day 2: Sampling, household selection\n")
  cat("Day 3: Team management, problem solving\n")
  cat("Day 4: Quality control, monitoring\n")
  cat("Day 5: Assessment and certification\n\n")
  
  # Week 2-3: Interviewers
  cat("WEEK 2-3 - INTERVIEWERS (50 per batch Ã— 4 batches)\n")
  cat("Day 1-2: Introduction, ethics, protocols\n")
  cat("Day 3-4: Questionnaire training\n")
  cat("Day 5-6: CAPI training\n")
  cat("Day 7-8: Field practice\n")
  cat("Day 9: Assessment\n")
  cat("Day 10: Certification and deployment\n\n")
  
  # Success metrics
  cat("SUCCESS METRICS:\n")
  cat("â€¢ Pass rate: >90%\n")
  cat("â€¢ Practical test: >80% score\n")
  cat("â€¢ Dropout rate: <5%\n")
  
  return(TRUE)
}

training_executed <- execute_training()
```

---

# Slide 332: Step 29 - Field Launch

## Day 1 in the Field

```{r field-launch, echo=FALSE}
launch_checklist <- tibble(
  Time = c("06:00", "07:00", "08:00", "09:00-12:00", "12:00-13:00",
           "13:00-16:00", "16:00", "17:00", "18:00"),
  Activity = c("Team assembly", "Briefing", "Depart to field", "First interviews",
               "Lunch break", "Continue interviews", "Return to base",
               "Debrief", "Data submission"),
  Responsible = c("Supervisors", "Field Director", "Team Leaders", "Interviewers",
                  "All", "Interviewers", "Team Leaders", "Supervisors", "Data team"),
  CheckPoint = c("Attendance", "Understanding", "Transport OK", "Quality check",
                 "-", "Progress check", "All safe", "Issues log", "100% sync")
)

launch_checklist %>%
  gt() %>%
  tab_header(
    title = "Field Launch Day Schedule",
    subtitle = "Hour-by-hour coordination"
  )
```

---

# Slide 333: Step 30 - Daily Monitoring

## Keeping Track of Progress

```{r daily-monitoring, echo=TRUE}
# Daily field monitoring dashboard
daily_monitoring <- function(day = 15) {
  
  cat("DAILY FIELD REPORT - DAY", day, "\n")
  cat("==============================\n\n")
  
  # Simulate daily statistics
  set.seed(day + 2025)
  
  stats <- list(
    interviews_planned = 200,
    interviews_completed = 175,
    response_rate = 0.78,
    avg_duration = 52,
    data_synced = 0.95,
    issues_reported = 3
  )
  
  cat("TARGET vs ACTUAL:\n")
  cat("Planned:", stats$interviews_planned, "\n")
  cat("Completed:", stats$interviews_completed, 
      sprintf("(%.0f%%)", stats$interviews_completed/stats$interviews_planned*100), "\n\n")
  
  cat("KEY INDICATORS:\n")
  cat("Response rate:", sprintf("%.1f%%", stats$response_rate * 100), "\n")
  cat("Avg duration:", stats$avg_duration, "minutes\n")
  cat("Data synced:", sprintf("%.0f%%", stats$data_synced * 100), "\n")
  cat("Issues:", stats$issues_reported, "\n\n")
  
  # Cumulative progress
  total_target <- 10000
  total_complete <- day * 175
  
  cat("CUMULATIVE PROGRESS:\n")
  cat("Total completed:", total_complete, "/", total_target,
      sprintf("(%.1f%%)", total_complete/total_target*100), "\n")
  
  return(stats)
}

day15_stats <- daily_monitoring(15)
```

---

# Slide 334: Step 31 - Quality Control Implementation

## Real-Time Quality Assurance

```{r quality-implementation, echo=FALSE}
quality_results <- tibble(
  Week = 1:4,
  Interviews = c(1250, 1300, 1275, 1350),
  Spot_Checks = c(125, 130, 128, 135),
  Errors_Found = c(23, 18, 12, 8),
  Error_Rate = Errors_Found / Spot_Checks * 100,
  Action = c("Retraining conducted", "Targeted coaching", 
             "Monitoring continues", "System working")
)

quality_results %>%
  ggplot(aes(x = Week, y = Error_Rate)) +
  geom_line(size = 2, color = sadc_colors[2]) +
  geom_point(size = 4, color = sadc_colors[2]) +
  geom_hline(yintercept = 5, linetype = "dashed", color = "red") +
  labs(title = "Quality Improvement Over Time",
       subtitle = "Error rate declining with intervention",
       y = "Error Rate (%)", x = "Week") +
  theme_minimal()
```

---

# Slide 335: Step 32 - Problem Resolution

## Handling Field Challenges

```{r problem-resolution, echo=TRUE}
# Problem tracking and resolution
resolve_field_problems <- function() {
  
  cat("FIELD PROBLEM LOG - WEEK 3\n")
  cat("=========================\n\n")
  
  problems <- data.frame(
    Date = c("Mon", "Mon", "Tue", "Wed", "Thu"),
    Problem = c("Road washed out", "Translator needed", "Tablet malfunction",
                "Hostile community", "Team member sick"),
    Resolution = c("Alternative route found", "Local teacher recruited",
                   "Spare tablet deployed", "Elder engagement successful",
                   "Replacement from float team"),
    Time_Lost = c(3, 2, 1, 4, 0),
    Status = c("Resolved", "Resolved", "Resolved", "Resolved", "Resolved")
  )
  
  print(problems)
  
  cat("\nSummary:\n")
  cat("Total problems:", nrow(problems), "\n")
  cat("All resolved:", all(problems$Status == "Resolved"), "\n")
  cat("Total time lost:", sum(problems$Time_Lost), "hours\n")
  cat("Impact on schedule: Minimal\n")
  
  return(problems)
}

week3_problems <- resolve_field_problems()
```

---

class: inverse, center, middle

# PHASE IV: PROCESSING & ANALYSIS
## Slides 353-377
### From Data to Insights

---

# Slide 353: Step 33 - Data Processing Setup

## Building the Pipeline

```{r processing-setup, echo=FALSE}
pipeline <- tibble(
  Stage = c("Reception", "Validation", "Editing", "Coding", 
            "Imputation", "Weighting", "Analysis", "Output"),
  Tool = c("Server", "R scripts", "R + rules", "Manual + auto",
           "R mice", "R survey", "R + Stata", "R Markdown"),
  Frequency = c("Real-time", "Daily", "Daily", "Weekly",
                "Once", "Once", "As needed", "Monthly"),
  Staff = c("IT", "Data team", "Data team", "Coders",
            "Statistician", "Methodologist", "Analysts", "All")
)

pipeline %>%
  gt() %>%
  tab_header(
    title = "Data Processing Pipeline",
    subtitle = "From field to analysis-ready"
  )
```

---

# Slide 354: Step 34 - Data Validation

## Checking Everything

```{r data-validation, echo=TRUE}
# Implement validation checks
validate_survey_data <- function(data) {
  
  cat("DATA VALIDATION REPORT\n")
  cat("=====================\n\n")
  
  # Run validation checks
  checks <- list(
    completeness = sum(complete.cases(data)) / nrow(data),
    duplicates = sum(duplicated(data$household_id)),
    range_age = all(data$age >= 0 & data$age <= 120, na.rm = TRUE),
    range_income = all(data$income >= 0, na.rm = TRUE),
    consistency_age_education = all(data$age >= data$education_years + 5, na.rm = TRUE)
  )
  
  cat("VALIDATION RESULTS:\n")
  cat(sprintf("Completeness: %.1f%%\n", checks$completeness * 100))
  cat(sprintf("Duplicates: %d\n", checks$duplicates))
  cat(sprintf("Age range valid: %s\n", checks$range_age))
  cat(sprintf("Income range valid: %s\n", checks$range_income))
  cat(sprintf("Age-education consistent: %s\n", checks$consistency_age_education))
  
  # Flag issues
  if(checks$completeness < 0.95) cat("\nâš ï¸ High missing data rate\n")
  if(checks$duplicates > 0) cat("\nâš ï¸ Duplicates found - investigate\n")
  
  return(checks)
}

# Simulate validation
test_data <- data.frame(
  household_id = 1:1000,
  age = sample(0:80, 1000, replace = TRUE),
  education_years = sample(0:20, 1000, replace = TRUE),
  income = abs(rnorm(1000, 50000, 30000))
)

validation <- validate_survey_data(test_data)
```

---

# Slide 355: Step 35 - Missing Data Treatment

## Imputation Strategy

```{r imputation-strategy, echo=FALSE}
missing_pattern <- tibble(
  Variable = c("Age", "Education", "Income", "Employment", "Health status"),
  Missing_Pct = c(0.5, 2.1, 8.3, 3.2, 5.6),
  Pattern = c("MCAR", "MAR", "MNAR", "MAR", "MAR"),
  Method = c("None needed", "Hot deck", "Multiple imputation", 
             "Logistic regression", "Multiple imputation"),
  Software = c("-", "R", "mice", "mice", "mice")
)

missing_pattern %>%
  gt() %>%
  tab_header(
    title = "Missing Data Treatment Plan",
    subtitle = "Variable-specific approach"
  ) %>%
  data_color(
    columns = Missing_Pct,
    colors = scales::col_numeric(
      palette = c("#d4edda", "#fff3cd", "#ffcccc"),
      domain = c(0, 10)
    )
  )
```

---

# Slide 356: Step 36 - Weight Calculation

## From Sample to Population

```{r weight-calculation, echo=TRUE}
# Calculate survey weights
calculate_survey_weights <- function(sample_data) {
  
  cat("WEIGHT CALCULATION PROCESS\n")
  cat("=========================\n\n")
  
  # Step 1: Base weights
  sample_data$base_weight <- 1 / (sample_data$psu_prob * sample_data$hh_prob)
  
  cat("Step 1 - Base weights:\n")
  cat("  Range:", range(sample_data$base_weight), "\n")
  cat("  Mean:", mean(sample_data$base_weight), "\n\n")
  
  # Step 2: Non-response adjustment
  response_rate <- 0.78
  sample_data$nr_weight <- sample_data$base_weight / response_rate
  
  cat("Step 2 - Non-response adjustment:\n")
  cat("  Response rate:", response_rate, "\n")
  cat("  Adjusted mean:", mean(sample_data$nr_weight), "\n\n")
  
  # Step 3: Calibration (simplified)
  population_total <- 15000000
  current_total <- sum(sample_data$nr_weight)
  calibration_factor <- population_total / current_total
  
  sample_data$final_weight <- sample_data$nr_weight * calibration_factor
  
  cat("Step 3 - Calibration:\n")
  cat("  Population total:", format(population_total, big.mark=","), "\n")
  cat("  Calibration factor:", round(calibration_factor, 4), "\n\n")
  
  cat("FINAL WEIGHTS:\n")
  cat("  Range:", range(sample_data$final_weight), "\n")
  cat("  CV:", round(sd(sample_data$final_weight)/mean(sample_data$final_weight), 3), "\n")
  cat("  Sum:", format(sum(sample_data$final_weight), big.mark=","), "\n")
  
  return(sample_data)
}

# Example with simulated data
sim_data <- data.frame(
  psu_prob = runif(100, 0.01, 0.05),
  hh_prob = runif(100, 0.05, 0.20)
)

weighted_data <- calculate_survey_weights(sim_data)
```

---

# Slide 357: Step 37 - Creating Analysis Datasets

## Ready for Researchers

```{r analysis-datasets, echo=FALSE}
datasets <- tibble(
  Dataset = c("Master file", "Person level", "Household level", 
              "Public use file", "Restricted file"),
  Records = c("50,000", "180,000", "10,000", "10,000", "10,000"),
  Variables = c(450, 250, 350, 200, 450),
  Size_MB = c(250, 200, 80, 40, 250),
  Access = c("Internal only", "Internal only", "Internal only", 
             "Public", "Approved researchers")
)

datasets %>%
  gt() %>%
  tab_header(
    title = "Analysis Dataset Specifications",
    subtitle = "Different files for different users"
  ) %>%
  tab_style(
    style = cell_fill(color = "#d4edda"),
    locations = cells_body(
      columns = Access,
      rows = Access == "Public"
    )
  )
```

---

# Slide 358: Step 38 - Key Indicator Calculation

## The Main Results

```{r key-indicators, echo=TRUE}
# Calculate key survey indicators
calculate_key_indicators <- function(weighted_data) {
  
  cat("KEY SURVEY INDICATORS\n")
  cat("====================\n\n")
  
  # Simulate calculations
  indicators <- list(
    poverty_rate = 0.342,
    poverty_se = 0.008,
    unemployment = 0.156,
    unemployment_se = 0.012,
    health_access = 0.673,
    health_se = 0.015
  )
  
  cat("NATIONAL ESTIMATES:\n\n")
  
  cat(sprintf("Poverty Rate: %.1f%% (SE: %.1f%%)\n", 
              indicators$poverty_rate * 100,
              indicators$poverty_se * 100))
  
  cat(sprintf("Unemployment: %.1f%% (SE: %.1f%%)\n",
              indicators$unemployment * 100,
              indicators$unemployment_se * 100))
  
  cat(sprintf("Health Access: %.1f%% (SE: %.1f%%)\n",
              indicators$health_access * 100,
              indicators$health_se * 100))
  
  cat("\nPRECISION ACHIEVED:\n")
  cat("All CVs < 5% âœ“\n")
  cat("Provincial CVs < 10% âœ“\n")
  
  return(indicators)
}

key_indicators <- calculate_key_indicators(weighted_data)
```

---

class: inverse, center, middle

# PHASE V: QUALITY & REPORTING
## Slides 378-400
### Delivering Excellence

---

# Slide 378: Step 39 - Quality Assessment

## How Good Is Our Data?

```{r quality-assessment, echo=FALSE}
quality_metrics <- tibble(
  Dimension = c("Coverage", "Sampling", "Nonresponse", "Measurement", "Processing"),
  Target = c(">95%", "DEFF<3", "RR>75%", "Item NR<5%", "Edit<5%"),
  Achieved = c("94.5%", "2.48", "78.2%", "3.8%", "4.2%"),
  Status = c("âš ï¸", "âœ“", "âœ“", "âœ“", "âœ“"),
  Impact = c("Minor", "None", "None", "None", "None")
)

quality_metrics %>%
  gt() %>%
  tab_header(
    title = "Final Quality Assessment",
    subtitle = "Meeting international standards"
  ) %>%
  tab_style(
    style = cell_fill(color = "#d4edda"),
    locations = cells_body(
      columns = Status,
      rows = Status == "âœ“"
    )
  )
```

---

# Slide 379: Step 40 - Report Writing

## Telling the Story

```{r report-writing, echo=TRUE}
# Structure main survey report
write_survey_report <- function() {
  
  cat("MAIN SURVEY REPORT OUTLINE\n")
  cat("=========================\n\n")
  
  outline <- list(
    "Executive Summary" = c("Key findings", "Policy implications", "2 pages"),
    "Introduction" = c("Background", "Objectives", "3 pages"),
    "Methodology" = c("Design", "Sample", "Collection", "5 pages"),
    "Results - Poverty" = c("National", "Provincial", "Trends", "15 pages"),
    "Results - Employment" = c("Rates", "Sectors", "Youth", "12 pages"),
    "Results - Health" = c("Access", "Utilization", "Barriers", "10 pages"),
    "Discussion" = c("Synthesis", "Comparisons", "5 pages"),
    "Recommendations" = c("Policy", "Future surveys", "3 pages"),
    "Appendices" = c("Tables", "Technical notes", "25 pages")
  )
  
  total_pages <- 0
  
  for(section in names(outline)) {
    pages <- as.numeric(gsub(" pages", "", outline[[section]][3]))
    total_pages <- total_pages + pages
    
    cat(sprintf("%-25s: %s\n", section, outline[[section]][3]))
  }
  
  cat("\nTotal pages:", total_pages, "\n")
  cat("Delivery: Month 15\n")
  
  return(outline)
}

report_outline <- write_survey_report()
```

---

# Slide 380: Step 41 - Data Visualization

## Making Data Speak

```{r data-visualization, echo=FALSE}
# Create example visualization
poverty_by_province <- tibble(
  Province = paste("Province", 1:8),
  Poverty_Rate = c(28.5, 35.2, 42.1, 31.8, 38.5, 44.2, 29.8, 36.5),
  Lower_CI = Poverty_Rate - c(2.1, 2.5, 3.1, 2.3, 2.8, 3.2, 2.2, 2.6),
  Upper_CI = Poverty_Rate + c(2.1, 2.5, 3.1, 2.3, 2.8, 3.2, 2.2, 2.6)
)

poverty_by_province %>%
  ggplot(aes(x = reorder(Province, Poverty_Rate), y = Poverty_Rate)) +
  geom_col(fill = sadc_colors[2]) +
  geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI), width = 0.3) +
  geom_hline(yintercept = 34.2, linetype = "dashed", color = "red") +
  coord_flip() +
  labs(title = "Poverty Rates by Province",
       subtitle = "With 95% confidence intervals (National rate = 34.2%)",
       x = "", y = "Poverty Rate (%)") +
  theme_minimal()
```

---

# Slide 381: Step 42 - Dissemination Strategy

## Getting Data to Users

```{r dissemination, echo=TRUE}
# Plan dissemination activities
plan_dissemination <- function() {
  
  cat("DISSEMINATION PLAN\n")
  cat("==================\n\n")
  
  activities <- data.frame(
    Month = c(15, 15, 16, 16, 17, 18),
    Activity = c("Ministerial briefing", "Press conference", 
                 "Technical workshop", "Public use file release",
                 "Regional presentations", "Academic conference"),
    Audience = c("Cabinet", "Media", "Researchers", "Public",
                 "Local government", "International"),
    Format = c("Presentation", "Press kit", "Technical report",
               "Dataset + docs", "Roadshow", "Paper"),
    Lead = c("Director", "Director + Minister", "Technical team",
             "Data team", "Regional coordinators", "Analysis team"),
    stringsAsFactors = FALSE
  )
  
  cat("DISSEMINATION ACTIVITIES:\n\n")
  print(activities)
  
  cat("\nKey products:\n")
  cat("â€¢ Main report (80 pages)\n")
  cat("â€¢ Executive brief (4 pages)\n")
  cat("â€¢ Provincial profiles (8 Ã— 10 pages)\n")
  cat("â€¢ Indicator dashboard (online)\n")
  cat("â€¢ Microdata files (anonymized)\n")
  
  return(activities)
}

dissemination_plan <- plan_dissemination()
```

---

# Slide 382: Step 43 - User Support System

## Helping Data Users

```{r user-support, echo=FALSE}
support_structure <- tibble(
  Service = c("Help desk", "Documentation", "Training workshops", 
              "Online tutorials", "User forum"),
  Availability = c("Business hours", "24/7 online", "Monthly", 
                   "Always", "24/7"),
  Target_Users = c("All", "All", "Researchers", "All", "Community"),
  Cost = c("2 FTE", "One-time", "$2,000/month", "One-time", "Minimal"),
  Success_Metric = c("Response time <24h", "Downloads", "Attendance", 
                     "View count", "Active users")
)

support_structure %>%
  gt() %>%
  tab_header(
    title = "User Support Infrastructure",
    subtitle = "Ensuring data gets used properly"
  )
```

---

# Slide 383: Step 44 - Archiving and Documentation

## Preserving the Knowledge

```{r archiving, echo=TRUE}
# Document archiving strategy
archive_survey_materials <- function() {
  
  cat("SURVEY ARCHIVING PLAN\n")
  cat("====================\n\n")
  
  archive_structure <- list(
    "/01_Design/" = c("Proposal.pdf", "Sample_design.xlsx", "Budget.xlsx"),
    "/02_Instruments/" = c("Questionnaire_v*.pdf", "Translations/", "Manuals/"),
    "/03_Data/" = c("Raw/", "Processed/", "Final/", "Weights.dta"),
    "/04_Programs/" = c("Processing/", "Analysis/", "Tables/"),
    "/05_Documentation/" = c("Codebook.pdf", "Technical_report.pdf", "Metadata.xml"),
    "/06_Outputs/" = c("Reports/", "Presentations/", "Publications/"),
    "/07_Admin/" = c("Contracts/", "Correspondence/", "Minutes/")
  )
  
  cat("Archive structure:\n")
  for(folder in names(archive_structure)) {
    cat(folder, "\n")
    for(file in archive_structure[[folder]]) {
      cat("  â”œâ”€â”€", file, "\n")
    }
  }
  
  cat("\nStorage requirements: ~50GB\n")
  cat("Backup: 3-2-1 rule (3 copies, 2 media, 1 offsite)\n")
  cat("Retention: Permanent for data, 10 years for admin\n")
  
  return(archive_structure)
}

archive <- archive_survey_materials()
```

---

# Slide 384: Step 45 - Lessons Learned

## What We Discovered

```{r lessons-learned, echo=FALSE}
# Load required libraries
library(tibble)
library(gt)
library(dplyr)

# Create the lessons learned data
lessons <- tibble(
  Area = c("Planning", "Field", "Technology", "Quality", "Team"),
  What_Worked = c(
    "Pilot testing", 
    "Local recruitment", 
    "CAPI system", 
    "Real-time monitoring", 
    "Intensive training"
  ),
  What_Didnt = c(
    "Timeline too tight", 
    "Initial response rate", 
    "Server capacity", 
    "Documentation gaps", 
    "Retention"
  ),
  Recommendation = c(
    "Add 3 months buffer", 
    "More contact attempts", 
    "Cloud infrastructure", 
    "Document as you go", 
    "Better incentives"
  )
)

# Version 1: Basic table with proper column widths
basic_lessons_table <- lessons %>%
  gt() %>%
  tab_header(
    title = "Lessons Learned",
    subtitle = "Improving for next time"
  ) %>%
  cols_label(
    Area = "Area",
    What_Worked = "What Worked",
    What_Didnt = "What Didn't Work",
    Recommendation = "Recommendation"
  ) %>%
  cols_width(
    Area ~ px(100),
    What_Worked ~ px(200),
    What_Didnt ~ px(200),
    Recommendation ~ px(200)
  ) %>%
  tab_style(
    style = list(
      cell_fill(color = "#d4edda")
    ),
    locations = cells_body(columns = What_Worked)
  ) %>%
  tab_style(
    style = list(
      cell_fill(color = "#f8d7da")
    ),
    locations = cells_body(columns = What_Didnt)
  ) %>%
  tab_style(
    style = list(
      cell_fill(color = "#cfe2ff")
    ),
    locations = cells_body(columns = Recommendation)
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_body(columns = Area)
  )

print(basic_lessons_table)

# Version 2: Enhanced lessons learned with more detail
detailed_lessons <- tibble(
  Area = c("Planning", "Field Operations", "Technology", "Quality Control", 
           "Team Management", "Budget", "Communication"),
  What_Worked = c(
    "Comprehensive pilot testing identified issues early",
    "Local recruitment improved community trust and response",
    "CAPI system reduced data entry errors by 80%",
    "Real-time monitoring dashboard caught problems quickly",
    "3-week intensive training program prepared staff well",
    "Contingency fund covered unexpected costs",
    "Weekly stakeholder updates maintained alignment"
  ),
  What_Didnt = c(
    "Timeline didn't account for seasonal variations",
    "Initial response rate below target (45% vs 60%)",
    "Server capacity insufficient during peak collection",
    "Documentation not maintained during busy periods",
    "High staff turnover in rural areas (30%)",
    "Underestimated translation costs by 40%",
    "Feedback loop with field teams too slow"
  ),
  Recommendation = c(
    "Build 3-month buffer and map seasonal constraints",
    "Increase contact attempts from 3 to 5, vary timing",
    "Move to cloud infrastructure with auto-scaling",
    "Assign dedicated documentation role, use templates",
    "Improve rural incentives, provide housing support",
    "Budget 50% extra for translation and localization",
    "Implement daily field reports via mobile app"
  ),
  Impact = c("High", "High", "Medium", "Medium", "High", "Low", "Medium"),
  Priority = c(1, 2, 4, 5, 3, 7, 6)
)

# Create enhanced table
enhanced_table <- detailed_lessons %>%
  arrange(Priority) %>%
  gt() %>%
  tab_header(
    title = "Comprehensive Lessons Learned Analysis",
    subtitle = "Prioritized improvements for future surveys"
  ) %>%
  cols_label(
    Area = "Area",
    What_Worked = "Successes",
    What_Didnt = "Challenges",
    Recommendation = "Action Items",
    Impact = "Impact",
    Priority = "Priority"
  ) %>%
  cols_width(
    Area ~ px(120),
    What_Worked ~ px(250),
    What_Didnt ~ px(250),
    Recommendation ~ px(250),
    Impact ~ px(80),
    Priority ~ px(60)
  ) %>%
  # Color code by impact
  tab_style(
    style = list(
      cell_fill(color = "#dc3545"),
      cell_text(color = "white", weight = "bold")
    ),
    locations = cells_body(
      columns = Impact,
      rows = Impact == "High"
    )
  ) %>%
  tab_style(
    style = list(
      cell_fill(color = "#ffc107"),
      cell_text(weight = "bold")
    ),
    locations = cells_body(
      columns = Impact,
      rows = Impact == "Medium"
    )
  ) %>%
  tab_style(
    style = list(
      cell_fill(color = "#28a745"),
      cell_text(color = "white")
    ),
    locations = cells_body(
      columns = Impact,
      rows = Impact == "Low"
    )
  ) %>%
  # Highlight top priorities
  tab_style(
    style = list(
      cell_text(weight = "bold", size = px(12))
    ),
    locations = cells_body(
      columns = everything(),
      rows = Priority <= 3
    )
  ) %>%
  tab_footnote(
    footnote = "Priority based on impact and feasibility of implementation",
    locations = cells_column_labels(columns = Priority)
  )

print(enhanced_table)

# Version 3: Quantified lessons with metrics
quantified_lessons <- tibble(
  Area = c("Response Rate", "Data Quality", "Cost Efficiency", 
           "Timeline", "Staff Performance"),
  Target = c("60%", "<2% errors", "$50/interview", "6 months", "90% retention"),
  Actual = c("45%", "1.8% errors", "$65/interview", "8 months", "70% retention"),
  Gap = c("-15pp", "Achieved âœ“", "-$15", "-2 months", "-20pp"),
  Root_Cause = c(
    "Insufficient contact attempts, poor timing",
    "Strong CAPI validation and training",
    "Higher travel costs, extended timeline",
    "Underestimated complexity, delays",
    "Inadequate rural incentives"
  ),
  Improvement = c(
    "5 attempts, SMS pre-notification",
    "Maintain current approach",
    "Better route planning, local hubs",
    "Detailed work breakdown structure",
    "Housing allowance, career path"
  )
)

metrics_table <- quantified_lessons %>%
  gt() %>%
  tab_header(
    title = "Performance Metrics Analysis",
    subtitle = "Targets vs. Actuals with Improvement Plans"
  ) %>%
  cols_label(
    Area = "Metric",
    Target = "Target",
    Actual = "Actual",
    Gap = "Gap",
    Root_Cause = "Root Cause",
    Improvement = "Improvement Action"
  ) %>%
  cols_width(
    Area ~ px(140),
    Target ~ px(100),
    Actual ~ px(100),
    Gap ~ px(100),
    Root_Cause ~ px(220),
    Improvement ~ px(220)
  ) %>%
  # Highlight achieved targets
  tab_style(
    style = list(
      cell_fill(color = "#d4edda"),
      cell_text(weight = "bold")
    ),
    locations = cells_body(
      columns = Gap,
      rows = grepl("âœ“", Gap)
    )
  ) %>%
  # Highlight significant gaps
  tab_style(
    style = list(
      cell_fill(color = "#f8d7da")
    ),
    locations = cells_body(
      columns = Gap,
      rows = !grepl("âœ“", Gap)
    )
  ) %>%
  cols_align(
    align = "center",
    columns = c(Target, Actual, Gap)
  )

print(metrics_table)

# Version 4: Action plan matrix
action_matrix <- tibble(
  Action = c(
    "Extend planning phase",
    "Increase contact attempts",
    "Upgrade infrastructure",
    "Improve documentation",
    "Enhance retention program",
    "Revise budget model"
  ),
  Owner = c("Project Manager", "Field Supervisor", "IT Manager", 
            "Quality Lead", "HR Manager", "Finance Lead"),
  Timeline = c("Next survey", "Immediate", "3 months", 
               "Ongoing", "Next month", "Next quarter"),
  Resources_Needed = c(
    "Planning consultant",
    "Additional interviewers",
    "Cloud services budget",
    "Documentation tools",
    "Incentive budget",
    "Financial analyst"
  ),
  Success_Metric = c(
    "On-time delivery",
    "60% response rate",
    "Zero downtime",
    "100% documented",
    "85% retention",
    "Â±5% accuracy"
  ),
  Status = c("Planned", "In Progress", "Planned", 
             "Started", "In Progress", "Not Started")
)

action_table <- action_matrix %>%
  gt() %>%
  tab_header(
    title = "Improvement Action Plan",
    subtitle = "Converting lessons into concrete actions"
  ) %>%
  cols_width(
    Action ~ px(200),
    Owner ~ px(120),
    Timeline ~ px(100),
    Resources_Needed ~ px(150),
    Success_Metric ~ px(120),
    Status ~ px(100)
  ) %>%
  # Color code status
  tab_style(
    style = list(
      cell_fill(color = "#28a745"),
      cell_text(color = "white")
    ),
    locations = cells_body(
      columns = Status,
      rows = Status == "In Progress"
    )
  ) %>%
  tab_style(
    style = list(
      cell_fill(color = "#007bff"),
      cell_text(color = "white")
    ),
    locations = cells_body(
      columns = Status,
      rows = Status == "Planned"
    )
  ) %>%
  tab_style(
    style = list(
      cell_fill(color = "#6c757d"),
      cell_text(color = "white")
    ),
    locations = cells_body(
      columns = Status,
      rows = Status == "Not Started"
    )
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_body(columns = Action)
  )

print(action_table)

# Summary recommendations
cat("\n================================================\n")
cat("LESSONS LEARNED SUMMARY\n")
cat("================================================\n\n")

cat("TOP 5 CRITICAL IMPROVEMENTS:\n")
cat("-----------------------------\n\n")

cat("1. PLANNING PHASE\n")
cat("   Issue: Timeline 33% over budget\n")
cat("   Solution: Add 3-month buffer, account for seasonality\n")
cat("   Expected Impact: 90% on-time delivery\n\n")

cat("2. RESPONSE RATES\n")
cat("   Issue: 15 percentage points below target\n")
cat("   Solution: 5 contact attempts, varied timing, SMS pre-notification\n")
cat("   Expected Impact: Achieve 60% response rate\n\n")

cat("3. STAFF RETENTION\n")
cat("   Issue: 30% turnover in rural areas\n")
cat("   Solution: Housing support, clear career progression\n")
cat("   Expected Impact: Reduce turnover to 15%\n\n")

cat("4. TECHNOLOGY INFRASTRUCTURE\n")
cat("   Issue: Server crashes during peak collection\n")
cat("   Solution: Cloud-based auto-scaling infrastructure\n")
cat("   Expected Impact: 99.9% uptime\n\n")

cat("5. DOCUMENTATION\n")
cat("   Issue: Incomplete documentation during busy periods\n")
cat("   Solution: Dedicated role, automated templates\n")
cat("   Expected Impact: 100% process documentation\n\n")

cat("IMPLEMENTATION ROADMAP:\n")
cat("-----------------------\n")
cat("Month 1: Address immediate issues (response rates, documentation)\n")
cat("Month 2-3: Plan infrastructure upgrade, start retention program\n")
cat("Month 4-6: Implement technology changes, refine processes\n")
cat("Next Survey: Apply all lessons with enhanced planning phase\n\n")

cat("ESTIMATED IMPROVEMENT POTENTIAL:\n")
cat("--------------------------------\n")
cat("Cost reduction: 20-25%\n")
cat("Quality improvement: 30-40%\n")
cat("Timeline accuracy: 85-90%\n")
cat("Staff satisfaction: 25-30% increase\n")
```

---

# Slide 385: Step 46 - Cost Analysis

## Where Did the Money Go?

```{r cost-analysis, echo=TRUE}
# Analyze actual vs planned costs
analyze_survey_costs <- function() {
  
  cat("COST ANALYSIS REPORT\n")
  cat("===================\n\n")
  
  costs <- data.frame(
    Category = c("Planning", "Training", "Field work", "Processing", 
                 "Analysis", "Dissemination", "Other"),
    Budgeted = c(200000, 160000, 1000000, 240000, 200000, 100000, 100000),
    Actual = c(185000, 175000, 1080000, 220000, 190000, 95000, 55000),
    stringsAsFactors = FALSE
  )
  
  costs$Variance <- costs$Actual - costs$Budgeted
  costs$Variance_Pct <- round(costs$Variance / costs$Budgeted * 100, 1)
  
  print(costs)
  
  cat("\nSUMMARY:\n")
  cat("Total budgeted: $", format(sum(costs$Budgeted), big.mark=","), "\n")
  cat("Total actual: $", format(sum(costs$Actual), big.mark=","), "\n")
  cat("Under budget by: $", format(sum(costs$Budgeted) - sum(costs$Actual), big.mark=","), "\n")
  
  cat("\nKey findings:\n")
  cat("â€¢ Training costs exceeded budget (more participants)\n")
  cat("â€¢ Field costs higher (fuel prices increased)\n")
  cat("â€¢ Saved on contingency\n")
  
  return(costs)
}

cost_analysis <- analyze_survey_costs()
```

---

# Slide 386: Step 47 - Impact Assessment

## Did We Make a Difference?

```{r impact-assessment, echo=FALSE}
impact_metrics <- tibble(
  Indicator = c("Policy decisions informed", "Media citations", 
                "Research papers", "Donor confidence", "Capacity built"),
  Target = c("5 major policies", "20 articles", "10 papers", 
             "Maintain funding", "50 trained staff"),
  Achieved = c("8 policies", "47 articles", "15 papers", 
               "Funding increased", "65 staff certified"),
  Impact = c("HIGH", "HIGH", "HIGH", "HIGH", "HIGH")
)

impact_metrics %>%
  gt() %>%
  tab_header(
    title = "Survey Impact Assessment",
    subtitle = "6 months post-release"
  ) %>%
  data_color(
    columns = Impact,
    colors = scales::col_factor(
      palette = c("HIGH" = "#d4edda", "MEDIUM" = "#fff3cd", "LOW" = "#ffcccc"),
      domain = c("HIGH", "MEDIUM", "LOW")
    )
  )
```

---

# Slide 387: Step 48 - Sustainability Planning

## Building for the Future

```{r sustainability, echo=TRUE}
# Plan for survey sustainability
plan_sustainability <- function() {
  
  cat("SUSTAINABILITY FRAMEWORK\n")
  cat("=======================\n\n")
  
  cat("INSTITUTIONAL CAPACITY:\n")
  cat("âœ“ 65 trained staff retained\n")
  cat("âœ“ Documentation system established\n")
  cat("âœ“ Technology infrastructure in place\n")
  cat("âœ“ Quality framework operational\n\n")
  
  cat("FINANCIAL SUSTAINABILITY:\n")
  cat("â€¢ Government budget line secured\n")
  cat("â€¢ Donor commitment for 3 years\n")
  cat("â€¢ Cost recovery from data sales\n")
  cat("â€¢ Efficiency gains = 20% savings\n\n")
  
  cat("TECHNICAL SUSTAINABILITY:\n")
  cat("â€¢ Scripts and programs documented\n")
  cat("â€¢ Knowledge transfer complete\n")
  cat("â€¢ Maintenance contracts in place\n")
  cat("â€¢ Update procedures defined\n\n")
  
  cat("NEXT SURVEY:\n")
  cat("â€¢ Planned for 2028\n")
  cat("â€¢ Budget approved\n")
  cat("â€¢ Core team retained\n")
  cat("â€¢ Improvements identified\n")
  
  return(TRUE)
}

sustainable <- plan_sustainability()
```

---

# Slide 388: Final Dashboard

## Survey at a Glance

```{r final-dashboard, echo=FALSE}
# Create final summary dashboard
dashboard_data <- tibble(
  Metric = c("Households surveyed", "Response rate", "Data quality score",
             "Time to release", "Budget utilization", "User satisfaction"),
  Value = c("10,180", "78.2%", "94/100", "6 months", "100%", "4.7/5"),
  Status = c("âœ…", "âœ…", "âœ…", "âœ…", "âœ…", "âœ…")
)

dashboard_data %>%
  gt() %>%
  tab_header(
    title = "2026 National Household Survey",
    subtitle = "Final Performance Dashboard"
  ) %>%
  tab_style(
    style = cell_text(size = "large", weight = "bold"),
    locations = cells_body(columns = Value)
  ) %>%
  tab_style(
    style = cell_fill(color = "#d4edda"),
    locations = cells_body()
  )
```

**Mission Accomplished!**

---

# Slide 389: Recognition and Awards

## Celebrating Success

```{r recognition, echo=FALSE}
achievements <- tibble(
  Recognition = c("UN Statistical Award", "Regional Best Practice", 
                  "Government Excellence", "Team Achievement"),
  For = c("Innovation in sampling", "Quality standards", 
          "Timely delivery", "Exceptional teamwork"),
  Date = c("Month 18", "Month 17", "Month 16", "Month 15")
)

achievements %>%
  gt() %>%
  tab_header(
    title = "Project Recognition",
    subtitle = "Excellence acknowledged"
  ) %>%
  tab_style(
    style = cell_fill(color = "#ffd700"),
    locations = cells_body(rows = 1)
  )
```

---

# Slide 390: Technical Appendix A - Sample Code

## Key R Functions Used

```{r technical-appendix, echo=TRUE}
# Core functions developed for survey
survey_functions <- function() {
  
  cat("CUSTOM SURVEY FUNCTIONS\n")
  cat("======================\n\n")
  
  cat("# PPS Selection\n")
  cat("select_pps <- function(frame, n, size_var) {...}\n\n")
  
  cat("# Weight Calculation\n")
  cat("calculate_weights <- function(data, response_rate) {...}\n\n")
  
  cat("# Variance Estimation\n")
  cat("estimate_variance <- function(y, weights, strata, psu) {...}\n\n")
  
  cat("# Quality Checks\n")
  cat("check_quality <- function(data) {...}\n\n")
  
  cat("# Report Generation\n")
  cat("generate_report <- function(results, template) {...}\n\n")
  
  cat("All functions available at:\n")
  cat("github.com/stats-zambezia/nhs2026\n")
  
  return(TRUE)
}

survey_functions()
```

---

# Slide 391: Technical Appendix B - Formulas

## Mathematical Details

```{r formulas-appendix, echo=FALSE}
formulas <- tribble(
  ~Concept, ~Formula, ~Description,
  "Sample size", "n = zÂ²pq/eÂ² Ã— DEFF Ã— (1+r)", "With non-response",
  "PPS selection", "Ï€áµ¢ = n Ã— Máµ¢/M", "Probability proportional to size",
  "Weight", "wáµ¢ = 1/(Ï€â‚áµ¢ Ã— Ï€â‚‚áµ¢) Ã— 1/RRáµ¢", "Two-stage with NR",
  "Variance", "V(Å¶) = Î£Î£(Ï€áµ¢â±¼ - Ï€áµ¢Ï€â±¼)/Ï€áµ¢â±¼ Ã— yáµ¢yâ±¼/Ï€áµ¢Ï€â±¼", "HT estimator",
  "Calibration", "wáµ¢* = wáµ¢(1 + Î»'xáµ¢)", "GREG weights"
)

formulas %>%
  gt() %>%
  tab_header(
    title = "Key Survey Formulas",
    subtitle = "Mathematical foundations"
  )
```

---

# Slide 392: Contact Information

## Stay Connected

```{r contact-info, echo=FALSE}
contacts <- tibble(
  Role = c("Project Director", "Technical Lead", "Data Access", "User Support"),
  Name = c("Harry Sampler", "Sarah Methods", "David Data", "Grace Support"),
  Email = c("harry@stats.zb", "sarah@stats.zb", "data@stats.zb", "support@stats.zb"),
  Phone = c("+260-XXX-XXXX", "+260-XXX-XXXX", "+260-XXX-XXXX", "+260-XXX-XXXX")
)

contacts %>%
  gt() %>%
  tab_header(
    title = "Survey Team Contacts",
    subtitle = "We're here to help"
  )
```

**Website:** www.stats.zb/nhs2026  
**Data portal:** data.stats.zb  
**Documentation:** docs.stats.zb/nhs2026

---

# Slide 393: References

## Standing on Giants' Shoulders

```{r references, echo=TRUE}
# Key references used
print_references <- function() {
  
  cat("KEY REFERENCES\n")
  cat("=============\n\n")
  
  refs <- c(
    "Cochran, W.G. (1977). Sampling Techniques. 3rd Edition.",
    "Lohr, S.L. (2019). Sampling: Design and Analysis. 3rd Edition.",
    "Groves, R.M. et al. (2009). Survey Methodology. 2nd Edition.",
    "UN (2005). Household Sample Surveys in Developing Countries.",
    "World Bank (2000). LSMS Survey Design.",
    "Eurostat (2018). EU-SILC Methodology.",
    "Statistics Canada (2003). Survey Methods and Practices.",
    "Lumley, T. (2010). Complex Surveys: R Guide.",
    "Rao, J.N.K. (2003). Small Area Estimation.",
    "Fuller, W.A. (2009). Sampling Statistics."
  )
  
  for(i in 1:length(refs)) {
    cat(sprintf("[%d] %s\n", i, refs[i]))
  }
  
  cat("\nTotal references: 47\n")
  cat("Full bibliography: Appendix F\n")
}

print_references()
```

---

# Slide 394: Acknowledgments

## Thank You!

**We gratefully acknowledge:**

- Ministry of Planning and Finance for funding
- Statistics Office staff for dedication
- Field teams for exceptional work
- Households for participation
- International partners for technical support
- World Bank for Survey Solutions platform
- UN Statistics Division for guidance
- Regional statistics offices for collaboration

**Special thanks to:**
- The 200 interviewers who walked thousands of kilometers
- The 50 supervisors who ensured quality
- The communities that welcomed our teams
- Harry, for leading us through this journey

---

# Slide 395: Student Reflections

## What You've Learned

```{r student-reflection, echo=TRUE}
# Capstone learning outcomes
reflect_on_learning <- function() {
  
  cat("CAPSTONE PROJECT LEARNING OUTCOMES\n")
  cat("==================================\n\n")
  
  cat("You have successfully:\n\n")
  
  outcomes <- c(
    "âœ… Designed a complete national survey",
    "âœ… Calculated sample sizes for complex designs",
    "âœ… Developed stratified two-stage sampling",
    "âœ… Created comprehensive documentation",
    "âœ… Implemented quality control systems",
    "âœ… Calculated survey weights",
    "âœ… Produced analysis-ready datasets",
    "âœ… Generated actionable insights",
    "âœ… Managed $2M budget",
    "âœ… Led a team of 270+ people"
  )
  
  for(outcome in outcomes) {
    cat(outcome, "\n")
  }
  
  cat("\nYou are now ready to:\n")
  cat("â€¢ Lead survey projects\n")
  cat("â€¢ Apply international standards\n")
  cat("â€¢ Solve complex sampling problems\n")
  cat("â€¢ Deliver quality statistics\n")
  
  return(TRUE)
}

learning_complete <- reflect_on_learning()
```

---

# Slide 396: Your Certificate

## Congratulations!

```{r certificate, echo=FALSE}
cert_data <- tibble(
  Field = c("Student", "Course", "Grade", "Date", "Instructor"),
  Value = c("[Your Name]", "Advanced Household Survey Methods", 
            "Distinction", "September 2025", "Harry Sampler")
)

cert_data %>%
  gt() %>%
  tab_header(
    title = "CERTIFICATE OF COMPLETION",
    subtitle = "SADC Statistical Training Centre"
  ) %>%
  tab_style(
    style = cell_text(size = "x-large", weight = "bold"),
    locations = cells_body(rows = 1)
  ) %>%
  tab_style(
    style = cell_fill(color = "#ffd700"),
    locations = cells_body()
  )
```

**Certification Number:** SADC-2025-ADV-001  
**Credits:** 40 hours CPD  
**Level:** Advanced Practitioner

---

# Slide 397: Next Steps

## Your Journey Continues

```{r next-steps, echo=TRUE}
# Where to go from here
define_next_steps <- function() {
  
  cat("YOUR NEXT STEPS\n")
  cat("==============\n\n")
  
  cat("IMMEDIATE (This week):\n")
  cat("â–¡ Review all materials\n")
  cat("â–¡ Run all code examples\n")
  cat("â–¡ Complete practice exercises\n")
  cat("â–¡ Join community of practice\n\n")
  
  cat("SHORT TERM (Next month):\n")
  cat("â–¡ Apply methods to your work\n")
  cat("â–¡ Share knowledge with team\n")
  cat("â–¡ Start a pilot project\n")
  cat("â–¡ Attend advanced workshops\n\n")
  
  cat("LONG TERM (Next year):\n")
  cat("â–¡ Lead a survey project\n")
  cat("â–¡ Publish methodology paper\n")
  cat("â–¡ Mentor others\n")
  cat("â–¡ Contribute to standards\n\n")
  
  cat("RESOURCES:\n")
  cat("â€¢ Online community: forum.sadc-stats.org\n")
  cat("â€¢ Monthly webinars: First Tuesday\n")
  cat("â€¢ Code repository: github.com/sadc-stats\n")
  cat("â€¢ Help desk: support@sadc-stats.org\n")
  
  return(TRUE)
}

next_steps <- define_next_steps()
```

---

# Slide 398: Final Exercise

## Test Your Mastery

**Design a rapid COVID-19 impact survey:**

- Budget: $100,000
- Timeline: 6 weeks
- Sample: 2,000 households
- Mode: Phone only
- Focus: Economic impact

**Deliverables:**
1. Sample design (2 pages)
2. Budget allocation
3. Questionnaire outline
4. Weight calculation plan
5. Timeline with milestones

**Submit to:** exercises@sadc-stats.org  
**Deadline:** 1 week  
**Feedback:** Within 48 hours

---

# Slide 399: Course Feedback

## Help Us Improve

```{r feedback-form, echo=FALSE}
feedback <- tibble(
  Aspect = c("Content quality", "Practical relevance", "Instructor knowledge",
             "Materials provided", "Exercises", "Overall satisfaction"),
  Rating = c("â­â­â­â­â­", "â­â­â­â­â­", "â­â­â­â­â­",
            "â­â­â­â­â­", "â­â­â­â­â­", "â­â­â­â­â­")
)

feedback %>%
  gt() %>%
  tab_header(
    title = "Course Evaluation",
    subtitle = "Your feedback matters"
  )
```

**Comments:** ________________________________

**Would you recommend this course?** â˜ Yes â˜ No

**Submit at:** feedback.sadc-stats.org/survey-methods

---

# Slide 400: The End... and The Beginning

## Harry's Final Words

```{r final-message, echo=TRUE}
# Harry's closing message
harrys_final_message <- function() {
  
  cat("=" %>% rep(50) %>% paste(collapse=""), "\n\n")
  
  cat("Dear Survey Champions,\n\n")
  
  cat("When we started on Monday morning, I was in crisis.\n")
  cat("Now, on Friday afternoon, WE are transformed.\n\n")
  
  cat("You've learned that excellent surveys are not\n")
  cat("accidents - they are the result of:\n")
  cat("  â€¢ Rigorous planning\n")
  cat("  â€¢ Scientific methods\n")
  cat("  â€¢ Attention to quality\n")
  cat("  â€¢ Dedicated teamwork\n")
  cat("  â€¢ Continuous learning\n\n")
  
  cat("You now have the knowledge to design and implement\n")
  cat("world-class household surveys that meet international\n")
  cat("standards while serving local needs.\n\n")
  
  cat("Go forth and create excellent statistics!\n\n")
  
  cat("Remember: Every number represents a person,\n")
  cat("         Every survey can change lives,\n")
  cat("         Every methodology matters.\n\n")
  
  cat("Stay curious, stay rigorous, stay connected.\n\n")
  
  cat("Yours in statistical excellence,\n")
  cat("Harry\n\n")
  
  cat("=" %>% rep(50) %>% paste(collapse=""), "\n")
}

harrys_final_message()
```

---

class: inverse, center, middle

# ðŸŽ“ CAPSTONE PROJECT COMPLETE ðŸŽ“

## You've Successfully Designed and Implemented
## The 2026 National Household Survey

### Budget: $2 Million âœ“
### Sample: 10,000 Households âœ“
### Quality: International Standards âœ“
### Impact: Transformational âœ“

---

# Thank You!

## See you in the field!

**Course Materials:** www.sadc-stats.org/survey-methods  
**Community Forum:** forum.sadc-stats.org  
**Next Course:** Panel Survey Methods - January 2026  

*"From Crisis to Confidence in 400 Slides"*  
*- Harry's Statistical Journey*

**#SurveyExcellence #StatisticalTransformation #SADCStats**